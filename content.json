{"pages":[{"title":"","text":"操先森的博客： caolizhi.top","link":"/README.html"},{"title":"","text":"In me the tiger sniffs the rose!心有猛虎，细嗅蔷薇！","link":"/about/index.html"}],"posts":[{"title":"Webflux 介绍","text":"Webflux目的与用户打交道 why created?1.基于函数式编程2.使用固定的线程和硬件资源处理并发 两种编程模型 基于注解的 controller 函数式端点Functional Endpoints Router与Handler RouterFunctions可以产生Router和Handler对象， RouterFunctions对标@Controller中的注解 Router相当于@RequestMapping Handler相当于Controller中的方法 ServerRequest和ServerResponse SpringMVC中使用的是HTTPServletRequest webFlux + SpringMVC 使用的是ServerHTTPRequest WebFlux+ 响应式 使用的是 ServerRequest 和 Spring MVC 区别IO 密集度较高，使用性能较好 使用 netty 作为 web 容器 基于注解的 WebFlux 阻塞式与响应式实现 WebFlux + SSE 服务器推 传统的SpringMVC注解与WebFlux通用，区别在于底层实现，WebFlux 中的 ServerHttpRequest 与 SpringMVC HTTPServletRequest 的区别 官网建议 如果 Spring MVC 用的好好的，不需要切换，命令式更好写，懂，debug 微服务架构，可以混合使用 如果使用了阻塞的持久化框架，如 JPA,JDBC，最好的选择就是 Spring MVC 陡峭的学习路线 处理请求类 HttpHandler 非阻塞 http 请求处理 WebHandler 高级一点，web api 的请求处理 WebSocket vs. HTTP http 只能由客户端发起连接，服务端作出响应 无状态：每次连接处理一个请求，请求结束后断开连接 无连接： 对于事务处理没有记忆能力，服务器不知道客户端是什么状态 缺陷：通信只能由客户端发起，如果服务器有连续的变化，客户端很难得知 基于http实现即时通讯 轮询: ajax 长轮询： ajax 请求，服务器 hold 住连接 长连接： 嵌入 iframe，长连接的请求，服务器不断输入数据 Flash Socket：内嵌 socket 类的 flash 程序，js 调用 flash，socket 通信 websockets 2008 诞生，2011 成为标准，浏览器支持 服务器主动向客户端推送消息，客户端也可以主动向服务器发送信息，全双工通信 建立握手连接是通过 http 传输的，建立之后，传输不需要 http 协议","link":"/Webflux-%E4%BB%8B%E7%BB%8D/"},{"title":"project-reactor 框架","text":"概述真正的响应式，服务端实现，实现了 Reactive Streams 规范 what’s reactor 一个基于事件，异步处理高并发服务请求的框架，集成了 java 8的 函数式 api CompletableFuture Steam Duration 通过reactor-netty支持非阻塞进程间通信 适合微服务架构 Reactor Netty 提供 HTTP（包括 Websockets）, TCP, UDP 的背压就绪网络引擎 hot/cold cold 为每一个订阅都重新生成数据，从头开始，总能收到产生的全部数据 defer（每次订阅都是相同的返回） hot 持续不断的产生消息，订阅者只能获取订阅之后产生的消息 just share replay 提供 Flux/Mono return 一个 mono, 先返回 mono ，这个 mono 包装好各种方法， 把 方法放到调用里面，看起来是异步，实际上同步，只不过阻塞是发生在 Web 容器（Netty）里面 Router 约等于 @Controller + @RequestMapping Handler controller 里面的方法 create 可以创建 Mono, Flux，异步 generate 只能生成 Flux，同步 Disposable cancel-and-clean-up，stop producing values and clean up any resources it created Mono onNext 和 onError 不能同时用，因为最多一个 single 弹珠图 怎么阅读弹珠图","link":"/project-reactor/"},{"title":"响应式编程","text":"what ？ 响应式宣言 一个基于面向数据流和传播变化的异步编程模型 和 Java 8 Streams 以及 Iterable-Iterator 比较 reactive 是 推模型, events 来了，推到 subscriber Java 8 Streams 以及 Iterable-Iterator 是 拉模型 背压流量控制: 告诉上游自己需要多少数据 如果不能 slow down， 只能 buffer ， drop or fail 在数据流从上游生产者向下游消费者传输的过程中，上游生产速度大于下游消费速度，导致下游的 Buffer 溢出，这种现象就叫做 Backpressure 出现。 规范标准，就是一个接口 publisher subscriber subscription processor 实现 webflux参考 webflux 文章 Project Reactor参考 Project Reactor 文章 RxJava 较老 main 里面同步 加 Scheduler，异步 响应式数据库 底层连接协议如何与数据库建立通讯 springJDBC -&gt; JDBC 规范 -&gt; mysql jdbc Driver -&gt; mysql R2DBC Drivers All terminal methods always return a Publisher type that represents the desired operation. The actual statements are sent to the database upon subscription. how总结来说，实际上就是：“异步编程，事件驱动” 消息驱动 同步与异步 callable BiFunction 同步：哪个线程产生就在哪个线程消费 命令式编程与响应式编程 函数式编程Functional Programming “what to solve” 命令式编程 “how to solve” 基于 lamda calculus 编程范式，编程程序的方法论 观察者模式 Tomcat 的 NIO 异步网络 IO 服务器推技术 Servlet 3.0 与 3.1 why ?一句话：提高性能 使用更多的线程和硬件资源来提高并行度 提高现有资源的使用效率","link":"/reactive-programming/"},{"title":"MySQL系列——MySQL的执行计划","text":"基于 MySQL 8.0 community 的版本 EXPLAIN 摘要用 EXPLAIN 来可以拿到 MySQL 是怎样执行 SQL 语句的。EXPLAIN 会返回一个表，表中的每一行都表示一个 select 语句的执行的信息。 为了更生动的说明这个 MySQL 的执行计划，我用具体的例子阐述，我在本地建一个叫 school 的数据库，并建立 4 张表，分别是学生表，教师表， 分数表，课程表，写一些测试数据进去。 执行脚本文章末尾。 EXPLAIN 输出的格式说明有的测试的数据库，现在我们针对 EXPLAIN 的输出做出一些说明和描述，理解一下 MySQL 的执行计划。我们可以简单执行一下 SQL 语句：explain select * from student;输出如下： idid 就是生成的 select 查询的序号，如果 id 号相同，则从上往下执行；如果 id 不同，id 越大，优先级越高，越先被执行。比如： select_typeselect_type 主要是用来分辨查询的类型，是普通查询还是联合查询还是子查询，又有以下几种类型： SIMPLE：简单的查询，不包含子查询和 union 查询 PRIMARY：查询中若包含任何复杂的子查询，最外层查询则被标记为 PRIMARY UNION：第二个或者之后的 select 查询标记为 UNION DEPENDENT UNION：跟 UNION 类似，dependent 表示 union 或 union all 联合而成的结果会受到外部表影响 UNION RESULT：从 union 表获取结果的 select SUBQUERY：在 select 或者 where 列表中包含子查询 子查询等于一个值得时候就是 subquery DEPENDENT SUBQUERY： SUBQUERY 的子查询要受到外部表查询的影响 子查询返回的是值得集合就是 DEPENDENT SUBQUERY DERIVED：衍生，from 子句中出现的子查询，也叫派生类 DEPENDENT DERIVED：DERIVED 的子查询受到外部衍生表的影响 MATERIALIZED：物化子查询,子查询来自视图 UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被换缓存 UNCACHEABLE UNION：表示使用 union 的查询的结果不能被缓存 partitions分区，分库分表才会有该值 table对应行正在访问哪一个表，表名或者别名，可能还是临时表或者 union 合并的结果集。如果是具体的表名，则是从物理表中获取的数据；如果是类似 derivedN 的形式，表示使用了 id 为 N 的查询产生的衍生表；当有 union 结果集的时候，表名是 union n1,n2 等形式，n1,n2 表示参与 union 的 id； type表示 MySQL 在表中找到所需行的方式，或者叫访问类型，常见的类型有以下几种，从上到下性能依次到好 ALL:全表扫描 index:索引全扫描，遍历整个索引来查询匹配的行主要有两种情况：一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取；另外一种是使用了索引进行排序，这样就避免数据的重排序； range:表示利用索引查询的时候限制了范围，在指定范围内进行查询，避免了 index 的全索引扫描。适用的操作符：=, &lt;&gt;, &gt; , &gt;=, &lt;, &lt;=, IS NULL, BETWEEN, LIKE, or IN () index_subquery:利用索引来关联子查询，不再扫描全表 unique_subquery:该连接类型类似于 index_subquery，使用的是唯一索引 index_merge:在查询过程中需要多个索引组合使用 ref_or_null:对于某个字段即需要关联条件，也需要 null 值的情况下，查询优化器会选择这种访问方式 ref:使用非唯一索引进行数据的查找，或者唯一索引的前缀扫描，返回匹配某个单独值得记录行，ref 还经常出现在 join 中。 eq_ref:使用唯一索引进行数据查找，对于每一个索引键值，表中只有一条记录匹配，简单来说就是多表连接中使用 primary key 或者 unique index 作为关联条件。 const:这个表至多有一个匹配行 system:表只有一行记录（等于系统表），这是const类型的特例 possible_keys显示可能应用在这张表中的索引，一个或者多个，查询设计到的字段上若存在索引，则列出该索引，但不一定被实际查询使用 key实际使用的索引，null 表示没有使用索引，查询中若使用了覆盖索引，则该索引和查询的 select 字段重叠 key_len表示索引中使用的字节数，可以通过 key_len 计算查询中使用的索引长度，在不损失精度的情况下长度越短越好 ref显示索引的那一列被使用了，如果可能的话，是一个常数 rows根据表的统计信息以及索引的使用情况，大致估算出找出所需记录需要读取的行数，直接反映 sql 找了多少数据，在完成目的情况下越少越好 extra包含额外的信息 using filesort: 说明 mysql 无法用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置 using temporary： 建立临时表来保存中间数据，查询完成之后把临时表删除 using index： 表示当前的查询覆盖索引的，直接从索引中读取数据，而不用访问数据表，如果同时出现 using where 表明索引别用来执行索引键值的查找，如果没有，表明索引被用来读取数据，而不是真的查找 using where： 使用 where 进行条件过滤 using join buffer：使用连接缓存 impossible where： where 语句的结果总是 false 官网参考文档 Understanding the Query Execution Plan 测试表以及数据 数据库school 数据库创建 SQL >folded1CREATE DATABASE IF NOT EXISTS school DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_bin; 表测试表 >folded12345678910111213141516171819202122232425262728293031 # 学生表CREATE TABLE `student`(`student_id` VARCHAR(20),`student_name` VARCHAR(20) NOT NULL DEFAULT '',`student_birth` VARCHAR(20) NOT NULL DEFAULT '',`student_sex` VARCHAR(10) NOT NULL DEFAULT '',PRIMARY KEY(`student_id`)) ENGINE=InnoDB;# 课程表CREATE TABLE `course`(`course_id` VARCHAR(20),`course_name` VARCHAR(20) NOT NULL DEFAULT '',`teacher_id` VARCHAR(20) NOT NULL,PRIMARY KEY(`course_id`)) ENGINE=InnoDB;# 教师表CREATE TABLE `teacher`(`teacher_id` VARCHAR(20),`teacher_name` VARCHAR(20) NOT NULL DEFAULT '',PRIMARY KEY(`teacher_id`)) ENGINE=InnoDB;# 分数表CREATE TABLE `score`(`student_id` VARCHAR(20),`course_id` VARCHAR(20),`student_score` BIGINT,PRIMARY KEY(`student_id`,`course_id`)) ENGINE=InnoDB; 数据测试数据 >folded123456789101112131415161718192021222324252627282930313233343536-- 插入学生表测试数据insert into student values('01' , '赵雷' , '1990-01-01' , '男');insert into student values('02' , '钱电' , '1990-12-21' , '男');insert into student values('03' , '孙风' , '1990-05-20' , '男');insert into student values('04' , '李云' , '1990-08-06' , '男');insert into student values('05' , '周梅' , '1991-12-01' , '女');insert into student values('06' , '吴兰' , '1992-03-01' , '女');insert into student values('07' , '郑竹' , '1989-07-01' , '女');insert into student values('08' , '王菊' , '1990-01-20' , '女');-- 课程表测试数据insert into course values('01' , '语文' , '02');insert into course values('02' , '数学' , '01');insert into course values('03' , '英语' , '03');-- 教师表测试数据insert into teacher values('01' , '张三');insert into teacher values('02' , '李四');insert into teacher values('03' , '王五');-- 成绩表测试数据insert into score values('01' , '01' , 80);insert into score values('01' , '02' , 90);insert into score values('01' , '03' , 99);insert into score values('02' , '01' , 70);insert into score values('02' , '02' , 60);insert into score values('02' , '03' , 80);insert into score values('03' , '01' , 80);insert into score values('03' , '02' , 80);insert into score values('03' , '03' , 80);insert into score values('04' , '01' , 50);insert into score values('04' , '02' , 30);insert into score values('04' , '03' , 20);insert into score values('05' , '01' , 76);insert into score values('05' , '02' , 87);insert into score values('06' , '01' , 31);insert into score values('06' , '03' , 34);insert into score values('07' , '02' , 89);insert into score values('07' , '03' , 98);","link":"/mysql-execution-plan/"},{"title":"Java JUC 包中原子类源码分析 CAS","text":"以 AtomicInteger 为例。 在使用 AtomicInteger 类时，加1操作会调用方法 incrementAndGet(),这个方法就是 CAS 的实现。先瞥一眼这个方法的内容， 实际上就是拿到 value 的值，然后再执行加 1 的操作。 1234567891011121314151617public class AtomicInteger extends Number implements java.io.Serializable { private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe(); /** * Unsafe 类直接操作内存 * 这个 VALUE 的值就是 AtomicInteger 类 value 的内存位置地址的偏移量， * 通过 native 方法，拿到地址指针 */ private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, &quot;value&quot;); private volatile int value; public final int incrementAndGet() { return U.getAndAddInt(this, VALUE, 1) + 1; } // 省略其他方法} 再跟踪到 getAndAddInt() 方法中，进到了 Unsafe 类中，如下： 123456789101112public final class Unsafe { ... @HotSpotIntrinsicCandidate public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v; } ...} 这个就是 CAS 的核心实现，流程如下： do 里面，先去拿 this 对象在偏移量为 offset 的值，v 取到的是 0； 然后 while 中 weakCompareAndSetInt() 方法再去判断这个偏移量位置上是不是 0，也就是期望的应该是0， 2.1 如果是 0，就把 0 + 1 = 1 写进去； 2.2 如果不是 0，说明在取到 0 后，有其他线程修改了这个 offset 位置的值，比如 1 2.3 然后又执行一次 do 里面的操作，拿到 v = 1，再去看看这个 offset 位置上的值是不是1，是就加上1，不是继续 do..while 操作 2.4 成功了就结束。 然后返回了 v，注意，这个 v 的值还是刚才取到的 0，并没有重新去取。 这里有个问题，有没有可能这样的情况出现，do 里面取到了是 0，然后比较了当前的位置确实是 0 ，然后再写的过程值又发生了变化呢？ 答案是不可能。我们进到 weakCompareAndSetObject(Object o, long offset,Object expected,Object x) 方法里面看一下源代码： 12345678910111213141516171819public final class Unsafe { @HotSpotIntrinsicCandidate public final boolean weakCompareAndSetObject(Object o, long offset, Object expected, Object x) { return compareAndSetObject(o, offset, expected, x); } /** * 如果当前持有expected则以原子方式将 Java 变量更新为x * 此操作具有volatile读写的内存语义。 对应于 C11 atomic_compare_exchange_strong。 * 返回：如果成功则为true */ @HotSpotIntrinsicCandidate public final native boolean compareAndSetInt(Object o, long offset, int expected, int x);} 我们可以看到注释里面 atomic_compare_exchange_strong 函数，这是 C11 原子的函数，反映到处理器的指令上就是 CMPXCHG 指令，这条指令已经无法再分割，而这条指令执行的时候，通过锁总线来让其他核心处理器都不能访问这个地址。简单来说，从 CPU 原语的级别来保证了 CAS 的操作。","link":"/Java-JUC-%E5%8C%85%E4%B8%AD%E5%8E%9F%E5%AD%90%E7%B1%BB%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"线程池源码分析","text":"线程池及简单介绍（1）线程池类关系图 Executors 是对线程执行的工具类，可以看做是线程池的工厂。execute() 方法任务立即执行，submit() 方法提交任务等待线程自己调度运行。 （2）线程池核心参数的交互 corePoolSize 核心线程数 maximumPoolSize 最大线程数 keepAliveTime 生存时间，线程池中超过核心线程数大小的线程的存活时间，如果设置 allowCoreThreadTimeOut 为 true，那么核心线程数也是此时间的存活时间 unit 生存时间的单位，类型是 TimeUnit workQueue 任务队列 BlockingQueue&lt;Runnable&gt; threadFactory 线程工厂 ThreadFactory handler 拒绝策略， 类型是 RejectedExecutionHandler 首先线程池中会保持 corePoolSize 大小的线程运行，即使没有任务也会空闲运行，但是如果设置了 allowCoreThreadTimeOut = true，那么核心线程也会在 keepAliveTime 时间大小之后关闭。当任务超过了核心线程数的话，会把新的任务放到工作队列，如果工作队列满了，并且当前的工作线程是小于 maximumPoolSize 定义的最大线程数的，那么创建一个新线程来运行任务，当运行的线程数超过了最大线程数的值，拒绝策略开始发挥作用，默认是丢弃策略。 终于来到了我们的线程池的源码解析啦，因为我们知道jdk自带的各种线程池本质上都是核心类 ThreadPollExecutor 构造出来的，所以我们来看里面到到底是个什么鬼？ 源码分析 成员变量 123456789101112131415161718192021222324252627282930313233public class ThreadPoolExecutor extends AbstractExecutorService { // 高 3 位表示线程池状态，低29位表示 worker 的数量 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; // 32 - 3 = 29 /** * 0010 0000 0000 0000 0000 0000 0000 0000 COUNT_BITS 二进制值 - 0000 0000 0000 0000 0000 0000 0000 0001 1 二进制值 ———————————————————————————————————————————— = 0001 1111 1111 1111 1111 1111 1111 1111 COUNT_MASK 二进制值 * */ private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1; // 1 * 2^29 -1 // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 表示接收新任务和处理队列中的任务 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 表示不接收新任务了，但是会处理队列中的任务 private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 表示不接收新任务，也不处理队列中的任务，中断进行中的任务 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 如果所有的任务的已经结束，工作线程是0，此时的线程状态转变为 TIDYING，调用 terminated() 钩子方法 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 表示 terminated() 方法执行完成 // Packing and unpacking ctl // ~COUNT_MASK 值: 1110 0000 0000 0000 0000 0000 0000 0000 // 按位与，低 29 位都是 0 private static int runStateOf(int c) { return c &amp; ~COUNT_MASK; } // COUNT_MASK 二进制值 : 0001 1111 1111 1111 1111 1111 1111 1111 // 按位与，高 3 位都是 0 private static int workerCountOf(int c) { return c &amp; COUNT_MASK; } // 根据线程池状态和线程数量计算 control(ctl) 的值 private static int ctlOf(int rs, int wc) { return rs | wc; }} ctl 这个原子整形变量，包含了两个含义，一个是 workerCount，就是线程池里面 worker 数量，另一个是 runState，就是线程池状态，运行还是停止等等。咦，一个变量怎么表示的两种意思呢？有一个很巧妙的方法就是高3 位表示线程池的状态，低 29 位来表示线程池中的线程数量，目前来说是29位数量足够的，如果不够，后面会扩展成 Long 类型就可以，这样在高并发的情况减少变量的锁同步。具体怎么做到的呢？先来看看线程池状态的表示，首先是 RUNNING 状态： private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; 我们知道 COUNT_BITS 是 29， -1 的二进制值表示是 1 的二进制值，取反，然后加 1 ，就是 -1 的二进制表示。int 是 32 位，那么： 0000 0000 0000 0000 0000 0000 0000 0001 1 的二进制1111 1111 1111 1111 1111 1111 1111 1110 取反1111 1111 1111 1111 1111 1111 1111 1111 加 1 即为 -1 的二进制表示 RUNNING 状态是左移 29 位，那么： 1111 1111 1111 1111 1111 1111 1111 1111 -1 的二进制表示1110 0000 0000 0000 0000 0000 0000 0000 左移 29 后的值 即 RUNNING 的值是：1110 0000 0000 0000 0000 0000 0000 0000， 同理得到：SHUTDOWN&emsp;&nbsp; 的值是 0000 0000 0000 0000 0000 0000 0000 0000，STOP&emsp;&emsp;&emsp;&nbsp; 的值是 0010 0000 0000 0000 0000 0000 0000 0000，TIDYING&emsp;&nbsp;&nbsp;&nbsp; 的值是 0100 0000 0000 0000 0000 0000 0000 0000，TERMINATED&nbsp; 的值是 0110 0000 0000 0000 0000 0000 0000 0000。 所以 ctl 变量的默认值是 RUNNING 的值 和 0 或运算，即 ctl = 1110 0000 0000 0000 0000 0000 0000 0000，实际上意思就是线程池在 RUNNING 状态，但是 0 个工作线程。通过方法 runStateOf() 可以拿到当前线程池的状态值。 上面说的是线程池状态的表示，再来看一下线程池中线程的个数，变量 COUNT_MASK 就是表示线程数的大小，最多（2^29 - 1） 个，通过方法 workerCountOf() 可以计算线程的个数。 构造方法构造方法主要是进行一些非空判断和校验。 1234567891011121314151617181920212223public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); // 将存活时间转换成纳秒 this.threadFactory = threadFactory; this.handler = handler; }} 提交任务的过程提交任务时，会调用 execute() 方法，我们来看一下这个方法： 12345678910111213141516171819202122232425262728293031323334353637383940public class ThreadPoolExecutor extends AbstractExecutorService { public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) // 带了任务参数 return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); // 没有带任务参数 } else if (!addWorker(command, false)) reject(command); }} execute() 方法的思路注释文档说的很清楚，首先非空判断，然后拿到 ctl 的值，来判断： 值（默认是 0 ）小于核心线程数的如果是小于就添加一个 Worker，这个 Worker 是 ThreadPoolExecutor 的内部类，简单来讲就是封装了线程信息和任务信息的类，后面再谈。 值大于核心线程数， 2.1 再判断线程池状态是 RUNNING 状态，就添加到工作队列当中去 2.1.1 这里注意的是还会再一次检查线程池的状态，以防线程池的状态在添加队列的过程中发生改变，如果发现线程池不是 RUNNING 状态的话，那么就把队列里面的任务 remove 掉，然后调用拒绝策略来拒绝，默认是丢弃。 2.1.2 在 2.1.1 的基础判断上，如果线程池仍然是 RUNNING 的状态，但是 workerCountOf() 拿到的 worker 是 0，那么添加一个 worker，这里只在线程池里面增加一个线程。这里我们可以看到核心线程数满了之后，先添加到队列，如果线程池中的 worker 是 0 的话，那么会新加一个线程，核心线程会带着任务直接执行，而核心线程之外的线程是从队列里面取任务来执行的，注意 addWorker() 方法的调用。 2.2 线程池状态并不是 RUNNING 状态的话，或者任务进入队列失败了，尝试创建worker执行任务，实际上 addWorker() 方法里面也是判断了线程池状态的，不是 RUNNING 状态的话直接返回 false，添加任务失败，触发 reject 策略。 addWorker 分析在上面添加任务的分析过程中，主要是调用 addWorker() 的方法，现在来窥探下 addWorker() 方法： 点击展开：addWorker() 方法 >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ThreadPoolExecutor extends AbstractExecutorService { private boolean addWorker(Runnable firstTask, boolean core) { retry: for (int c = ctl.get(); ; ) { /** * 这里的 if 条件等价于 * if(rs &gt; SHUTDOWN || * rs == SHUTDOWN &amp;&amp; firstTask != null || * rs == SHUTDOWN &amp;&amp; workQueue.isEmpty() * ) * 1. 线程池状态 &gt; SHUTDOWN 时，直接返回false； * 2. 线程池状态 = SHUTDOWN 时，且 firstTask 不等于 null，直接返回false； * 3. 线程池状态 = SHUTDOWN 时，且工作队列是空的话，直接返回false； * */ // Check if queue empty only if necessary. if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; // 内存自旋 for (; ; ) { // worker 超过容量，直接返回 false if (workerCountOf(c) &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK)) return false; // 使用 CAS 的方式增加 worker 数量，成功了跳出外层 for 循环 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果线程状态发生变化外层自旋。 if (runStateAtLeast(c, SHUTDOWN)) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); // 重新检查线程池的状态 if (isRunning(c) || (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) { if (t.getState() != Thread.State.NEW) throw new IllegalThreadStateException(); workers.add(w); workerAdded = true; int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; } } finally { mainLock.unlock(); } // 启动 worker 的线程 if (workerAdded) { t.start(); workerStarted = true; } } } finally { if (!workerStarted) addWorkerFailed(w); } return workerStarted; }} &emsp;&emsp;这个方法的代码分为两部分，第一部分是 for() 循环，也就干了一件事把 workerCount 加 1，第二部分循环后执行的代码，目的是添加一个 Worker 对象。在第一 部分代码里面，主要就是第一层的循环判断当前的线程池状态，如果是大于 shutdown 的话就直接返回 false。第二层的循环，先去判断当前的线程数量是不是超过了 corePoolSize 和 maximumPoolSize，然后再用 CAS 的方式把 workerCount 加 1，这是第一部分代码的主要逻辑。 我们再来看看第二部分代码的逻辑，就是 new 一个 Worker 对象，然后把封装任务信息，添加到 workers 集合里面，因为涉及到多线程，肯定需要加锁的，这里用 ReentrantLock 来实现的，加入之后，启动这个线程，开始执行任务。addWorker() 这个方法的思路还是比较清晰的。 接下来我们来看一看 Worker 这个类： 点击展开：Worker 类 >folded12345678910111213141516171819202122232425262728293031public class ThreadPoolExecutor extends AbstractExecutorService { private final class Worker extends AbstractQueuedSynchronizer implements Runnable { /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } /** Delegates main run loop to outer runWorker. */ public void run() { runWorker(this); } }} &emsp;&emsp;主要看一下构造方法，在构造方法里面最重要的就是把当前的 Worker 对象 this 当作参数进行 thread 的生成，实际上等价与 new Thread(runnable)。 因为 Worker 本身是继承了 AQS 类又实现了 Runnable 类的。所以我们要看一下 Worker 重写 run() 方法里面 runWorker() 方法。 runWorker 核心线程执行逻辑先来看一下 runWorker 的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ThreadPoolExecutor extends AbstractExecutorService { final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; // 为了能够让外部中断 w.unlock(); // allow interrupts // 所有任务完成时标志，线程池正在结束 boolean completedAbruptly = true; try { // 如果 firstTask 不为空就执行 first task，为空就去队列里面取。 while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { // 空实现，为了扩展 beforeExecute(wt, task); try { task.run(); afterExecute(task, null); } catch (Throwable ex) { afterExecute(task, ex); throw ex; } } finally { // 帮助 GC task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } }} 上面我们提到 Worker 这个类既继承了 AQS 类又实现了 Runnable 类，那么它本身就是一把锁，就可以做同步。很多线程都会去 new Worker()，然后去放自己的任务，所以给自己加了一把锁，然后只执行自己的任务，如果不加锁，别的线程进来之后有可能让它执行其他的任务，所以这个时候要枷锁。这是自己继承 AQS，不用 new其他的锁了，自己 lock 就行了。这一部分实际上就是执行任务，加了很多状态的判断逻辑。 总结来说，首先提交任务 submit (返回 Future 对象) 或者 execute 任务，然后核心线程池够不够，启动核心的，核心线程够了就加入阻塞队列，队列满了，就添加非核心线程，一直到的最大线程数，然后再执行拒绝策略。","link":"/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java JUC 中的基石： AQS 源码解读","text":"以 ReentrantLock 类为例 在使用 ReentrantLock 类时，调用 lock() 方法，我们先来看一下 lock() 方法： 12345678910111213public class ReentrantLock implements Lock, java.io.Serializable { private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { ... } ... public void lock() { sync.acquire(1); } ...} 看到 sync.acquire(1)，sync 是 ReentrantLock 的内部类，继承了 AbstractQueuedSynchronizer (AQS)，而 acquire(1) 方法是属于 AQS 的，我们进到里面看看： 1234567public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); }} if 条件的两个并列条件，首先是第一个 tryAcquire(1)，这个方法的作用是尝试获得锁，如果当前的锁获取不到就会执行第二个条件，尝试加入队列，如果有任何中断直接中断。先进到 tryAcquire(1) 方法看看： 12345public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); }} 这个方法没有实现，说明留给子类去做实现，这里使用到了模板方法设计模式，在 ReentrantLock 类中，默认是非公平锁，所以内部类 NonfairSync 实现了 tryAcquire(1) 方法，该类继承了 Sync，而根据上述 Sync 继承了 AQS 类。我们看来 ReentrantLock 中 的 NonfairSync 类的结构： 12345678910public class ReentrantLock implements Lock, java.io.Serializable { static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } }} NonfairSync 类里面又调用父类 Sync 的 nonfairTryAcquire(1)，至此，我们到了获取锁的核心方法。 1234567891011121314151617181920212223242526272829public class ReentrantLock implements Lock, java.io.Serializable { abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ @ReservedStackAccess final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); // 获取当前线程 int c = getState(); // 获取当前状态，这个方法是 AQS 里面的方法，拿到的是 volatile 的 state 值，具体 state 值怎么用是子类要干的事情 if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } }} 拿到 state 值以后，if 条件中，判断 state 的值，如果 state 值为 0 ，说明还没有线程拿到锁，然后 CAS 齐昂锁，如果抢锁成功，那么 state 值为 1，并且把当前线程设置为独占锁；如果 state 值不是 0， 说明已经有其他的线程占用了这个锁；else if 的条件分支中，再判断一下已经拿到这个锁的是不是自己，如果是自己的话，就把 state + 1，释放的时候会 - 1。在判断 state 值既不是 0，也不是当前线程持有锁，那么一定是其他线程正在持有锁，返回 false。那么在 AbstractQueuedSynchronizer 类中 acquire(1)方法的第一个 if 条件 tryAcquire(1) 是 false，说明 ReentrantLock实例在调用 lock() 方法没有拿到锁，那就执行if 并列条件的第二个方法 acquireQueued(addWaiter(Node.EXCLUSIVE), arg))，这个方法是尝试加入到等待队列中。首先我们来看 addWaiter() 方法： 12345678910111213141516171819public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { private Node addWaiter(Node mode) { Node node = new Node(mode); for (; ; ) { Node oldTail = tail; if (oldTail != null) { node.setPrevRelaxed(oldTail); if (compareAndSetTail(oldTail, node)) { oldTail.next = node; return node; } } else { initializeSyncQueue(); } } }} 这里我们看到这个方法返回 Node 类，这个 Node 类是什么呢？我们看一下 Node 类的定义： 点击展开: AQS 的内部类 Node 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Wait queue node class. * * &lt;p&gt;The wait queue is a variant of a &quot;CLH&quot; (Craig, Landin, and * Hagersten) lock queue. CLH locks are normally used for * spinlocks. We instead use them for blocking synchronizers, but * use the same basic tactic of holding some of the control * information about a thread in the predecessor of its node. A * &quot;status&quot; field in each node keeps track of whether a thread * should block. A node is signalled when its predecessor * releases. Each node of the queue otherwise serves as a * specific-notification-style monitor holding a single waiting * thread. The status field does NOT control whether threads are * granted locks etc though. A thread may try to acquire if it is * first in the queue. But being first does not guarantee success; * it only gives the right to contend. So the currently released * contender thread may need to rewait. * * &lt;p&gt;To enqueue into a CLH lock, you atomically splice it in as new * tail. To dequeue, you just set the head field. * &lt;pre&gt; * +------+ prev +-----+ +-----+ * head | | &lt;---- | | &lt;---- | | tail * +------+ +-----+ +-----+ * &lt;/pre&gt; * * &lt;p&gt;Insertion into a CLH queue requires only a single atomic * operation on &quot;tail&quot;, so there is a simple atomic point of * demarcation from unqueued to queued. Similarly, dequeuing * involves only updating the &quot;head&quot;. However, it takes a bit * more work for nodes to determine who their successors are, * in part to deal with possible cancellation due to timeouts * and interrupts. * * &lt;p&gt;The &quot;prev&quot; links (not used in original CLH locks), are mainly * needed to handle cancellation. If a node is cancelled, its * successor is (normally) relinked to a non-cancelled * predecessor. For explanation of similar mechanics in the case * of spin locks, see the papers by Scott and Scherer at * http://www.cs.rochester.edu/u/scott/synchronization/ * * &lt;p&gt;We also use &quot;next&quot; links to implement blocking mechanics. * The thread id for each node is kept in its own node, so a * predecessor signals the next node to wake up by traversing * next link to determine which thread it is. Determination of * successor must avoid races with newly queued nodes to set * the &quot;next&quot; fields of their predecessors. This is solved * when necessary by checking backwards from the atomically * updated &quot;tail&quot; when a node's successor appears to be null. * (Or, said differently, the next-links are an optimization * so that we don't usually need a backward scan.) * * &lt;p&gt;Cancellation introduces some conservatism to the basic * algorithms. Since we must poll for cancellation of other * nodes, we can miss noticing whether a cancelled node is * ahead or behind us. This is dealt with by always unparking * successors upon cancellation, allowing them to stabilize on * a new predecessor, unless we can identify an uncancelled * predecessor who will carry this responsibility. * * &lt;p&gt;CLH queues need a dummy header node to get started. But * we don't create them on construction, because it would be wasted * effort if there is never contention. Instead, the node * is constructed and head and tail pointers are set upon first * contention. * * &lt;p&gt;Threads waiting on Conditions use the same nodes, but * use an additional link. Conditions only need to link nodes * in simple (non-concurrent) linked queues because they are * only accessed when exclusively held. Upon await, a node is * inserted into a condition queue. Upon signal, the node is * transferred to the main queue. A special value of status * field is used to mark which queue a node is on. * * &lt;p&gt;Thanks go to Dave Dice, Mark Moir, Victor Luchangco, Bill * Scherer and Michael Scott, along with members of JSR-166 * expert group, for helpful ideas, discussions, and critiques * on the design of this class. */ static final class Node { /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled. */ static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking. */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition. */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate. */ static final int PROPAGATE = -3; /** * Status field, taking on only the values: * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 0: None of the above * * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn't need to * signal. So, most code doesn't need to check for particular * values, just for sign. * * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). */ volatile int waitStatus; /** * Link to predecessor node that current node/thread relies on * for checking waitStatus. Assigned during enqueuing, and nulled * out (for sake of GC) only upon dequeuing. Also, upon * cancellation of a predecessor, we short-circuit while * finding a non-cancelled one, which will always exist * because the head node is never cancelled: A node becomes * head only as a result of successful acquire. A * cancelled thread never succeeds in acquiring, and a thread only * cancels itself, not any other node. */ volatile Node prev; /** * Link to the successor node that the current node/thread * unparks upon release. Assigned during enqueuing, adjusted * when bypassing cancelled predecessors, and nulled out (for * sake of GC) when dequeued. The enq operation does not * assign next field of a predecessor until after attachment, * so seeing a null next field does not necessarily mean that * node is at end of queue. However, if a next field appears * to be null, we can scan prev's from the tail to * double-check. The next field of cancelled nodes is set to * point to the node itself instead of null, to make life * easier for isOnSyncQueue. */ volatile Node next; /** * The thread that enqueued this node. Initialized on * construction and nulled out after use. */ volatile Thread thread; /** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. */ Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() { return nextWaiter == SHARED; } /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * * @return the predecessor of this node */ final Node predecessor() { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } /** Establishes initial head or SHARED marker. */ Node() {} /** Constructor used by addWaiter. */ Node(Node nextWaiter) { this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread()); } /** Constructor used by addConditionWaiter. */ Node(int waitStatus) { WAITSTATUS.set(this, waitStatus); THREAD.set(this, Thread.currentThread()); } /** CASes waitStatus field. */ final boolean compareAndSetWaitStatus(int expect, int update) { return WAITSTATUS.compareAndSet(this, expect, update); } /** CASes next field. */ final boolean compareAndSetNext(Node expect, Node update) { return NEXT.compareAndSet(this, expect, update); } final void setPrevRelaxed(Node p) { PREV.set(this, p); } // VarHandle mechanics private static final VarHandle NEXT; private static final VarHandle PREV; private static final VarHandle THREAD; private static final VarHandle WAITSTATUS; static { try { MethodHandles.Lookup l = MethodHandles.lookup(); NEXT = l.findVarHandle(Node.class, &quot;next&quot;, Node.class); PREV = l.findVarHandle(Node.class, &quot;prev&quot;, Node.class); THREAD = l.findVarHandle(Node.class, &quot;thread&quot;, Thread.class); WAITSTATUS = l.findVarHandle(Node.class, &quot;waitStatus&quot;, int.class); } catch (ReflectiveOperationException e) { throw new ExceptionInInitializerError(e); } } }} 总结一下就是，上面说到的等待队列是由一个双向链表实现的，这个队列是 CLH 队列的变种，把 synchronized 换成了 CAS， 而 Node 类就是这个双向链表带有线程信息的节点类。 Node 只有两种模式，EXCLUSIVE 和 SHARED，还有个成员变量 waitStatus，有几种状态，注释文档说的很清楚，最重要的是 SIGNAL 状态，表示当前的线程的后继节点正在阻塞等待， 当前线程释放锁或者取消后需要唤醒它的后继节点。 > 为什么是双向链表，单向的行不行？ 行，但是还是不够好，如果我要找到某个 node 的前一个节点，时间复杂度就是 O(n)，如果是双向链表就是 O(1)。 继续看 addWaiter(Node.EXCLUSIVE)方法，首先拿到等待队列的 tail 节点，如果为空就初始化一个队列，头尾都是指向这个 node；如果 tail 存在，就把要添加的这个 node 的 prev 指向 tail 节点，因为在操作的过程中，可能其他的线程改动了 tail，所以需要CAS 自旋的把 tail 节点的 next 指向这个要添加的 node。一句话就是：addWaiter() 方法就是添加 node 到等待队列的队尾。然后返回这个 node 添加到队尾之后，执行 acquireQueued(Node.EXCLUSIVE,1)方法，再看一下这个方法： 1234567891011121314151617181920212223242526272829303132public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting */ final boolean acquireQueued(final Node node, int arg) { boolean interrupted = false; try { for (; ; ) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC return interrupted; } if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); } } catch (Throwable t) { cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; } }} 首先去拿这个 node 的 prev 节点，先判断一下是不是头结点，然后再去 tryAcquire(1) ，看看能不能拿到锁，万一头结点刚好释放锁呢，拿到锁之后，说明头结点释放了锁，把这个 node 设置为头结点，然后头结点的 next 节点设置为 null，这样头结点就不会有引用存在，帮助 GC 回收，如果有中断就返回了。如果说，这个 node 的 prev 节点不是头结点或者没有拿到锁，那么进入下面一个条件判断，进入方法 shouldParkAfterFailedAcquire()： 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ pred.compareAndSetWaitStatus(ws, Node.SIGNAL); } return false; }} 在看这个方法前，我们看一下参数，进到这个方法的前提是，如果参数 pred 不是头结点，当前线程也没有拿到锁，那么是不是应该等一下？首先拿到 pred 这个 node 的状态，判断：如果 pred 这个 node 的状态是 SINGAL，表示 pred 的这个 node 待会释放锁的时候会唤醒后继节点，也就是参数 node 指向的这个 Node，实际上就是当前的 node，那么返回 true，就是要等一会；如果 pred 这个 node 的状态是大于 0，大于 0 的状态是 CANCELLED 的状态，可能这个线程 node 被取消调度或者timeout，那么就再去找 pred 的这个 node 的前驱节点，反正一直找到不是 CANCELLED 状态的节点；如果 pred 这个 node 的状态是小于等于 0， waitStatus 默认是 0，小于 0 是处在 CONDITION 和 PROPAGATE 的状态，把 pred 的这个 node 的状态 CAS 设置成 SIGNAL 状态，最后返回 false。总结一下，实际上就是当前的线程节点加塞成为即将被唤醒的节点，坏得很~ 我们再回到方法 acquireQueued(Node.EXCLUSIVE, 1) 中，如果 shouldParkAfterFailedAcquire() 返回是 true，那么就是执行 parkAndCheckInterrupt()，即： 123456789101112public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Convenience method to park and then check if interrupted. * * @return {@code true} if interrupted */ private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); }} 这个方法就是调用同步辅助工具类 LockSupport.park(this)，阻塞住当前线程。 最后，如果在 lock() 的整个过程中拿到了锁，就会继续执行后面的程序，如果没有就阻塞住，这就是整个 AQS 的源码基本思路。 我们再来关注一下 AQS 为什么效率高？主要是 AQS 采用 CAS 来操作链表尾巴，如果好多线程都要往链表尾巴上插入节点，第一想法肯定会加锁，锁定整个 (Sync) 对象，保证线程安全，但是锁定整个链表的话，锁的太多太大了，现在 AQS 并不是锁定整个链表的方法，而是观测 tail 这个节点就可以了，用 CAS 是做实现，这就是AQS 效率高的核心。","link":"/Java-JUC-%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%9F%B3%EF%BC%9A-AQS-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"}],"tags":[{"name":"web","slug":"web","link":"/tags/web/"},{"name":"reactive","slug":"reactive","link":"/tags/reactive/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"CAS","slug":"CAS","link":"/tags/CAS/"},{"name":"JUC","slug":"JUC","link":"/tags/JUC/"},{"name":"线程池","slug":"线程池","link":"/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"}],"categories":[{"name":"响应式编程","slug":"响应式编程","link":"/categories/%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"多线程","slug":"多线程","link":"/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]}