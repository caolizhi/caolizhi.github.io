{"pages":[{"title":"","text":"In me the tiger sniffs the rose!心有猛虎，细嗅蔷薇！","link":"/about/index.html"}],"posts":[{"title":"JVM系列 —— 对象从出生到死亡","text":"这是 JVM 系列的第九篇，见 JVM 系列。 写在前面TBD","link":"/2022-01-JVM%E7%B3%BB%E5%88%97-%E5%AF%B9%E8%B1%A1%E4%BB%8E%E5%87%BA%E7%94%9F%E5%88%B0%E6%AD%BB%E4%BA%A1/"},{"title":"JVM系列 —— 对象的内存布局","text":"这是 JVM 系列的第八篇，见 JVM 系列。 写在前面这里仅仅就一个 java 对象结构本身来学习的。其实在前面的类加载阶段，了解了，oop-klass 体系结构，简单来说，oop（ordinary object pointer 普通对象指针） 体系主要用来描述Java 对象和实例数据，klass 体系主要用来描述 Java 对象在 C++ 中的表示形式。个人理解来说，oop 是从 Java 对象角度的，klass 是从 JVM C++ 角度的。但是两者是有关联的，oop 中保存了一个指针指向 klass，这样 JVM 在运行期间就能知道每一个实例的数据结构和实际类型。 在前面的知识，我们知道，oop 体系的基类是 oopDesc，它的结构如下： oopDesc类结构12345678910111213141516171819class oopDesc { friend class VMStructs; private: volatile markOop _mark; union _metadata { Klass* _klass; narrowKlass _compressed_klass; } _metadata; // Fast access to barrier set. Must be initialized. static BarrierSet* _bs; public: markOop mark() const { return _mark; } markOop* mark_addr() const { return (markOop*) &amp;_mark; } void set_mark(volatile markOop m) { _mark = m; } ...} oopDesc 包含两部分，一个是 mark，一个是 metadata。 对象头JVM 运行过程中，每创建一个新的对象，在 JVM 内部就会创建相应的 oop 对象。一个 java 对象实例包括一个 instanceOopDesc* instanceOop; 和实例数据。 因为 instanceOopDesc 类是继承的基类 oopDesc。 instanceOopDesc 又用来表示对象头。也就是说对象头包括了两部分：Mark Word 和 元数据指针 instanceOopDesc 类结构1234567891011121314151617181920class instanceOopDesc : public oopDesc { public: // aligned header size. static int header_size() { return sizeof(instanceOopDesc)/HeapWordSize; } // If compressed, the offset of the fields of the instance may not be aligned. static int base_offset_in_bytes() { // offset computation code breaks if UseCompressedClassPointers // only is true return (UseCompressedOops &amp;&amp; UseCompressedClassPointers) ? klass_gap_offset_in_bytes() : sizeof(instanceOopDesc); } static bool contains_field_offset(int offset, int nonstatic_field_size) { int base_in_bytes = base_offset_in_bytes(); return (offset &gt;= base_in_bytes &amp;&amp; (offset-base_in_bytes) &lt; nonstatic_field_size * heapOopSize); }}; Mark Word在基类 oopDesc 中看到 mark 的类型是一个 markOopDesc，这个 C++ 类在 JVM 内部起一个标记的作用，就是第一个整型数字，但是为了面向对象的设计风格，设计成了一个类。在 markOopDesc 类源码注释里面，作者也说明了：Note that the mark is not a real oop but just a word. It is placed in the oop hierarchy for historical reasons.。 那么，这个 markOopDesc 就是我们所说的对象头里面 Mark Word 的结构，64位的虚拟机上 Mark Word 大小是 64 bit。结构如下： markOopDesc 结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146// The markOop describes the header of an object.//// Note that the mark is not a real oop but just a word.// It is placed in the oop hierarchy for historical reasons.//// Bit-format of an object header (most significant first, big endian layout below)://// 32 bits:// --------// hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object)// size:32 ------------------------------------------&gt;| (CMS free block)// PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)//// 64 bits:// --------// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)// size:64 -----------------------------------------------------&gt;| (CMS free block)//// unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block)//// - hash contains the identity hash value: largest value is// 31 bits, see os::random(). Also, 64-bit vm's require// a hash value no bigger than 32 bits because they will not// properly generate a mask larger than that: see library_call.cpp// and c1_CodePatterns_sparc.cpp.//// - the biased lock pattern is used to bias a lock toward a given// thread. When this pattern is set in the low three bits, the lock// is either biased toward a given thread or &quot;anonymously&quot; biased,// indicating that it is possible for it to be biased. When the// lock is biased toward a given thread, locking and unlocking can// be performed by that thread without using atomic operations.// When a lock's bias is revoked, it reverts back to the normal// locking scheme described below.//// Note that we are overloading the meaning of the &quot;unlocked&quot; state// of the header. Because we steal a bit from the age we can// guarantee that the bias pattern will never be seen for a truly// unlocked object.//// Note also that the biased state contains the age bits normally// contained in the object header. Large increases in scavenge// times were seen when these bits were absent and an arbitrary age// assigned to all biased objects, because they tended to consume a// significant fraction of the eden semispaces and were not// promoted promptly, causing an increase in the amount of copying// performed. The runtime system aligns all JavaThread* pointers to// a very large value (currently 128 bytes (32bVM) or 256 bytes (64bVM))// to make room for the age bits &amp; the epoch bits (used in support of// biased locking), and for the CMS &quot;freeness&quot; bit in the 64bVM (+COOPs).//// [JavaThread* | epoch | age | 1 | 01] lock is biased toward given thread// [0 | epoch | age | 1 | 01] lock is anonymously biased//// - the two lock bits are used to describe three states: locked/unlocked and monitor.//// [ptr | 00] locked ptr points to real header on stack// [header | 0 | 01] unlocked regular object header// [ptr | 10] monitor inflated lock (header is wapped out)// [ptr | 11] marked used by markSweep to mark an object// not valid at any other time//// We assume that stack/thread pointers have the lowest two bits cleared.class markOopDesc: public oopDesc { private: // Conversion uintptr_t value() const { return (uintptr_t) this; } public: // Constants enum { age_bits = 4, lock_bits = 2, biased_lock_bits = 1, max_hash_bits = BitsPerWord - age_bits - lock_bits - biased_lock_bits, hash_bits = max_hash_bits &gt; 31 ? 31 : max_hash_bits, cms_bits = LP64_ONLY(1) NOT_LP64(0), epoch_bits = 2 }; // The biased locking code currently requires that the age bits be // contiguous to the lock bits. enum { lock_shift = 0, biased_lock_shift = lock_bits, age_shift = lock_bits + biased_lock_bits, cms_shift = age_shift + age_bits, hash_shift = cms_shift + cms_bits, epoch_shift = hash_shift }; enum { lock_mask = right_n_bits(lock_bits), lock_mask_in_place = lock_mask &lt;&lt; lock_shift, biased_lock_mask = right_n_bits(lock_bits + biased_lock_bits), biased_lock_mask_in_place= biased_lock_mask &lt;&lt; lock_shift, biased_lock_bit_in_place = 1 &lt;&lt; biased_lock_shift, age_mask = right_n_bits(age_bits), age_mask_in_place = age_mask &lt;&lt; age_shift, epoch_mask = right_n_bits(epoch_bits), epoch_mask_in_place = epoch_mask &lt;&lt; epoch_shift, cms_mask = right_n_bits(cms_bits), cms_mask_in_place = cms_mask &lt;&lt; cms_shift }; const static uintptr_t hash_mask = right_n_bits(hash_bits); const static uintptr_t hash_mask_in_place = hash_mask &lt;&lt; hash_shift; // Alignment of JavaThread pointers encoded in object header required by biased locking enum { biased_lock_alignment = 2 &lt;&lt; (epoch_shift + epoch_bits) }; enum { locked_value = 0, unlocked_value = 1, monitor_value = 2, marked_value = 3, biased_lock_pattern = 5 }; enum { no_hash = 0 }; // no hash value assigned enum { no_hash_in_place = (address_word)no_hash &lt;&lt; hash_shift, no_lock_in_place = unlocked_value }; enum { max_age = age_mask }; enum { max_bias_epoch = epoch_mask }; // Biased Locking accessors. // These must be checked by all code which calls into the // ObjectSynchronizer and other code. The biasing is not understood // by the lower-level CAS-based locking code, although the runtime // fixes up biased locks to be compatible with it when a bias is // revoked. bool has_bias_pattern() const { return (mask_bits(value(), biased_lock_mask_in_place) == biased_lock_pattern); } ......} java 对象头中 Mark Word 与 synchronized 锁升级降级关系密切，源码里面的注释也说得很清楚了，示意图如下： epoch 是偏向锁的时间戳 关于 synchronized 的锁升级和降级以及跟 Mark Word 的关系借用网上的一张图： 关于并发这块，后续再详细讨论。 Metadata对象头的第二部分就是元数据指针，从基类 oopDesc 结构中可以看到，如果开启了压缩指针 JVM 参数，那么就是 _compressed_klass，未开启就是 _klass，这个指针就是指向在类加载阶段生成的 InstanceKlass 对象，指针大小是 8 个字节。在 Hotspot 中，默认开启了压缩指针的选项 -XX:+UseCompressedClassPointers，所以类指针占 4 个字节。那么默认情况下，一个对象的头就占了 8+4=12 个字节。 数组长度（可能会有）如果是数组对象，那么对象头里面还有数组长度。 计算一个对象大小计算了一个对象的大小，实际上就是计算（对象头大小 + 实例数据大小 + 对齐填充字节大小）的总大小。所以从上面的对象头的描述可以知道，一个对象头最小的大小是 12 个字节，因为 Hotspot 的对齐填充的要求必须是 8 字节的整数倍，所以需要填充 4 个字节对齐，所以一个对象大小最小值就是： 16 字节 对象的对齐填充，并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用，Hotspot 要求对象起始地址必须是 8 字节的倍数，也就是说对象大小必须是 8 字节的整数倍。 下面通过 java 的 java.lang.Instrumentation 类才打印出一个 object 的大小，Instrumentation 是 jdk1.5 添加的一个辅助类，用来调试或者增加 Java 程序代码的类，也就是 -javaagent，像 pinpoint 开源监控组件也是采用这种方式实现，原理就是插入额外的字节码来实现收集数据的服务，比如监控代理、事件日志记录等，增强服务的字节码不会影响程序的正常行为。 定义一个 java agentjava 命令有一个选项 -javaagent:&lt;jarpath&gt;，可以指定一个 jar 包作为代理，但是必须要符合 2 点： jar 包的 MENIFEST.MF 文件必须指定 Premain-Class 项，实际上就是一个类。 Premain-Class 指向的那个类要实现 premain() 方法。 premain() 就是运行在 main 之前的方法，JVM 启动后，先运行 premain() 方法，然后再去运行 main() 方法。 在 Instrumentation 类的实现类中也有说明： InstrumentationImpl.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class InstrumentationImpl implements Instrumentation { ...... // WARNING: the native code knows the name &amp; signature of this method private void loadClassAndCallPremain(String classname, String optionsString) throws Throwable { loadClassAndStartAgent( classname, &quot;premain&quot;, optionsString ); } // Attempt to load and start an agent private void loadClassAndStartAgent( String classname, String methodname, String optionsString) throws Throwable { ClassLoader mainAppLoader = ClassLoader.getSystemClassLoader(); Class&lt;?&gt; javaAgentClass = mainAppLoader.loadClass(classname); Method m = null; NoSuchMethodException firstExc = null; boolean twoArgAgent = false; // The agent class must have a premain or agentmain method that // has 1 or 2 arguments. We check in the following order: // // 1) declared with a signature of (String, Instrumentation) // 2) declared with a signature of (String) // 3) inherited with a signature of (String, Instrumentation) // 4) inherited with a signature of (String) // // So the declared version of either 1-arg or 2-arg always takes // primary precedence over an inherited version. After that, the // 2-arg version takes precedence over the 1-arg version. // // If no method is found then we throw the NoSuchMethodException // from the first attempt so that the exception text indicates // the lookup failed for the 2-arg method (same as JDK5.0). try { m = javaAgentClass.getDeclaredMethod( methodname, new Class&lt;?&gt;[] { String.class, java.lang.instrument.Instrumentation.class } ); twoArgAgent = true; } catch (NoSuchMethodException x) { // remember the NoSuchMethodException firstExc = x; } if (m == null) { // now try the declared 1-arg method try { m = javaAgentClass.getDeclaredMethod(methodname, new Class&lt;?&gt;[] { String.class }); } catch (NoSuchMethodException x) { // ignore this exception because we'll try // two arg inheritance next } } if (m == null) { // now try the inherited 2-arg method try { m = javaAgentClass.getMethod( methodname, new Class&lt;?&gt;[] { String.class, java.lang.instrument.Instrumentation.class } ); twoArgAgent = true; } catch (NoSuchMethodException x) { // ignore this exception because we'll try // one arg inheritance next } } if (m == null) { // finally try the inherited 1-arg method try { m = javaAgentClass.getMethod(methodname, new Class&lt;?&gt;[] { String.class }); } catch (NoSuchMethodException x) { // none of the methods exists so we throw the // first NoSuchMethodException as per 5.0 throw firstExc; } } // the premain method should not be required to be public, // make it accessible so we can call it // Note: The spec says the following: // The agent class must implement a public static premain method... setAccessible(m, true); // invoke the 1 or 2-arg method if (twoArgAgent) { m.invoke(null, new Object[] { optionsString, this }); } else { m.invoke(null, new Object[] { optionsString }); } // don't let others access a non-public premain method setAccessible(m, false); } ......} 所以，定义个类来实现 premain() 方法，逻辑就是调用 Instrumentation 类的 getObjectSize() 获取对象大小的方法， 如下： 12345678910111213public class ObjectSizeAgent { private static Instrumentation inst; public ObjectSizeAgent() {} public static void premain(String agentArgs, Instrumentation _inst) { inst = _inst; } public static long sizeOf(Object o) { return inst.getObjectSize(o); }} 上面的方法很简单，接下来就是使用 java agent 了。 使用 java agent使用一个 javaagent 的主要步骤如下： 1.自定义 MANIFEST.MF 文件，然后添加 Premain-Class 项 可以使用 maven 自定义创建 MANIFEST.MF的选项。在我的工程里面，新建了一个子模块 object-agent，在 pom.xml 文件加入自定义 manifest 的配置： 123456789101112131415161718192021222324252627282930313233343536&lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;manifest.version&gt;1.0&lt;/manifest.version&gt; &lt;created.by&gt;caolizhi&lt;/created.by&gt; &lt;premain.class&gt;top.caolizhi.example.jvm.agent.ObjectSizeAgent&lt;/premain.class&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--跳过 spring 打包，子模块只当做工具类使用--&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Manifest-Version&gt;${manifest.version}&lt;/Manifest-Version&gt; &lt;Created-By&gt;${created.by}&lt;/Created-By&gt; &lt;Premain-Class&gt;${premain.class}&lt;/Premain-Class&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 2.创建 Premain-Class 指定的类，然后实现 premain() 方法上面已经实现了该方法，这里忽略。 3.将类和MANIFEST.MF 文件打包成 jar 包直接执行 maven 的 clean package 的命令，会生成一个 object-agent-0.0.1-SNAPSHOT.jar 包。可以看到 Premian-Class 的选项。 4.使用 -javaagent:&quot;jar 路径&quot; 启动代理 定义一个测试类，并且导入 object-agent 的 jar 依赖。我本地定义在 jmm 子模块里面。 如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 public class SizeOfAnObject { public static void printObjectSize(Object object) { System.out.println(&quot;Object type: &quot; + object.getClass() + &quot;, size: &quot; + ObjectSizeAgent.sizeOf(object) + &quot; bytes.&quot;); } public static void main(String[] args) { /** VM Option:（-XX:+UseCompressedClassPointers 默认开启） * ① 对象头 8 + 4 = 12 字节 * - mark word 8 字节 * - class pointer 4 字节 * ② 实例数据： 0 字节 * * ③ padding： 4 字节 * =============总共：16 字节================== */ /**VM Option:（-XX:-UseCompressedClassPointers 不开启） * ① 对象头 8 + 8 = 16 字节 * - mark word 8 字节 * - class pointer 8 字节 * ② 实例数据： 0 字节 * ③ padding： 0 字节 * =============总共：16 字节================== */ printObjectSize(new Object()); /** VM Option:（-XX:+UseCompressedClassPointers 默认开启） * ① 对象头 8 + 4 = 12 字节 * - mark word 8 字节 * - class pointer ** 4 ** 字节 * ② 数组长度：4 字节 * ③ 实例数据： 0 字节 * ④ padding： 0 字节 * =============总共：16 字节================== */ /** VM Option:（-XX:-UseCompressedClassPointers 不开启） * ① 对象头 8 + 8 = 16 字节 * - mark word 8 字节 * - class pointer ** 8 ** 字节 * ② 数组长度：4 字节 * ③ 实例数据： 0 字节 * ④ padding： 4 字节 * =============总共：24 字节================== */ printObjectSize(new int[]{}); /** VM Option:（-XX:+UseCompressedClassPointers 默认开启） * ① 对象头 8 + 4 = 12 字节 * - mark word 8 字节 * - class pointer 4 字节 * ② 实例数据：14 字节 * ③ padding： 6 字节 * =============总共：32 字节================== */ /** VM Option:（-XX:-UseCompressedClassPointers 不开启） * ① 对象头 8 + 8 = 16 字节 * - mark word 8 字节 * - class pointer 8 字节 * ② 实例数据：14 字节 * ③ padding： 2 字节 * =============总共：32 字节================== */ printObjectSize(new T()); } private static class T { // 8 mark word // 4 class pointer， -XX:+UseCompressedClassPointers 开启占4字节，未开启8字节 int id; // 4 String name; // 4 ops = ordinary object pointers， -XX:+UseCompressedOops 引用类型变量的字节大小，开启占4字节，未开启8字节， int age; // 4 byte b1; // 1 byte b2; // 1 }} 打印结果： 123Object type: class java.lang.Object, size: 16 bytes.Object type: class [I, size: 16 bytes.Object type: class top.caolizhi.example.jvm.jmm.object.SizeOfAnObject$T, size: 32 bytes. 上面的代码里面已经写得很清楚了，在开启压缩指针选项和不开启压缩指针的情况下，对象大小变化。 以上就是一个 java 对象的结构以及大小计算。用一个示意图总结如下： 参考 代码地址：caolizhi/jvm 《深入理解 Java 虚拟机（第3版）》 周志明著. 《揭秘 Java 虚拟机：JVM 设计原理与实现》 封亚飞著.","link":"/2022-01-JVM%E7%B3%BB%E5%88%97-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/"},{"title":"JVM系列 —— GC基础","text":"这是 JVM 系列的第十篇，见 JVM 系列。 写在前面前面的几篇文章分享了，JVM 的大概的流程，就差编译器和执行引擎这两部分，这两部分比较高级，大概有个了解就行。接下来的几篇主要学习和分享一下 JVM 的垃圾收集机制。 哪些内存需要回收在前面分享的文章中，JVM 运行时数据区域从随线程而创建和随进程而创建，随线程启动而创建的包括程序计数器、Java栈（Java 方法栈）、虚拟机栈（本地方法栈），随着进程启动而创建的区域包括Java堆、方法区。对于随线程启动而创建的部分，实际上并不需要太多的关注，因为这些区域的内存分配和回收都是确定的，当方法或者是线程结束时，内存自然也就释放了，所以内存分配和回收的关键区域在于 Java堆和方法区，而且在 JVM 运行期间才知道创建了哪些对象，并且这两个区域还是线程共享的，不同的线程对于对象的引用也是在不同的时机触发，复杂度也就产生了。垃圾收集器关注的也是这些部分的内存该如何管理。 对于Java堆和方法区的内存怎么释放的问题，先思考一下Java堆和方法区里面放的是什么东西，首先 Java堆存放的是对象，方法区在 jdk1.8 的实现是存放的是类的元数据，包括类名、访问修饰符、常量池、字符描述、方法描述等，从 jdk7 起，字符串的常量池和静态变量已经迁移放到Java堆中了，不再放在永久代，并且 jdk1.8 取消了永久代（PermGen），换成了元空间（Metaspace），元空间只存储类的结构信息。 因为Java堆中的对象都被变量所引用，所以找出那些没有被变量所引用的对象，将其回收，而变量引用基本上存在于Java栈中，如果调用的是本地方法，那么还有会本地方法栈引用的对象。并且字符串常量池也会在运行时可能有所增加，比如 String.intern() 方法的调用，运行时的字符串常量池也有可能引用对象，还有静态变量引用的对象，这两种引用的对象逻辑上属于”方法区“。这里其实是在分析 GC Roots 的路径。 对方法区垃圾收集的性价比是比较低的。而对于这部分区域的垃圾回收主要两部分：一部分是常量池里面废弃的常量以及不再使用的类的类型。对于废弃的常量指没有一个引用指向常量池里面的字面量，可以清理出常量池。而不再使用的类型可以参考《深入理解Java虚拟机》里面所说，需要同时满足三个条件： 该类的所有实例都已经被回收 该类的类加载器已经被回收，比如 OSGi 等 该类对应的 java.lang.Class 对象没有在任何地方被引用 所以要回收的区域主要在Java堆上，元空间存储的是类结构信息，并且其大小跟本地内存的大小有关。下面就是要讨论一下什么时候回收。 什么时候回收我们已经知道Java堆和方法区存储的内容，那么接下来就是要了解什么时候要回收了。实际上也就是说一个对象在什么样的情况下变成了垃圾，可以被回收了。就不得不提对象存活的判断，JVM 使用的是可达性分析算法，通过 GC Roots 为根节点集，通过引用关系不断向下搜索，搜索过的路径为“引用链（Reference Chain）”，当某个对象不可达时，就表明这个对象不再使用了。 &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 如何回收上面的讨论，我们知道哪些内存需要回收，并且这内存区域的对象也已经被标记了，那么怎么有效的去把这些区域对象清理？因为我们需要考虑下程序执行的时间，垃圾回收的延迟等。一般而言，大多数 JVM 的垃圾收集器都遵循的是“分代收集”理论。分代收集并不是一种算法，而是一种理论基石，实质上是一套符合大多数程序运行实际情况的经验法则，这种经验法则建立在两种假说之上： 1.弱分代假说（Weak Generational Hypothesis）：大部分的对象都是朝生夕死的。 2.强分代假说（Strong Generational Hypothesis）：经历越多的垃圾回收次数的对象，就越难以消亡。 根据这两种假说，把内存区域进行了划分，分为年轻代和老年代，年轻代中的对象大多数都会很快被回收，在经历了多次回收后仍在存活的对象就会进入老年代（经历过 15 次垃圾回收的对象）。虽然划分内存区域很容易，但是对象并不是孤立的，如果说老年代的对象引用了新生代的对象怎么办？或者新生代对象引用了老年代的对象？也就是存在跨代引用的问题。这就需要第三条经验法则： 3.跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅仅占极少数。 对于老年代的对象会引用新生代的对象这种情况，由于老年代的对象很难消除，那么引用的新生代的对象会经历多次回收而达到进入老年代的条件，那么跨代引用也就消除了；而对于新生的对象引用的老年代的这种情况，收集新生代的对象时候，为了少量的跨代引用去扫描一边老年代对象的话，那效率就降低了，并且还要增加空间去记录那些对象有跨代引用。所以在新生代里面建立一个新的数据结构，称作“记忆集”（RememberSet），这个结构把老年代划分成若干块，标识出老年代的哪一块的内存有跨代引用。那么在 Minor GC 的时候，那些存在跨代引用的内存里面对象才会被加到 GC Roots 里面进行扫描。这种方案比起扫描整个老年代来说是划算的。 所以针对上面的假说，根据不同的区域的特点，出现了不同的垃圾回收算法。 标记-清除标记所有需要回收的对象，然后再统一进行清理回收。 这个算法有两个缺点， 一个是执行效率不稳定，如果堆里面的对象非常多，并且大部分是需要回收的，这时候就需要进行大量的标记和清除，这就会导致执行效率因为对象的增长而降低。另外一个是产生很多内存碎片，后续如果分配的对象过大，因为连续的内存不够，导致无法分配，就会提前触发再一次的垃圾回收。 标记-复制将内存区域划分成等量的两块，每次只使用一块，垃圾回收是，把使用中的这块内存存活的对象复制到空闲的一块内存上，然后再把之前使用的那半块全部一次性清空。这样可以解决标记-清除算法中存在执行效率低的缺点。但是牺牲的代价是内存减半，有点空间换时间的意思。如果存活的对象很多，那么也会耗费时间去复制这些对象，效率也会降低。 就 Hotspot 而言，把内存区域分成了新生代和老年代，而新生代就是采用了标记复制算法，并且新生代又分为 Eden 和 Survivor 区域，比例为 8:1，所以实际上并不是减半分离，只占了 10%，因为大部分的对象基本上在第一轮垃圾收集中被回收。但是始终会有极端情况，万一存活的对象 Survivor 区域放不下呢？那么会直接进入老年代，这种情况叫分配担保。 标记-整理标记整理的标记处理和标记清除的算法是一样的，只不过标记之后，存活的对象向内存空间一段移动，然后再直接清除调边界以外的内存。 所以标记清除和标记整理算法之间，就是不移动和移动的区别，如果不移动，那么就会产生内存碎片；如果移动，那么对象的引用就会改变，需要停顿用户线程来重新引用赋值，这种停顿就是所谓的 STW（“Stop The World”）。当然不移动的情况下，清除的操作也是需要停顿的，但是相对而言，标记清除的停顿时间比标记整理的停顿时间要少一些，也就是说垃圾收集的效率要高一些。但是毕竟内存的访问和分配频率始终比垃圾清理的频率要高，所以内存的碎片化问题导致这部分的耗时要高，导致的整体的吞吐量降低，即用标记整理算法的垃圾回收器要比使用标记清除的吞吐量要高，同样的，用标记整理算法的垃圾回收器要比使用标记清除的延迟要高。那么在实际使用合适的垃圾回收器时，需要根据场景进行选择，如果更关注吞吐量的话，选择用标记整理算法实现的垃圾回收器；如果更关注延迟的话，选用标记清除算法实现的垃圾回收器。Hotspot 里面 Parallel Scavenge（PS）垃圾回收器就是使用的标记整理，而 CMS 收集器采用的标记清除算法。 &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;运行用户代码的时间 吞吐量 = —————————————————————————————————— &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;运行用户代码的时间 + 运行垃圾回收的时间 GC 的类型 部分收集（Partial GC）: 不是完整的对整个 Java 堆进行垃圾收集，又分为： 新生代收集（Young GC）：新生代的垃圾回收 老年代收集（Major GC / Old GC）：老年代的垃圾回收，只有 CMS 会有单独的回收老年代的行为。 混合收集（Mixed GC）： 新生代和部分老年代的垃圾回收，只有 G1 有这种收集。 整堆收集（Full GC）：对整个 Java 堆和方法区进行垃圾收集","link":"/2022-01-JVM%E7%B3%BB%E5%88%97-GC%E5%9F%BA%E7%A1%80/"},{"title":"Spring Batch Mysql Schema","text":"概览spring batch 框架有自己的一套表结构，基本上跟和 java 对象相对应。 表名称 Java对象 BATCH_JOB_INSTANCE JobInstance BATCH_JOB_EXECUTION JobExecution BATCH_JOB_EXECUTION_PARAMS JobParameters BATCH_STEP_EXECUTION StepExecution BATCH_JOB_EXECUTION_CONTEXT, BATCH_STEP_EXECUTION_CONTEXT ExecutionContext ERD 如下： 这些表结构的初始化脚本在包 org.springframework.batch.core 包下。 几点说明关于 Version 字段spring batch 中 BATCH_JOB_INSTANCE，BATCH_JOB_EXECUTION，BATCH_STEP_EXECUTION 三张表的 update 操作都使用了乐观锁的机制，通过 VERSION 字段来控制。主要是用来不同的 job 在不同的机器上运行，但是使用的是相同的数据库。 关于 Id 字段表 BATCH_JOB_INSTANCE，ATCH_JOB_EXECUTION 以及 BATCH_STEP_EXECUTION 都包含一个一 _ID 后缀结尾的字段，这些其实充当的就是自增主键。只不过自增的机制不是通过数据库自动创建的，而是通过 sequence 手动创建的自增。 就是说这三张表 BATCH_JOB_SEQ，BATCH_JOB_EXECUTION_SEQ 和 BATCH_STEP_EXECUTION_SEQ 是用来给表BATCH_JOB_INSTANCE，BATCH_JOB_EXECUTION以及 BATCH_STEP_EXECUTION 创建自增主键的的作用。在 spring batch 中的实现类是 MySQLMaxValueIncrementer.java 表结构BATCH_JOB_INSTANCE123456CREATE TABLE BATCH_JOB_INSTANCE ( JOB_INSTANCE_ID BIGINT PRIMARY KEY , VERSION BIGINT, JOB_NAME VARCHAR(100) NOT NULL , JOB_KEY VARCHAR(2500)); 关于 JobInstance 的信息，spring batch 的顶层对象。各个字段解释如下： JOB_INSTANCE_ID 主键 VERSION 乐观锁字段 JOB_NAME job 名称，从 Job 对象拿到该值 JOB_KEY 区分不同 job 的 序列化的 hash 值，根据 job 的 name 和 job 的 JobParameters 共同计算得到，如果相同名称，但是参数不同，那么 Job_KEY 就是不同的，否则是相同的。 BATCH_JOB_EXECUTION123456789101112131415CREATE TABLE BATCH_JOB_EXECUTION ( JOB_EXECUTION_ID BIGINT PRIMARY KEY , VERSION BIGINT, JOB_INSTANCE_ID BIGINT NOT NULL, CREATE_TIME TIMESTAMP NOT NULL, START_TIME TIMESTAMP DEFAULT NULL, END_TIME TIMESTAMP DEFAULT NULL, STATUS VARCHAR(10), EXIT_CODE VARCHAR(20), EXIT_MESSAGE VARCHAR(2500), LAST_UPDATED TIMESTAMP, JOB_CONFIGURATION_LOCATION VARCHAR(2500) NULL, constraint JOB_INSTANCE_EXECUTION_FK foreign key (JOB_INSTANCE_ID) references BATCH_JOB_INSTANCE(JOB_INSTANCE_ID)) ; 关于 JobExecution 对象的相关信息。每一个 Job 对象的运行，都会产生一个 JobExecution 对象，也就是在这个表里面插入一条记录。字段解释： JOB_EXECUTION_ID: 主键 VERSION: 乐观锁字段 JOB_INSTANCE_ID: BATCH_JOB_INSTANCE 表的外键，表明这个是属于哪个 Job 的。一个 Job 会对应多个 execution 的数据，JobInstance 和 JobExecution 是一对多的关系。 CREATE_TIME: execution 创建时间 START_TIME: execution 开始时间 END_TIME: execution 完成时间，如果有不可避免的错误，这里可能为空 STATUS: execution 的状态，可能有 COMPLETED, STARTED 以及其他，具体参考类 BatchStatus。 EXIT_CODE: execution 退出代码字符，如果是命令行启动的 job，可能是数字。 EXIT_MESSAGE: 退出的原因，正常完成 job 是空的，失败的 job 会详细记录原因。 LAST_UPDATED: 上一次执行的时间，存在多次执行同一个 job的情况。 BATCH_JOB_EXECUTION_PARAMS123456789101112CREATE TABLE BATCH_JOB_EXECUTION_PARAMS ( JOB_EXECUTION_ID BIGINT NOT NULL , TYPE_CD VARCHAR(6) NOT NULL , KEY_NAME VARCHAR(100) NOT NULL , STRING_VAL VARCHAR(250) , DATE_VAL DATETIME DEFAULT NULL , LONG_VAL BIGINT , DOUBLE_VAL DOUBLE PRECISION , IDENTIFYING CHAR(1) NOT NULL , constraint JOB_EXEC_PARAMS_FK foreign key (JOB_EXECUTION_ID) references BATCH_JOB_EXECUTION(JOB_EXECUTION_ID)); 关于 JobParameters 对象的相关信息，键值对的方式。这个表存放的数据一个非规范化的数据。 JOB_EXECUTION_ID: BATCH_JOB_EXECUTION 表的外键，表示这一条数据是属于哪一个 job 的。如果 JobParameters 有两个键值对的话，那么就会生成两条数据，对应同一个 BATCH_JOB_EXECUTION 表中的 JOB_EXECUTION_ID TYPE_CD: 表示这个 job 参数的类型，支持四种类型 string，date，long，double KEY_NAME: job 参数的 key STRING_VAL: 如果参数的值是 string 类型的，那么会存在这个字段 DATE_VAL: 如果参数的值是 date 类型的，那么会存在这个字段 LONG_VAL: 如果参数的值是 long 类型的，那么会存在这个字段 DOUBLE_VAL: 如果参数的值是 double 类型的，那么会存在这个字段 IDENTIFYING: 这是个布尔类型，跟上面 BATCH_JOB_INSTANCE 表中的 JOB_KEY 相关。表示是否贡献于 JobInstance 的识别。 注意：这个表是没有主键字段的，官网说明，框架本身不会使用这个表的主键，觉得没有必要增加主键字段，所以没有创建。 但是如果在 mysql 8.0.12 及以上版本运行 job 的时候会报错，因为不允许将数据插入到没有主键的表中。所以需要加上一个主键字段（id），不会影响 spring batch 的运行。 BATCH_STEP_EXECUTION12345678910111213141516171819202122CREATE TABLE BATCH_STEP_EXECUTION ( STEP_EXECUTION_ID BIGINT PRIMARY KEY , VERSION BIGINT NOT NULL, STEP_NAME VARCHAR(100) NOT NULL, JOB_EXECUTION_ID BIGINT NOT NULL, START_TIME TIMESTAMP NOT NULL , END_TIME TIMESTAMP DEFAULT NULL, STATUS VARCHAR(10), COMMIT_COUNT BIGINT , READ_COUNT BIGINT , FILTER_COUNT BIGINT , WRITE_COUNT BIGINT , READ_SKIP_COUNT BIGINT , WRITE_SKIP_COUNT BIGINT , PROCESS_SKIP_COUNT BIGINT , ROLLBACK_COUNT BIGINT , EXIT_CODE VARCHAR(20) , EXIT_MESSAGE VARCHAR(2500) , LAST_UPDATED TIMESTAMP, constraint JOB_EXECUTION_STEP_FK foreign key (JOB_EXECUTION_ID) references BATCH_JOB_EXECUTION(JOB_EXECUTION_ID)); 关于 StepExecution 对象的信息，和表 BATCH_JOB_EXECUTION 有很多相同的字段，并且含义都差不多。每一个 JobExecution 的创建都会至少创建一个 Step。 STEP_EXECUTION_ID: 主键 VERSION: 乐观锁字段 STEP_NAME: step 名称 JOB_EXECUTION_ID: BATCH_JOB_EXECUTION 表的外键，表示这个 step 是哪一个 job 的，JobExecution 可能只有一个给定的 step 名称的 StepExecution。 START_TIME: step execution 开始时间 END_TIME: step execution 结束时间，有可能因为报错导致为空。 STATUS: execution 的状态，可能有 COMPLETED, STARTED 以及其他，具体参考类 BatchStatus。 COMMIT_COUNT: 提交事务的数量 READ_COUNT: reader 里面读取到的 item 的数量 FILTER_COUNT: 过滤的 item 的数量 WRITE_COUNT: item 写的数量 READ_SKIP_COUNT: 读 item 的时候，跳过的数量 WRITE_SKIP_COUNT: 写 item 的时候，跳过的数量 PROCESS_SKIP_COUNT: 处理 item 的时候，跳过的数量 ROLLBACK_COUNT: 回滚的数量，每一次回滚发生就记录一次， 包括 retry 的时候发生的回滚以及 recover 处理逻辑里面的混滚。 EXIT_CODE: execution 退出代码字符，如果是命令行启动的 job，可能是数字。 EXIT_MESSAGE: 退出的原因，正常完成 job 是空的，失败的 job 会详细记录原因。 LAST_UPDATED: 上一次执行的时间，存在多次执行同一个 job的情况。 BATCH_JOB_EXECUTION_CONTEXT12345678CREATE TABLE BATCH_JOB_EXECUTION_CONTEXT ( JOB_EXECUTION_ID BIGINT PRIMARY KEY, SHORT_CONTEXT VARCHAR(2500) NOT NULL, SERIALIZED_CONTEXT CLOB, constraint JOB_EXEC_CTX_FK foreign key (JOB_EXECUTION_ID) references BATCH_JOB_EXECUTION(JOB_EXECUTION_ID)); 关于Job 的 ExecutionContext 对象信息。Job ，ExecutionContext 以及 JobExecution 三者都是一一对应的关系。典型的应用场景是，当 JobInstance 执行失败，但是又不想重头开始执行，那么这个表的数据就可以用来继续执行。 JOB_EXECUTION_ID: JobExecution 表的外键，这个 context 属于哪一个 job 的。可能存储在多行数据关联一个 execution。 SHORT_CONTEXT: SERIALIZED_CONTEXT 的字符串，比如：{&quot;@class&quot;:&quot;java.util.HashMap&quot;} SERIALIZED_CONTEXT: 序列化的上下文 BATCH_STEP_EXECUTION_CONTEXT1234567CREATE TABLE BATCH_STEP_EXECUTION_CONTEXT ( STEP_EXECUTION_ID BIGINT PRIMARY KEY, SHORT_CONTEXT VARCHAR(2500) NOT NULL, SERIALIZED_CONTEXT CLOB, constraint STEP_EXEC_CTX_FK foreign key (STEP_EXECUTION_ID) references BATCH_STEP_EXECUTION(STEP_EXECUTION_ID)); 关于 Step 的 ExecutionContext 的对象。 每一个 StepExecution 仅对应一个 ExecutionContext 。包含所有需要持久化的数据，典型的应用场景也是“断线重连”的感觉。 STEP_EXECUTION_ID: StepExecution 表的外键，表明这个 context 属于哪一个 step。可能存储在多行数据关联一个 execution。 SHORT_CONTEXT: SERIALIZED_CONTEXT 的字符串 12345678910{ &quot;@class&quot;: &quot;java.util.HashMap&quot;, &quot;JdbcPagingItemReader.start.after&quot;: { &quot;@class&quot;: &quot;java.util.LinkedHashMap&quot;, &quot;project_key&quot;: &quot;Pd8608197e0aa7_test-webapp&quot;}, &quot;JdbcPagingItemReader.read.count&quot;: 259, &quot;batch.taskletType&quot;: &quot;org.springframework.batch.core.step.item.ChunkOrientedTasklet&quot;, &quot;batch.stepType&quot;: &quot;org.springframework.batch.core.step.tasklet.TaskletStep&quot;} SERIALIZED_CONTEXT: 序列化的上下文， CLOB 类型。","link":"/2022-04-spring-batch-mysql-schema/"},{"title":"Webflux 介绍","text":"Webflux目的与用户打交道 why created?1.基于函数式编程2.使用固定的线程和硬件资源处理并发 两种编程模型 基于注解的 controller 函数式端点Functional Endpoints Router与Handler RouterFunctions可以产生Router和Handler对象， RouterFunctions对标@Controller中的注解 Router相当于@RequestMapping Handler相当于Controller中的方法 ServerRequest和ServerResponse SpringMVC中使用的是HTTPServletRequest webFlux + SpringMVC 使用的是ServerHTTPRequest WebFlux+ 响应式 使用的是 ServerRequest 和 Spring MVC 区别IO 密集度较高，使用性能较好 使用 netty 作为 web 容器 基于注解的 WebFlux 阻塞式与响应式实现 WebFlux + SSE 服务器推 传统的SpringMVC注解与WebFlux通用，区别在于底层实现，WebFlux 中的 ServerHttpRequest 与 SpringMVC HTTPServletRequest 的区别 官网建议 如果 Spring MVC 用的好好的，不需要切换，命令式更好写，懂，debug 微服务架构，可以混合使用 如果使用了阻塞的持久化框架，如 JPA,JDBC，最好的选择就是 Spring MVC 陡峭的学习路线 处理请求类 HttpHandler 非阻塞 http 请求处理 WebHandler 高级一点，web api 的请求处理 WebSocket vs. HTTP http 只能由客户端发起连接，服务端作出响应 无状态：每次连接处理一个请求，请求结束后断开连接 无连接： 对于事务处理没有记忆能力，服务器不知道客户端是什么状态 缺陷：通信只能由客户端发起，如果服务器有连续的变化，客户端很难得知 基于http实现即时通讯 轮询: ajax 长轮询： ajax 请求，服务器 hold 住连接 长连接： 嵌入 iframe，长连接的请求，服务器不断输入数据 Flash Socket：内嵌 socket 类的 flash 程序，js 调用 flash，socket 通信 websockets 2008 诞生，2011 成为标准，浏览器支持 服务器主动向客户端推送消息，客户端也可以主动向服务器发送信息，全双工通信 建立握手连接是通过 http 传输的，建立之后，传输不需要 http 协议","link":"/2021-08-Webflux-%E4%BB%8B%E7%BB%8D/"},{"title":"MySQL系列——MySQL的执行计划","text":"基于 MySQL 8.0 community 的版本 EXPLAIN 摘要用 EXPLAIN 来可以拿到 MySQL 是怎样执行 SQL 语句的。EXPLAIN 会返回一个表，表中的每一行都表示一个 select 语句的执行的信息。 为了更生动的说明这个 MySQL 的执行计划，我用具体的例子阐述，我在本地建一个叫 school 的数据库，并建立 4 张表，分别是学生表，教师表， 分数表，课程表，写一些测试数据进去。 执行脚本文章末尾。 EXPLAIN 输出的格式说明有的测试的数据库，现在我们针对 EXPLAIN 的输出做出一些说明和描述，理解一下 MySQL 的执行计划。我们可以简单执行一下 SQL 语句：explain select * from student;输出如下： idid 就是生成的 select 查询的序号，如果 id 号相同，则从上往下执行；如果 id 不同，id 越大，优先级越高，越先被执行。比如： select_typeselect_type 主要是用来分辨查询的类型，是普通查询还是联合查询还是子查询，又有以下几种类型： SIMPLE：简单的查询，不包含子查询和 union 查询 PRIMARY：查询中若包含任何复杂的子查询，最外层查询则被标记为 PRIMARY UNION：第二个或者之后的 select 查询标记为 UNION DEPENDENT UNION：跟 UNION 类似，dependent 表示 union 或 union all 联合而成的结果会受到外部表影响 UNION RESULT：从 union 表获取结果的 select SUBQUERY：在 select 或者 where 列表中包含子查询 子查询等于一个值得时候就是 subquery DEPENDENT SUBQUERY： SUBQUERY 的子查询要受到外部表查询的影响 子查询返回的是值得集合就是 DEPENDENT SUBQUERY DERIVED：衍生，from 子句中出现的子查询，也叫派生类 DEPENDENT DERIVED：DERIVED 的子查询受到外部衍生表的影响 MATERIALIZED：物化子查询,子查询来自视图 UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被换缓存 UNCACHEABLE UNION：表示使用 union 的查询的结果不能被缓存 partitions分区，分库分表才会有该值 table对应行正在访问哪一个表，表名或者别名，可能还是临时表或者 union 合并的结果集。如果是具体的表名，则是从物理表中获取的数据；如果是类似 derivedN 的形式，表示使用了 id 为 N 的查询产生的衍生表；当有 union 结果集的时候，表名是 union n1,n2 等形式，n1,n2 表示参与 union 的 id； type表示 MySQL 在表中找到所需行的方式，或者叫访问类型，常见的类型有以下几种，从上到下性能依次到好 ALL:全表扫描 index:索引全扫描，遍历整个索引来查询匹配的行主要有两种情况：一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取；另外一种是使用了索引进行排序，这样就避免数据的重排序； range:表示利用索引查询的时候限制了范围，在指定范围内进行查询，避免了 index 的全索引扫描。适用的操作符：=, &lt;&gt;, &gt; , &gt;=, &lt;, &lt;=, IS NULL, BETWEEN, LIKE, or IN () index_subquery:利用索引来关联子查询，不再扫描全表 unique_subquery:该连接类型类似于 index_subquery，使用的是唯一索引 index_merge:在查询过程中需要多个索引组合使用 ref_or_null:对于某个字段即需要关联条件，也需要 null 值的情况下，查询优化器会选择这种访问方式 ref:使用非唯一索引进行数据的查找，或者唯一索引的前缀扫描，返回匹配某个单独值得记录行，ref 还经常出现在 join 中。 eq_ref:使用唯一索引进行数据查找，对于每一个索引键值，表中只有一条记录匹配，简单来说就是多表连接中使用 primary key 或者 unique index 作为关联条件。 const:这个表至多有一个匹配行 system:表只有一行记录（等于系统表），这是const类型的特例 possible_keys显示可能应用在这张表中的索引，一个或者多个，查询设计到的字段上若存在索引，则列出该索引，但不一定被实际查询使用 key实际使用的索引，null 表示没有使用索引，查询中若使用了覆盖索引，则该索引和查询的 select 字段重叠 key_len表示索引中使用的字节数，可以通过 key_len 计算查询中使用的索引长度，在不损失精度的情况下长度越短越好 ref显示索引的那一列被使用了，如果可能的话，是一个常数 rows根据表的统计信息以及索引的使用情况，大致估算出找出所需记录需要读取的行数，直接反映 sql 找了多少数据，在完成目的情况下越少越好 extra包含额外的信息 using filesort: 说明 mysql 无法用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置 using temporary： 建立临时表来保存中间数据，查询完成之后把临时表删除 using index： 表示当前的查询覆盖索引的，直接从索引中读取数据，而不用访问数据表，如果同时出现 using where 表明索引别用来执行索引键值的查找，如果没有，表明索引被用来读取数据，而不是真的查找 using where： 使用 where 进行条件过滤 using join buffer：使用连接缓存 impossible where： where 语句的结果总是 false 官网参考文档 Understanding the Query Execution Plan 测试表以及数据 数据库school 数据库创建 SQL >folded1CREATE DATABASE IF NOT EXISTS school DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_bin; 表测试表 >folded12345678910111213141516171819202122232425262728293031 # 学生表CREATE TABLE `student`(`student_id` VARCHAR(20),`student_name` VARCHAR(20) NOT NULL DEFAULT '',`student_birth` VARCHAR(20) NOT NULL DEFAULT '',`student_sex` VARCHAR(10) NOT NULL DEFAULT '',PRIMARY KEY(`student_id`)) ENGINE=InnoDB;# 课程表CREATE TABLE `course`(`course_id` VARCHAR(20),`course_name` VARCHAR(20) NOT NULL DEFAULT '',`teacher_id` VARCHAR(20) NOT NULL,PRIMARY KEY(`course_id`)) ENGINE=InnoDB;# 教师表CREATE TABLE `teacher`(`teacher_id` VARCHAR(20),`teacher_name` VARCHAR(20) NOT NULL DEFAULT '',PRIMARY KEY(`teacher_id`)) ENGINE=InnoDB;# 分数表CREATE TABLE `score`(`student_id` VARCHAR(20),`course_id` VARCHAR(20),`student_score` BIGINT,PRIMARY KEY(`student_id`,`course_id`)) ENGINE=InnoDB; 数据测试数据 >folded123456789101112131415161718192021222324252627282930313233343536-- 插入学生表测试数据insert into student values('01' , '赵雷' , '1990-01-01' , '男');insert into student values('02' , '钱电' , '1990-12-21' , '男');insert into student values('03' , '孙风' , '1990-05-20' , '男');insert into student values('04' , '李云' , '1990-08-06' , '男');insert into student values('05' , '周梅' , '1991-12-01' , '女');insert into student values('06' , '吴兰' , '1992-03-01' , '女');insert into student values('07' , '郑竹' , '1989-07-01' , '女');insert into student values('08' , '王菊' , '1990-01-20' , '女');-- 课程表测试数据insert into course values('01' , '语文' , '02');insert into course values('02' , '数学' , '01');insert into course values('03' , '英语' , '03');-- 教师表测试数据insert into teacher values('01' , '张三');insert into teacher values('02' , '李四');insert into teacher values('03' , '王五');-- 成绩表测试数据insert into score values('01' , '01' , 80);insert into score values('01' , '02' , 90);insert into score values('01' , '03' , 99);insert into score values('02' , '01' , 70);insert into score values('02' , '02' , 60);insert into score values('02' , '03' , 80);insert into score values('03' , '01' , 80);insert into score values('03' , '02' , 80);insert into score values('03' , '03' , 80);insert into score values('04' , '01' , 50);insert into score values('04' , '02' , 30);insert into score values('04' , '03' , 20);insert into score values('05' , '01' , 76);insert into score values('05' , '02' , 87);insert into score values('06' , '01' , 31);insert into score values('06' , '03' , 34);insert into score values('07' , '02' , 89);insert into score values('07' , '03' , 98);","link":"/2021-08-mysql-execution-plan/"},{"title":"project-reactor 框架","text":"概述真正的响应式，服务端实现，实现了 Reactive Streams 规范 what’s reactor 一个基于事件，异步处理高并发服务请求的框架，集成了 java 8的 函数式 api CompletableFuture Steam Duration 通过reactor-netty支持非阻塞进程间通信 适合微服务架构 Reactor Netty 提供 HTTP（包括 Websockets）, TCP, UDP 的背压就绪网络引擎 hot/cold cold 为每一个订阅都重新生成数据，从头开始，总能收到产生的全部数据 defer（每次订阅都是相同的返回） hot 持续不断的产生消息，订阅者只能获取订阅之后产生的消息 just share replay 提供 Flux/Mono return 一个 mono, 先返回 mono ，这个 mono 包装好各种方法， 把 方法放到调用里面，看起来是异步，实际上同步，只不过阻塞是发生在 Web 容器（Netty）里面 Router 约等于 @Controller + @RequestMapping Handler controller 里面的方法 create 可以创建 Mono, Flux，异步 generate 只能生成 Flux，同步 Disposable cancel-and-clean-up，stop producing values and clean up any resources it created Mono onNext 和 onError 不能同时用，因为最多一个 single 弹珠图 怎么阅读弹珠图","link":"/2021-08-project-reactor/"},{"title":"响应式编程","text":"what ？ 响应式宣言 一个基于面向数据流和传播变化的异步编程模型 和 Java 8 Streams 以及 Iterable-Iterator 比较 reactive 是 推模型, events 来了，推到 subscriber Java 8 Streams 以及 Iterable-Iterator 是 拉模型 背压流量控制: 告诉上游自己需要多少数据 如果不能 slow down， 只能 buffer ， drop or fail 在数据流从上游生产者向下游消费者传输的过程中，上游生产速度大于下游消费速度，导致下游的 Buffer 溢出，这种现象就叫做 Backpressure 出现。 规范标准，就是一个接口 publisher subscriber subscription processor 实现 webflux参考 webflux 文章 Project Reactor参考 Project Reactor 文章 RxJava 较老 main 里面同步 加 Scheduler，异步 响应式数据库 底层连接协议如何与数据库建立通讯 springJDBC -&gt; JDBC 规范 -&gt; mysql jdbc Driver -&gt; mysql R2DBC Drivers All terminal methods always return a Publisher type that represents the desired operation. The actual statements are sent to the database upon subscription. how总结来说，实际上就是：“异步编程，事件驱动” 消息驱动 同步与异步 callable BiFunction 同步：哪个线程产生就在哪个线程消费 命令式编程与响应式编程 函数式编程Functional Programming “what to solve” 命令式编程 “how to solve” 基于 lamda calculus 编程范式，编程程序的方法论 观察者模式 Tomcat 的 NIO 异步网络 IO 服务器推技术 Servlet 3.0 与 3.1 why ?一句话：提高性能 使用更多的线程和硬件资源来提高并行度 提高现有资源的使用效率","link":"/2021-08-reactive-programming/"},{"title":"Java JUC 中的基石： AQS 源码解读","text":"以 ReentrantLock 类为例 在使用 ReentrantLock 类时，调用 lock() 方法，我们先来看一下 lock() 方法： 12345678910111213public class ReentrantLock implements Lock, java.io.Serializable { private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer { ... } ... public void lock() { sync.acquire(1); } ...} 看到 sync.acquire(1)，sync 是 ReentrantLock 的内部类，继承了 AbstractQueuedSynchronizer (AQS)，而 acquire(1) 方法是属于 AQS 的，我们进到里面看看： 1234567public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); }} if 条件的两个并列条件，首先是第一个 tryAcquire(1)，这个方法的作用是尝试获得锁，如果当前的锁获取不到就会执行第二个条件，尝试加入队列，如果有任何中断直接中断。先进到 tryAcquire(1) 方法看看： 12345public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); }} 这个方法没有实现，说明留给子类去做实现，这里使用到了模板方法设计模式，在 ReentrantLock 类中，默认是非公平锁，所以内部类 NonfairSync 实现了 tryAcquire(1) 方法，该类继承了 Sync，而根据上述 Sync 继承了 AQS 类。我们看来 ReentrantLock 中 的 NonfairSync 类的结构： 12345678910public class ReentrantLock implements Lock, java.io.Serializable { static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } }} NonfairSync 类里面又调用父类 Sync 的 nonfairTryAcquire(1)，至此，我们到了获取锁的核心方法。 1234567891011121314151617181920212223242526272829public class ReentrantLock implements Lock, java.io.Serializable { abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ @ReservedStackAccess final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); // 获取当前线程 int c = getState(); // 获取当前状态，这个方法是 AQS 里面的方法，拿到的是 volatile 的 state 值，具体 state 值怎么用是子类要干的事情 if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } }} 拿到 state 值以后，if 条件中，判断 state 的值，如果 state 值为 0 ，说明还没有线程拿到锁，然后 CAS 齐昂锁，如果抢锁成功，那么 state 值为 1，并且把当前线程设置为独占锁；如果 state 值不是 0， 说明已经有其他的线程占用了这个锁；else if 的条件分支中，再判断一下已经拿到这个锁的是不是自己，如果是自己的话，就把 state + 1，释放的时候会 - 1。在判断 state 值既不是 0，也不是当前线程持有锁，那么一定是其他线程正在持有锁，返回 false。那么在 AbstractQueuedSynchronizer 类中 acquire(1)方法的第一个 if 条件 tryAcquire(1) 是 false，说明 ReentrantLock实例在调用 lock() 方法没有拿到锁，那就执行if 并列条件的第二个方法 acquireQueued(addWaiter(Node.EXCLUSIVE), arg))，这个方法是尝试加入到等待队列中。首先我们来看 addWaiter() 方法： 12345678910111213141516171819public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { private Node addWaiter(Node mode) { Node node = new Node(mode); for (; ; ) { Node oldTail = tail; if (oldTail != null) { node.setPrevRelaxed(oldTail); if (compareAndSetTail(oldTail, node)) { oldTail.next = node; return node; } } else { initializeSyncQueue(); } } }} 这里我们看到这个方法返回 Node 类，这个 Node 类是什么呢？我们看一下 Node 类的定义： 点击展开: AQS 的内部类 Node 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Wait queue node class. * * &lt;p&gt;The wait queue is a variant of a &quot;CLH&quot; (Craig, Landin, and * Hagersten) lock queue. CLH locks are normally used for * spinlocks. We instead use them for blocking synchronizers, but * use the same basic tactic of holding some of the control * information about a thread in the predecessor of its node. A * &quot;status&quot; field in each node keeps track of whether a thread * should block. A node is signalled when its predecessor * releases. Each node of the queue otherwise serves as a * specific-notification-style monitor holding a single waiting * thread. The status field does NOT control whether threads are * granted locks etc though. A thread may try to acquire if it is * first in the queue. But being first does not guarantee success; * it only gives the right to contend. So the currently released * contender thread may need to rewait. * * &lt;p&gt;To enqueue into a CLH lock, you atomically splice it in as new * tail. To dequeue, you just set the head field. * &lt;pre&gt; * +------+ prev +-----+ +-----+ * head | | &lt;---- | | &lt;---- | | tail * +------+ +-----+ +-----+ * &lt;/pre&gt; * * &lt;p&gt;Insertion into a CLH queue requires only a single atomic * operation on &quot;tail&quot;, so there is a simple atomic point of * demarcation from unqueued to queued. Similarly, dequeuing * involves only updating the &quot;head&quot;. However, it takes a bit * more work for nodes to determine who their successors are, * in part to deal with possible cancellation due to timeouts * and interrupts. * * &lt;p&gt;The &quot;prev&quot; links (not used in original CLH locks), are mainly * needed to handle cancellation. If a node is cancelled, its * successor is (normally) relinked to a non-cancelled * predecessor. For explanation of similar mechanics in the case * of spin locks, see the papers by Scott and Scherer at * http://www.cs.rochester.edu/u/scott/synchronization/ * * &lt;p&gt;We also use &quot;next&quot; links to implement blocking mechanics. * The thread id for each node is kept in its own node, so a * predecessor signals the next node to wake up by traversing * next link to determine which thread it is. Determination of * successor must avoid races with newly queued nodes to set * the &quot;next&quot; fields of their predecessors. This is solved * when necessary by checking backwards from the atomically * updated &quot;tail&quot; when a node's successor appears to be null. * (Or, said differently, the next-links are an optimization * so that we don't usually need a backward scan.) * * &lt;p&gt;Cancellation introduces some conservatism to the basic * algorithms. Since we must poll for cancellation of other * nodes, we can miss noticing whether a cancelled node is * ahead or behind us. This is dealt with by always unparking * successors upon cancellation, allowing them to stabilize on * a new predecessor, unless we can identify an uncancelled * predecessor who will carry this responsibility. * * &lt;p&gt;CLH queues need a dummy header node to get started. But * we don't create them on construction, because it would be wasted * effort if there is never contention. Instead, the node * is constructed and head and tail pointers are set upon first * contention. * * &lt;p&gt;Threads waiting on Conditions use the same nodes, but * use an additional link. Conditions only need to link nodes * in simple (non-concurrent) linked queues because they are * only accessed when exclusively held. Upon await, a node is * inserted into a condition queue. Upon signal, the node is * transferred to the main queue. A special value of status * field is used to mark which queue a node is on. * * &lt;p&gt;Thanks go to Dave Dice, Mark Moir, Victor Luchangco, Bill * Scherer and Michael Scott, along with members of JSR-166 * expert group, for helpful ideas, discussions, and critiques * on the design of this class. */ static final class Node { /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled. */ static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking. */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition. */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate. */ static final int PROPAGATE = -3; /** * Status field, taking on only the values: * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 0: None of the above * * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn't need to * signal. So, most code doesn't need to check for particular * values, just for sign. * * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). */ volatile int waitStatus; /** * Link to predecessor node that current node/thread relies on * for checking waitStatus. Assigned during enqueuing, and nulled * out (for sake of GC) only upon dequeuing. Also, upon * cancellation of a predecessor, we short-circuit while * finding a non-cancelled one, which will always exist * because the head node is never cancelled: A node becomes * head only as a result of successful acquire. A * cancelled thread never succeeds in acquiring, and a thread only * cancels itself, not any other node. */ volatile Node prev; /** * Link to the successor node that the current node/thread * unparks upon release. Assigned during enqueuing, adjusted * when bypassing cancelled predecessors, and nulled out (for * sake of GC) when dequeued. The enq operation does not * assign next field of a predecessor until after attachment, * so seeing a null next field does not necessarily mean that * node is at end of queue. However, if a next field appears * to be null, we can scan prev's from the tail to * double-check. The next field of cancelled nodes is set to * point to the node itself instead of null, to make life * easier for isOnSyncQueue. */ volatile Node next; /** * The thread that enqueued this node. Initialized on * construction and nulled out after use. */ volatile Thread thread; /** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. */ Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() { return nextWaiter == SHARED; } /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * * @return the predecessor of this node */ final Node predecessor() { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } /** Establishes initial head or SHARED marker. */ Node() {} /** Constructor used by addWaiter. */ Node(Node nextWaiter) { this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread()); } /** Constructor used by addConditionWaiter. */ Node(int waitStatus) { WAITSTATUS.set(this, waitStatus); THREAD.set(this, Thread.currentThread()); } /** CASes waitStatus field. */ final boolean compareAndSetWaitStatus(int expect, int update) { return WAITSTATUS.compareAndSet(this, expect, update); } /** CASes next field. */ final boolean compareAndSetNext(Node expect, Node update) { return NEXT.compareAndSet(this, expect, update); } final void setPrevRelaxed(Node p) { PREV.set(this, p); } // VarHandle mechanics private static final VarHandle NEXT; private static final VarHandle PREV; private static final VarHandle THREAD; private static final VarHandle WAITSTATUS; static { try { MethodHandles.Lookup l = MethodHandles.lookup(); NEXT = l.findVarHandle(Node.class, &quot;next&quot;, Node.class); PREV = l.findVarHandle(Node.class, &quot;prev&quot;, Node.class); THREAD = l.findVarHandle(Node.class, &quot;thread&quot;, Thread.class); WAITSTATUS = l.findVarHandle(Node.class, &quot;waitStatus&quot;, int.class); } catch (ReflectiveOperationException e) { throw new ExceptionInInitializerError(e); } } }} 总结一下就是，上面说到的等待队列是由一个双向链表实现的，这个队列是 CLH 队列的变种，把 synchronized 换成了 CAS， 而 Node 类就是这个双向链表带有线程信息的节点类。 Node 只有两种模式，EXCLUSIVE 和 SHARED，还有个成员变量 waitStatus，有几种状态，注释文档说的很清楚，最重要的是 SIGNAL 状态，表示当前的线程的后继节点正在阻塞等待， 当前线程释放锁或者取消后需要唤醒它的后继节点。 > 为什么是双向链表，单向的行不行？ 行，但是还是不够好，如果我要找到某个 node 的前一个节点，时间复杂度就是 O(n)，如果是双向链表就是 O(1)。 继续看 addWaiter(Node.EXCLUSIVE)方法，首先拿到等待队列的 tail 节点，如果为空就初始化一个队列，头尾都是指向这个 node；如果 tail 存在，就把要添加的这个 node 的 prev 指向 tail 节点，因为在操作的过程中，可能其他的线程改动了 tail，所以需要CAS 自旋的把 tail 节点的 next 指向这个要添加的 node。一句话就是：addWaiter() 方法就是添加 node 到等待队列的队尾。然后返回这个 node 添加到队尾之后，执行 acquireQueued(Node.EXCLUSIVE,1)方法，再看一下这个方法： 1234567891011121314151617181920212223242526272829303132public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting */ final boolean acquireQueued(final Node node, int arg) { boolean interrupted = false; try { for (; ; ) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC return interrupted; } if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); } } catch (Throwable t) { cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; } }} 首先去拿这个 node 的 prev 节点，先判断一下是不是头结点，然后再去 tryAcquire(1) ，看看能不能拿到锁，万一头结点刚好释放锁呢，拿到锁之后，说明头结点释放了锁，把这个 node 设置为头结点，然后头结点的 next 节点设置为 null，这样头结点就不会有引用存在，帮助 GC 回收，如果有中断就返回了。如果说，这个 node 的 prev 节点不是头结点或者没有拿到锁，那么进入下面一个条件判断，进入方法 shouldParkAfterFailedAcquire()： 123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ pred.compareAndSetWaitStatus(ws, Node.SIGNAL); } return false; }} 在看这个方法前，我们看一下参数，进到这个方法的前提是，如果参数 pred 不是头结点，当前线程也没有拿到锁，那么是不是应该等一下？首先拿到 pred 这个 node 的状态，判断：如果 pred 这个 node 的状态是 SINGAL，表示 pred 的这个 node 待会释放锁的时候会唤醒后继节点，也就是参数 node 指向的这个 Node，实际上就是当前的 node，那么返回 true，就是要等一会；如果 pred 这个 node 的状态是大于 0，大于 0 的状态是 CANCELLED 的状态，可能这个线程 node 被取消调度或者timeout，那么就再去找 pred 的这个 node 的前驱节点，反正一直找到不是 CANCELLED 状态的节点；如果 pred 这个 node 的状态是小于等于 0， waitStatus 默认是 0，小于 0 是处在 CONDITION 和 PROPAGATE 的状态，把 pred 的这个 node 的状态 CAS 设置成 SIGNAL 状态，最后返回 false。总结一下，实际上就是当前的线程节点加塞成为即将被唤醒的节点，坏得很~ 我们再回到方法 acquireQueued(Node.EXCLUSIVE, 1) 中，如果 shouldParkAfterFailedAcquire() 返回是 true，那么就是执行 parkAndCheckInterrupt()，即： 123456789101112public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { /** * Convenience method to park and then check if interrupted. * * @return {@code true} if interrupted */ private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); }} 这个方法就是调用同步辅助工具类 LockSupport.park(this)，阻塞住当前线程。 最后，如果在 lock() 的整个过程中拿到了锁，就会继续执行后面的程序，如果没有就阻塞住，这就是整个 AQS 的源码基本思路。 我们再来关注一下 AQS 为什么效率高？主要是 AQS 采用 CAS 来操作链表尾巴，如果好多线程都要往链表尾巴上插入节点，第一想法肯定会加锁，锁定整个 (Sync) 对象，保证线程安全，但是锁定整个链表的话，锁的太多太大了，现在 AQS 并不是锁定整个链表的方法，而是观测 tail 这个节点就可以了，用 CAS 是做实现，这就是AQS 效率高的核心。","link":"/2021-09-Java-JUC-%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%9F%B3%EF%BC%9A-AQS-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"},{"title":"Java JUC 包中原子类源码分析 CAS","text":"以 AtomicInteger 为例。 在使用 AtomicInteger 类时，加1操作会调用方法 incrementAndGet(),这个方法就是 CAS 的实现。先瞥一眼这个方法的内容， 实际上就是拿到 value 的值，然后再执行加 1 的操作。 1234567891011121314151617public class AtomicInteger extends Number implements java.io.Serializable { private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe(); /** * Unsafe 类直接操作内存 * 这个 VALUE 的值就是 AtomicInteger 类 value 的内存位置地址的偏移量， * 通过 native 方法，拿到地址指针 */ private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, &quot;value&quot;); private volatile int value; public final int incrementAndGet() { return U.getAndAddInt(this, VALUE, 1) + 1; } // 省略其他方法} 再跟踪到 getAndAddInt() 方法中，进到了 Unsafe 类中，如下： 123456789101112public final class Unsafe { ... @HotSpotIntrinsicCandidate public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v; } ...} 这个就是 CAS 的核心实现，流程如下： do 里面，先去拿 this 对象在偏移量为 offset 的值，v 取到的是 0； 然后 while 中 weakCompareAndSetInt() 方法再去判断这个偏移量位置上是不是 0，也就是期望的应该是0， 2.1 如果是 0，就把 0 + 1 = 1 写进去； 2.2 如果不是 0，说明在取到 0 后，有其他线程修改了这个 offset 位置的值，比如 1 2.3 然后又执行一次 do 里面的操作，拿到 v = 1，再去看看这个 offset 位置上的值是不是1，是就加上1，不是继续 do..while 操作 2.4 成功了就结束。 然后返回了 v，注意，这个 v 的值还是刚才取到的 0，并没有重新去取。 这里有个问题，有没有可能这样的情况出现，do 里面取到了是 0，然后比较了当前的位置确实是 0 ，然后再写的过程值又发生了变化呢？ 答案是不可能。我们进到 weakCompareAndSetObject(Object o, long offset,Object expected,Object x) 方法里面看一下源代码： 12345678910111213141516171819public final class Unsafe { @HotSpotIntrinsicCandidate public final boolean weakCompareAndSetObject(Object o, long offset, Object expected, Object x) { return compareAndSetObject(o, offset, expected, x); } /** * 如果当前持有expected则以原子方式将 Java 变量更新为x * 此操作具有volatile读写的内存语义。 对应于 C11 atomic_compare_exchange_strong。 * 返回：如果成功则为true */ @HotSpotIntrinsicCandidate public final native boolean compareAndSetInt(Object o, long offset, int expected, int x);} 我们可以看到注释里面 atomic_compare_exchange_strong 函数，这是 C11 原子的函数，反映到处理器的指令上就是 CMPXCHG 指令，这条指令已经无法再分割，而这条指令执行的时候，通过锁总线来让其他核心处理器都不能访问这个地址。简单来说，从 CPU 原语的级别来保证了 CAS 的操作。","link":"/2021-09-Java-JUC-%E5%8C%85%E4%B8%AD%E5%8E%9F%E5%AD%90%E7%B1%BB%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java内存模型之what,why,how","text":"why&emsp;&emsp;我们先来聊聊一些背景知识，首先现代的计算机中，多任务和高并发是衡量一台计算机处理的能力重要指标之一，一个关键性的指标 TPS（transaction per second），一般能说明问题，它代表的是一秒内服务器平均能响应的请求数。&emsp;&emsp;其次，硬件的效率和一致性的方面，计算机的处理器运算速度与存储设备（内存，硬盘）的读写速度有几个数量级的差距，为了缓解这种差距，现在计算机加入高速缓存（cache）来作为内存与处理器之间的缓冲，其读写速度接近于 CPU，将运算需要的数据复制到缓存中，运算结束后在动缓存同步到内存中。但是事务的发展总是解决老问题带来新问题，高速缓存解决了处理器与内存之间的速度矛盾，带来了一个新的问题，缓存一致性（Cache Coherence）。 &emsp;&emsp;尤其是在多处理器的系统中，每个处理器都有自己的高速缓存，而他们有共享同一个主存。多处理器系统缓存示意图和多级缓存结构如下： &emsp;&emsp;所以需要一种协议可以保障数据的一致性，目前主流的缓存一致性协议有 MSI, MESI, MOSI, Dragon Protocol, 要注意的是缓存都是有一个基础单位 cache line，这也是java中造成伪共享的根本原因。 &emsp;&emsp;值得注意的是，为了处理器内部的运算单元被充分利用，处理器可能会对代码进行乱序执行（out of order execution） 优化，在 java 中，JIT 也是有执行重排序的优化，经典案例就是双重检查单例，要不要加 volatile 关键字。 what所谓的 java 的内存模型的概念主要有以下几点： 主要目标是定义各个变量的访问规则，即 jvm 中将变量存储到内存和从内存中取出变量这样底层细节 规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存 （类比于处理器的高速缓存） 线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝 线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量 不同线程之间无法直接访问对方的工作内存中的变量，线程间变量的传递需要在主存中来完成 how最后，我们知道了 java 内存模型的一些定义和条件，那么怎样实现它的呢？主要有以下的几点： 8种操作 lock unlock read load use assign store write happens-before 原则 重排序从 java 源代码到最终实际执行的指令序列，经过三种排序 synchronized volatile final &emsp;&emsp;综上所述，我们对 java 内存模型的背景、概念、实现的过程有个总体上的理解。每一部分涉及到的细节还是很多的，以后再花时间深究。","link":"/2021-09-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B9%8Bwhat-why-how/"},{"title":"Kubernetes介绍","text":"K8S 是什么Kubernetes，又称为 k8s（首字母为 k、首字母与尾字母之间有 8 个字符、尾字母为 s，所以简称 k8s）或者简称为 “kube”。一个开源平台，用来干嘛的？用来自动化部署，缩扩容和管理容器应用的。下面这张图是 K8S 集群的架构图。 基本概念和术语 预期状态管理（Desired State Management） K8S API 对象（声明预期状态） ConfigMap why解耦配置文件和容器 典型用法 作为环境变量，为容器所使用 设置容器启动命令的启动参数（需要设置为环境变量） 以 Volume 的形式挂载为容器内部的文件或者目录 创建 yaml 文件，kubectl create -f configmap.yaml 命令行格式：kubectl create configmap --from-file=[key=]source --from-file=[key=]source（1）–from-file=文件名，就是从文件中创建（2）–from-file=文件夹名，就是目录中创建（3）–from-file=key=value 键值对，就是直接从 key-value 键值对创建 使用 通过环境变量的方式使用 通过 volumeMount 的方式使用 限制必须在 pod 创建之前完成 K8S Control Plane确保集群当前状态匹配预期状态 工作负载 Pod最小的调度和计算单位，由一个或者多个 container 组成，Pod 中的所有 container 共享存储，网络空间和 cgroup 的资源 工作负载资源（Controllers） Deployment &amp; ReplicaSetDeployment 部署无状态应用，可以 rollout、update、rollback ReplicaSet。 ReplicaSet 保证特定数量的 Pod 副本始终保持运行状态，ReplicaSet 并不是直接部署，而是通过 Deployment 来部署。 StatefulSetStatefulSet 部署有状态的应用，StatefulSet 要求一个 headless Service 搭配使用。 为什么要用 headless service + StatefulSet 部署有状态应用？ headless service会为关联的Pod分配一个域&lt;service name&gt;.$&lt;namespace name&gt;.svc.cluster.local StatefulSet会为关联的Pod保持一个不变的Pod Namestatefulset中Pod的hostname格式为$(StatefulSet name)-$(pod序号) StatefulSet会为关联的Pod分配一个dnsName$&lt;Pod Name&gt;.$&lt;service name&gt;.$&lt;namespace name&gt;.svc.cluster.local DaemonSet保证所有或者部分 Nodes 运行 Pod 的副本。使用场景在集群存储进程，日志收集进程，节点监控进程 Job &amp; CronJobJob 和 CronJob 都是任务，前者是直到特定数量的 Job 被成功执行，后者是重复间隔执行一次。 核心组件的运行机制 K8S Master kube-apiserver (API Server) 对外提供各种对象的CRUD REST接口 对外提供Watch机制，通知对象变化 将对象存储到 Etcd 中 kube-controller-mamager (守护进程)通过 apiserver 监视集群的状态，并做出相应更改，以使得集群的当前状态向预期状态靠拢，通过 Controller 会尝试将状态调整为期望的状态。Controller 包括：Replication Controller，Node Controller，ResourceQuota Controller，Namespace Controller，ServiceAccount Controller，Token Controller，Service Controller，Endpoint Controller。 kube-scheduler (调度器)将待调度的 Pod 按照特定的调度算法和调度策略绑定到集群中某个适合的 Node 上，并将绑定信息写入到 etcd 中，调度需要考虑的因素有：资源需求，服务治理要求，硬件/软件/策略限制，亲和以及反亲和要求，数据局域性，负载间的干扰等。 Work Node Kubelet（节点代理）接受通过各种机制（主要是通过 apiserver ）提供的一组 PodSpec，确保 PodSpec 中描述的容器处于运行状态且运行状况良好 Kube-proxy（节点网络代理）在节点上提供 Kubernetes API 中定义 Service，设置Service对应的 IPtables 规则，进行流量转发（userspace模式） 共享存储原理 PV(PersistentVolume)它是对底层网络存储的抽象，由管理员创建和配置，挂载到 node 上。PV 的生命周期： available资源的产生来源： 静态模式管理员手动创建许多 PV 动态模式通过 StorageClass 的设置对后端存储进行描述，标记为某种类型 Bound Released Failed PVC(PersistentVolumeClaim)对 PV 的 一个申请，就像 pod 消费 node 资源一样，PVC StorageClass 生命为 “”，说明PVC禁止使用动态模式，多个 pod 可以挂载同一个 PVC StorageClass管理员定义储存资源为某种类别，用户根据 storage class 直观了解存储资源的特性 CSI 机制 （Container Storage Interface）容器存储接口 why ?上面的方式都是 in-tree，耦合太重 what ?与容器对接的存储接口标准，存储提供方只需要基于接口标准进行存储插件的实现，就能使用K8S 的原生存储机制为容器提供存储 动态存储 安全机制 基础概念User类型： Service AccountK8S 管理它，并且绑定在特定的 namespace Normal User存在于 K8S 集群外，使用集群的 CA 证书授权 Authentication — 客户端认证 最严格的 HTTPS 正数认证： 基于 CA 根证书签名的双向数字证书认证方式 HTTP token 认证： 通过一个 Token 来识别用户 HTTP base 认证： 通过用户名 + 密码的方式认证 Authorization — 授权 RBAC Namespace Scope Role RoleBinding：把一个角色绑定到一个目标上 User，Group，Service Account Cluster Scope ClusterRole CluseterRoleBinding：只对集群级别角色生效 授权策略来决定一个 API 调用是否合法 API Server 授权策略 AlawaysDeny: 拒绝所有请求，用于测试 AlawaysAllow: K8S 默认设置，允许接收所有请求，集群不需要授权流程，可以采用 ABAC (Attribute-Based Access Control): 基于属性的访问控制，使用用户配置的授权规则对用户请求进行匹配和控制 RBAC (Role-Base Access Control): 基于角色的访问控制 Node: 专用模式，对 kubelet 发出的请求进行访问控制 Webhook: 调用外部 REST 服务对用户进行授权鉴权的流程，可以通过命令看详细的请求，kubectl --v=8 version，流程如下图： Admission Control — 准入控制准入控制器的插件列表中的每个准入控制器检查请求，插件举例：LimitRanger，ServiceAccount 等 Service Account — 服务账户不是给用户用的，给运行在 Pod 中的进程提供必要的身份证明，与API Server 交互流程为： Pod 访问 API Server 的服务时，以 service 方式调用名为 Kubernetes 的这个服务的，而 Kubernetes 服务只在HTTPS 安全端口 443 上提供 请求时，类似于 HTTP Token，Header 中加了 token 字符串，来自于 /run/secrets/kubernetes.io/serviceaccount/token 建立链接时，用 Pod 里指定路径下的一个 CA 证书 （/run/secrets/kubernetes.io/serviceaccount/ca.rt)，验证 API Server 发来的证书 API Server 在收到这个 Token，会对这个 token 进行合法性验证 /run/secrets/kubernetes.io/serviceaccount/namespace 会作为参数调用 Kubernetes API 每个 Namespace 下都有个 default 的默认 Service Account 对象，名为 Tokens 的可以当作 Volume 被挂载到 Pod 里的 Secret，Pod 启动时挂载，协助进程访问 API Server 时的鉴权。 Secret — 私密凭据保管私密凭据，从属于 Service Account，一旦 Secret 的使用方式： 创建 Pod 时，为 Pod 指定 Service Account 自动使用改 Secret 挂载该 Secret 到 Pod 使用，执行 ls /etc/{secret name} 可以看到 Secret 的 data 域中的 key 值作为目录中文件 在 Docker image 下载时，指定 Pod 的 spec.ImagePullSecrets 网络原理K8S 的网络原理比较复杂，基于 Docker 的网络之上有封装很多东西，深入了解还需要时间。 基础概念需要了解网络里面的一些概念和原理 Linux Network Virtualization， Linux Tun/Tap Linux Network Namespace Veth Pair Linux Bridge Vlan VxlAN Routing ProtocolDistance Vector Protocol,BGPLink-State Protocol,OSPF K8S Network Service Cluster IP Headless NodePort LoadBalancer Ingress K8S Ingress lstio Ingress Gateway API Gateway + Service Mesh Kubernetes CNI 插件, Calico","link":"/2021-09-Kubernetes%E4%BB%8B%E7%BB%8D/"},{"title":"线程池源码分析","text":"线程池及简单介绍（1）线程池类关系图 Executors 是对线程执行的工具类，可以看做是线程池的工厂。execute() 方法任务立即执行，submit() 方法提交任务等待线程自己调度运行。 （2）线程池核心参数的交互 corePoolSize 核心线程数 maximumPoolSize 最大线程数 keepAliveTime 生存时间，线程池中超过核心线程数大小的线程的存活时间，如果设置 allowCoreThreadTimeOut 为 true，那么核心线程数也是此时间的存活时间 unit 生存时间的单位，类型是 TimeUnit workQueue 任务队列 BlockingQueue&lt;Runnable&gt; threadFactory 线程工厂 ThreadFactory handler 拒绝策略， 类型是 RejectedExecutionHandler 首先线程池中会保持 corePoolSize 大小的线程运行，即使没有任务也会空闲运行，但是如果设置了 allowCoreThreadTimeOut = true，那么核心线程也会在 keepAliveTime 时间大小之后关闭。当任务超过了核心线程数的话，会把新的任务放到工作队列，如果工作队列满了，并且当前的工作线程是小于 maximumPoolSize 定义的最大线程数的，那么创建一个新线程来运行任务，当运行的线程数超过了最大线程数的值，拒绝策略开始发挥作用，默认是丢弃策略。 终于来到了我们的线程池的源码解析啦，因为我们知道jdk自带的各种线程池本质上都是核心类 ThreadPollExecutor 构造出来的，所以我们来看里面到到底是个什么鬼？ 源码分析 成员变量 123456789101112131415161718192021222324252627282930313233public class ThreadPoolExecutor extends AbstractExecutorService { // 高 3 位表示线程池状态，低29位表示 worker 的数量 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; // 32 - 3 = 29 /** * 0010 0000 0000 0000 0000 0000 0000 0000 COUNT_BITS 二进制值 - 0000 0000 0000 0000 0000 0000 0000 0001 1 二进制值 ———————————————————————————————————————————— = 0001 1111 1111 1111 1111 1111 1111 1111 COUNT_MASK 二进制值 * */ private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1; // 1 * 2^29 -1 // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 表示接收新任务和处理队列中的任务 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 表示不接收新任务了，但是会处理队列中的任务 private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 表示不接收新任务，也不处理队列中的任务，中断进行中的任务 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 如果所有的任务的已经结束，工作线程是0，此时的线程状态转变为 TIDYING，调用 terminated() 钩子方法 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 表示 terminated() 方法执行完成 // Packing and unpacking ctl // ~COUNT_MASK 值: 1110 0000 0000 0000 0000 0000 0000 0000 // 按位与，低 29 位都是 0 private static int runStateOf(int c) { return c &amp; ~COUNT_MASK; } // COUNT_MASK 二进制值 : 0001 1111 1111 1111 1111 1111 1111 1111 // 按位与，高 3 位都是 0 private static int workerCountOf(int c) { return c &amp; COUNT_MASK; } // 根据线程池状态和线程数量计算 control(ctl) 的值 private static int ctlOf(int rs, int wc) { return rs | wc; }} ctl 这个原子整形变量，包含了两个含义，一个是 workerCount，就是线程池里面 worker 数量，另一个是 runState，就是线程池状态，运行还是停止等等。咦，一个变量怎么表示的两种意思呢？有一个很巧妙的方法就是高3 位表示线程池的状态，低 29 位来表示线程池中的线程数量，目前来说是29位数量足够的，如果不够，后面会扩展成 Long 类型就可以，这样在高并发的情况减少变量的锁同步。具体怎么做到的呢？先来看看线程池状态的表示，首先是 RUNNING 状态： private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; 我们知道 COUNT_BITS 是 29， -1 的二进制值表示是 1 的二进制值，取反，然后加 1 ，就是 -1 的二进制表示。int 是 32 位，那么： 0000 0000 0000 0000 0000 0000 0000 0001 1 的二进制1111 1111 1111 1111 1111 1111 1111 1110 取反1111 1111 1111 1111 1111 1111 1111 1111 加 1 即为 -1 的二进制表示 RUNNING 状态是左移 29 位，那么： 1111 1111 1111 1111 1111 1111 1111 1111 -1 的二进制表示1110 0000 0000 0000 0000 0000 0000 0000 左移 29 后的值 即 RUNNING 的值是：1110 0000 0000 0000 0000 0000 0000 0000， 同理得到：SHUTDOWN&emsp;&nbsp; 的值是 0000 0000 0000 0000 0000 0000 0000 0000，STOP&emsp;&emsp;&emsp;&nbsp; 的值是 0010 0000 0000 0000 0000 0000 0000 0000，TIDYING&emsp;&nbsp;&nbsp;&nbsp; 的值是 0100 0000 0000 0000 0000 0000 0000 0000，TERMINATED&nbsp; 的值是 0110 0000 0000 0000 0000 0000 0000 0000。 所以 ctl 变量的默认值是 RUNNING 的值 和 0 或运算，即 ctl = 1110 0000 0000 0000 0000 0000 0000 0000，实际上意思就是线程池在 RUNNING 状态，但是 0 个工作线程。通过方法 runStateOf() 可以拿到当前线程池的状态值。 上面说的是线程池状态的表示，再来看一下线程池中线程的个数，变量 COUNT_MASK 就是表示线程数的大小，最多（2^29 - 1） 个，通过方法 workerCountOf() 可以计算线程的个数。 构造方法构造方法主要是进行一些非空判断和校验。 1234567891011121314151617181920212223public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); // 将存活时间转换成纳秒 this.threadFactory = threadFactory; this.handler = handler; }} 提交任务的过程提交任务时，会调用 execute() 方法，我们来看一下这个方法： 12345678910111213141516171819202122232425262728293031323334353637383940public class ThreadPoolExecutor extends AbstractExecutorService { public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) // 带了任务参数 return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); // 没有带任务参数 } else if (!addWorker(command, false)) reject(command); }} execute() 方法的思路注释文档说的很清楚，首先非空判断，然后拿到 ctl 的值，来判断： 值（默认是 0 ）小于核心线程数的如果是小于就添加一个 Worker，这个 Worker 是 ThreadPoolExecutor 的内部类，简单来讲就是封装了线程信息和任务信息的类，后面再谈。 值大于核心线程数， 2.1 再判断线程池状态是 RUNNING 状态，就添加到工作队列当中去 2.1.1 这里注意的是还会再一次检查线程池的状态，以防线程池的状态在添加队列的过程中发生改变，如果发现线程池不是 RUNNING 状态的话，那么就把队列里面的任务 remove 掉，然后调用拒绝策略来拒绝，默认是丢弃。 2.1.2 在 2.1.1 的基础判断上，如果线程池仍然是 RUNNING 的状态，但是 workerCountOf() 拿到的 worker 是 0，那么添加一个 worker，这里只在线程池里面增加一个线程。这里我们可以看到核心线程数满了之后，先添加到队列，如果线程池中的 worker 是 0 的话，那么会新加一个线程，核心线程会带着任务直接执行，而核心线程之外的线程是从队列里面取任务来执行的，注意 addWorker() 方法的调用。 2.2 线程池状态并不是 RUNNING 状态的话，或者任务进入队列失败了，尝试创建worker执行任务，实际上 addWorker() 方法里面也是判断了线程池状态的，不是 RUNNING 状态的话直接返回 false，添加任务失败，触发 reject 策略。 addWorker 分析在上面添加任务的分析过程中，主要是调用 addWorker() 的方法，现在来窥探下 addWorker() 方法： 点击展开：addWorker() 方法 >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ThreadPoolExecutor extends AbstractExecutorService { private boolean addWorker(Runnable firstTask, boolean core) { retry: for (int c = ctl.get(); ; ) { /** * 这里的 if 条件等价于 * if(rs &gt; SHUTDOWN || * rs == SHUTDOWN &amp;&amp; firstTask != null || * rs == SHUTDOWN &amp;&amp; workQueue.isEmpty() * ) * 1. 线程池状态 &gt; SHUTDOWN 时，直接返回false； * 2. 线程池状态 = SHUTDOWN 时，且 firstTask 不等于 null，直接返回false； * 3. 线程池状态 = SHUTDOWN 时，且工作队列是空的话，直接返回false； * */ // Check if queue empty only if necessary. if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; // 内存自旋 for (; ; ) { // worker 超过容量，直接返回 false if (workerCountOf(c) &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK)) return false; // 使用 CAS 的方式增加 worker 数量，成功了跳出外层 for 循环 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果线程状态发生变化外层自旋。 if (runStateAtLeast(c, SHUTDOWN)) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); // 重新检查线程池的状态 if (isRunning(c) || (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) { if (t.getState() != Thread.State.NEW) throw new IllegalThreadStateException(); workers.add(w); workerAdded = true; int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; } } finally { mainLock.unlock(); } // 启动 worker 的线程 if (workerAdded) { t.start(); workerStarted = true; } } } finally { if (!workerStarted) addWorkerFailed(w); } return workerStarted; }} &emsp;&emsp;这个方法的代码分为两部分，第一部分是 for() 循环，也就干了一件事把 workerCount 加 1，第二部分循环后执行的代码，目的是添加一个 Worker 对象。在第一 部分代码里面，主要就是第一层的循环判断当前的线程池状态，如果是大于 shutdown 的话就直接返回 false。第二层的循环，先去判断当前的线程数量是不是超过了 corePoolSize 和 maximumPoolSize，然后再用 CAS 的方式把 workerCount 加 1，这是第一部分代码的主要逻辑。 我们再来看看第二部分代码的逻辑，就是 new 一个 Worker 对象，然后把封装任务信息，添加到 workers 集合里面，因为涉及到多线程，肯定需要加锁的，这里用 ReentrantLock 来实现的，加入之后，启动这个线程，开始执行任务。addWorker() 这个方法的思路还是比较清晰的。 接下来我们来看一看 Worker 这个类： 点击展开：Worker 类 >folded12345678910111213141516171819202122232425262728293031public class ThreadPoolExecutor extends AbstractExecutorService { private final class Worker extends AbstractQueuedSynchronizer implements Runnable { /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } /** Delegates main run loop to outer runWorker. */ public void run() { runWorker(this); } }} &emsp;&emsp;主要看一下构造方法，在构造方法里面最重要的就是把当前的 Worker 对象 this 当作参数进行 thread 的生成，实际上等价与 new Thread(runnable)。 因为 Worker 本身是继承了 AQS 类又实现了 Runnable 类的。所以我们要看一下 Worker 重写 run() 方法里面 runWorker() 方法。 runWorker 核心线程执行逻辑先来看一下 runWorker 的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ThreadPoolExecutor extends AbstractExecutorService { final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; // 为了能够让外部中断 w.unlock(); // allow interrupts // 所有任务完成时标志，线程池正在结束 boolean completedAbruptly = true; try { // 如果 firstTask 不为空就执行 first task，为空就去队列里面取。 while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { // 空实现，为了扩展 beforeExecute(wt, task); try { task.run(); afterExecute(task, null); } catch (Throwable ex) { afterExecute(task, ex); throw ex; } } finally { // 帮助 GC task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } }} 上面我们提到 Worker 这个类既继承了 AQS 类又实现了 Runnable 类，那么它本身就是一把锁，就可以做同步。很多线程都会去 new Worker()，然后去放自己的任务，所以给自己加了一把锁，然后只执行自己的任务，如果不加锁，别的线程进来之后有可能让它执行其他的任务，所以这个时候要枷锁。这是自己继承 AQS，不用 new其他的锁了，自己 lock 就行了。这一部分实际上就是执行任务，加了很多状态的判断逻辑。 总结来说，首先提交任务 submit (返回 Future 对象) 或者 execute 任务，然后核心线程池够不够，启动核心的，核心线程够了就加入阻塞队列，队列满了，就添加非核心线程，一直到的最大线程数，然后再执行拒绝策略。","link":"/2021-09-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"网络IO模型","text":"背景知识在深入的去了解和学习 IO 模型时，是要求对操作系统的一些底层概念是要了解的，比如 VFS树、FD、Page Cache、Dirty Page、Flush 等。这些概念到时候我会再学习一下，然后单独去写一篇操作系统关键性概念的文章。另外，在学习 IO 的时候，TCP/IP 协议也是需要了解的，包括三次握手以及 linux 中在建立连接时的系统调用信息，这对于理解 IO 很有帮助。 C10K 问题 C10K 问题介绍 线程是 CPU 调度的最小单位，进程是 CPU 分配资源的最小单位 C10K 是一个经典的服务端问题。最初的服务器是基于进程/线程模型，新的一个 TCP 连接，就需要分配一个进程（或者线程），如果有 10k 个连接，那么需要创建 1w 个进程（或线程），对于单机服务器来说，这是无法承受的。所以如何去突破单机的性能，是高性能网络编程必须要面对的问题。关于 C10K 问题的探讨，可以参考这篇文章 The C10K problem. 解决方案从 C10K 的背景中看出，要向解决高并发的连接问题，无非有两种，一是一个连接一个线程，另一个是多个连接一个线程。前者会因为系统资源而限制，就算系统资源充足，实际上效率也并不高，会涉及到大量的线程上下文切换操作，扩展性差，后者是现在的主流处理方式。 同步与异步在涉及到 IO 问题时，通常会聊到同步与异步的概念，所谓的同步异步是在于应用程序读写数据还是内核来读写数据，如果说读操作是应用程序来读（调用 read() 的 system call 方法），写操作是应用程序来写（调用 write() 的 system call 方法），那么这种模型就是同步的；如果是内核来做的读写，那么就是异步的。实际上，在目前的 linux 内核版本（2.6）是没有异步的实现，只有 Windows 实现了异步模型。 阻塞与非阻塞阻塞与非阻塞也是 IO 中经常容易混淆的概念，应用程序在发起读写操作时，对应就是某一个线程发起读写操作，那么会通过系统内核来进行 IO 操作，发起读写操作的线程如果一直等待内核 IO 操作完成以后，才能执行其他的操作，那么这种模型就是阻塞的，如果不需要等待内核 IO 操作完成，可以直接进行后续的操作，此时内核会立即返回给线程一个状态值。那么这种模型就是非阻塞的。 综上所述，IO 模型可以分为四类，同步阻塞、同步非阻塞、异步阻塞、异步非阻塞，实际上异步阻塞 是没有意义的。所以目前 IO 主要分为三大类，而 Linux 只有前两类的实现，只有 Windows 实现了异步非阻塞的模型。接下来再了解一下同步阻塞和同步非阻塞的 IO 模型。 IO 模型 系统环境：CentOS 7.9，内核版本是 2.6JDK 版本：11 BIO（同步阻塞）BIO（Blocking IO） 也是常说的传统 IO，java 中的实现在 java.io 包中。对于 BIO 的模型，从 linux 内核角度来说就是一个 TCP 连接就新建一个 thread 去处理，在很高的并发连接下，对于系统资源的开销还是比较大的。另外对于数据的读写，都必须要等到内核 IO 操作完成以后，在等待的过程中，线程一直占用资源，利用率不高。看一个 java BIO 的例子。 123456789101112131415161718192021222324252627282930313233343536373839404142public class SocketBio { public static void main(String[] args) throws IOException { // 打开 socket server 服务 final ServerSocket server = new ServerSocket(9999); System.out.println(&quot;start server：&quot; + server.getInetAddress().getHostAddress() + &quot;:&quot; + server.getLocalPort()); // 这里 while 是模拟 BIO 模型下一直在等待连接 while (true) { System.out.println(Thread.currentThread().getName() + &quot;: 服务器正在等待连接...&quot;); final Socket client = server.accept(); // 阻塞住 System.out.println(&quot;client: &quot; + client.getInetAddress() + &quot;:&quot; + client.getPort()); // 当客户端连接成功以后，开启一个线程来处理 new Thread(() -&gt; { try { // 拿到字节流，socket 通信 final InputStream in = client.getInputStream(); // 字节流转成字符流 final BufferedReader reader = new BufferedReader(new InputStreamReader(in)); System.out.println(Thread.currentThread().getName() + &quot;: 服务器正在等待数据...&quot;); // 一直循环等待消息 while (true) { final String line = reader.readLine(); if (null != line) { System.out.println(Thread.currentThread().getName() + &quot;: 服务器已经接收到数据：&quot; + line); } else { client.close(); break; } } System.out.println(Thread.currentThread().getName() + &quot;: 客户端 --&gt; &quot; + client.getInetAddress().getHostAddress() + &quot;断开！&quot;); } catch (IOException e) { e.printStackTrace(); } }).start(); } }} 编译后在linux上跑一下（我的linux内核版本是 2.6），用linux工具命令strace 来跟踪该 java 进程的系统调用情况，运行：strace -ff -o out java top.caolizhi.example.io.bio.SocketBio跟踪的日志输出到 out 文件中。服务端开始启动，并且阻塞在 accept 代码段，输出： 我们看到有很多 out.pid 格式的文件产生，如下图所示，最小的 pid 是主进程，还有垃圾回收进程等，应该都是 fork 出来的子进程。 再来看一下服务端打开的TCP端口监听，执行命令netstat -natp可以看到 java 进程的 pid 是 7184，然后当前的状态是 LISTEN 状态 再来看一下 7184 这个进程打开 FD（File Descriptor 文件描述符）有哪些，执行命令：lsof -p 7184lsof命令是查看当前系统文件的工具，一切皆文件，我们查看的是 java 进程打开了哪些文件（FD），如图： 还可以看一下 java 进程 socket 的信息，执行命令：ll /proc/7184/fd看到当前打了一个 fd = 5 的 socket，与 lsof 的结果一致。 看了 java 进程打开的 FD 之后，接来下就看一下 java 进程 7184 的系统调用日志，打开 out.7184，主要看到最后几行的片段： 12345678910stat(&quot;/etc/sysconfig/64bit_strstr_via_64bit_strstr_sse2_unaligned&quot;, 0x7fff49a171a0) = -1 ENOENT (No such file or directory)mprotect(0x7f5abc955000, 806912, PROT_READ) = 0munmap(0x7f5abd8d9000, 28940) = 0mmap(NULL, 1052672, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7f5abd7d3000clone(child_stack=0x7f5abd8d2fb0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7f5abd8d39d0, tls=0x7f5abd8d3700, child_tidptr=0x7f5abd8d39d0) = 7185futex(0x7f5abd8d39d0, FUTEX_WAIT, 7185, NULL 实际上，7184 的进程里面又 clone 了一个子进程 7185，我们再去 7185 这个进程里面看一下，在 7185 的进程里面有几个关键的系统调用：bind(),listen() 12345678910bind(5, {sa_family=AF_INET6, sin6_port=htons(9999), inet_pton(AF_INET6, &quot;::&quot;, &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0}, 28) = 0listen(5, 50) .......write(1, &quot;start server\\357\\274\\2320.0.0.0:9999&quot;, 27) = 27write(1, &quot;\\n&quot;, 1) = 1write(1, &quot;\\346\\234\\215\\345\\212\\241\\345\\231\\250\\346\\255\\243\\345\\234\\250\\347\\255\\211\\345\\276\\205\\350\\277\\236\\346\\216\\245...&quot;, 30) = 30write(1, &quot;\\n&quot;, 1) = 1mprotect(0x7f5ab418d000, 32768, PROT_READ|PROT_WRITE) = 0pread64(3, &quot;\\312\\376\\272\\276\\0\\0\\0007\\0026\\n\\0\\6\\1_\\t\\0\\236\\1`\\t\\0\\236\\1a\\t\\0\\236\\1b\\t\\0&quot;..., 18001, 9986808) = 18001poll([{fd=5, events=POLLIN|POLLERR}], 1, -1 上面操作中，bind()把等于 5 的 FD 和端口 9999 绑定，listen监听 5 这个 FD。然后调用 write() 的系统调用把需要打印信息写到标准输入的FD 1。最后是 poll() 和以前的 accept() 类似，阻塞等待。 实际上这里有点疑问，之前的系统调用是 accept 阻塞等待，但是现在变成了 poll 接下来，我们接入一个客户端，看一下是什么情况，执行命令：nc localhost 9999看到有信息输出： 再来看一下 7184 fd 的情况： 可以看到 fd = 6 的 socket 连接，状态为 ESTABLISHED。当有客户端连接以后，代码里面会新建一个线程来处理，我们得到了 out.7382 的日志： 上图中，大概能看到 thread 的名称，pid 号, 还有系统调用 recvfrom(6,)，等待接收数据。 以上就是一个 BIO 的底层实现流程,从上面的过程可以看到，服务端有两次阻塞，第一次是启动后等待客户端连接(accept)，第二次是在客户端连接后等待客户端发送数据(recevfrom)，如果没有数据，服务会一直阻塞住。另外如果我再开一个客户端连接，那么会新开一个线程去处理，大量的请求连接会造成服务器的压力。 另外我们可以还可以看一下客户端和服务端建立 TCP 连接的三次握手，四次挥手的过程，执行命令：tcpdump -nn -i ens33 port 999过程如下： NIO（同步非阻塞）针对 BIO 的劣势，我们考虑在单线程服务器处理，即我不去新建一个线程去处理，所有的请求在同一个线程里面处理，（其实这里你可以想一下 redis），但是这样会有一个问题就是一个连接请求进来了，线程阻塞住在等待客户端发送数据，如果另一个客户端连接过来，那么服务端无法处理，我们进行优化一下，可以这样去解决，如果等待数据的阻塞，还可以继续接收客户端的连接，再继续优化，如果等待数据时阻塞住了，那么我们遍历下一个 socket client，我们改进一下 BIO 的代码。12345678910111213141516171819202122232425262728293031323334353637383940public class SocketNio { public static void main(String[] args) throws IOException, InterruptedException { List&lt;SocketChannel&gt; clientList = new LinkedList&lt;&gt;(); final ServerSocketChannel socketChannel = ServerSocketChannel.open(); socketChannel.bind(new InetSocketAddress(9999)); socketChannel.configureBlocking(false); // 不设置，就是阻塞，调用 accept()，这里解决 BIO 的第一个阻塞 System.out.println(&quot;server started ...&quot; + socketChannel.socket().getInetAddress() + &quot;:&quot; + socketChannel.socket().getLocalPort()); while (true) { Thread.sleep(1000); final SocketChannel client = socketChannel.accept(); if (null != client) { client.configureBlocking(false); // 配置非阻塞，否则一直等待客户端的数据，这里解决 BIO 的第二个阻塞 System.out.println(&quot;client :&quot; + client.socket().getInetAddress() + &quot;:&quot; + client.socket().getPort()); clientList.add(client); }else { System.out.println(&quot;waiting for connection ....&quot;); } final ByteBuffer byteBuffer = ByteBuffer.allocate(4096); // 遍历客户端，读写数据 for (SocketChannel channel : clientList) { System.out.println(&quot;read data from client &quot; + channel.socket().getInetAddress() + &quot;:&quot; + channel.socket().getPort()); final int byteNum = channel.read(byteBuffer); if (byteNum &gt; 0) { byteBuffer.flip(); // 翻转，由写转成读 final byte[] readBytes = new byte[byteBuffer.limit()]; byteBuffer.get(readBytes); // 把 buffer 里面的数据 copy 到 readBytes 数组 final String data = new String(readBytes); System.out.println(channel.socket().getInetAddress() + &quot;:&quot; + channel.socket().getPort() + &quot;'s data :&quot; + data) ; } } } }} 上述代码中，server 端和 client 端都设置成非阻塞的方式，configureBlocking(false)，并且将连接放在一个list集合中，在等待客户端消息时，看看消息是否准备好，遍历 list 集合，如果有消息则打印出来。我们可以再来看一下在启动服务的时候，第一次设置成阻塞模式的系统调用，同样是执行：strace -ff -o out java top.caolizhi.example.io.nio.SocketNio如下图，可以看到 server 端阻塞住了： out.pid 找到 java 进程 fork 出来的监听子进程，1463，查看 1463 的 socket fd，如下： 再来看一下系统调用： 1234567891011write(1, &quot;server started .../0:0:0:0:0:0:0&quot;..., 39) = 39write(1, &quot;\\n&quot;, 1) = 1futex(0x7f31a4026f54, FUTEX_WAIT_BITSET_PRIVATE, 1, {tv_sec=1884, tv_nsec=45138802}, 0xffffffff) = -1 ETIMEDOUT (Connection timed out)futex(0x7f31a4026f28, FUTEX_WAKE_PRIVATE, 1) = 0pread64(3, &quot;\\312\\376\\272\\276\\0\\0\\0007\\0:\\n\\0\\r\\0%\\n\\0&amp;\\0'\\t\\0\\f\\0(\\7\\0)\\7\\0*\\n&quot;..., 1072, 5183108) = 1072pread64(3, &quot;\\312\\376\\272\\276\\0\\0\\0007\\0005\\t\\0\\10\\0!\\n\\0\\t\\0\\&quot;\\t\\0\\36\\0#\\t\\0\\36\\0$\\t\\0&quot;..., 1161, 10456208) = 1161pread64(3, &quot;\\312\\376\\272\\276\\0\\0\\0007\\0\\t\\7\\0\\7\\7\\0\\10\\1\\0\\tinterrupt\\1\\0\\25(&quot;..., 162, 17327013) = 162pread64(3, &quot;\\312\\376\\272\\276\\0\\0\\0007\\0\\35\\n\\0\\5\\0\\25\\n\\0\\26\\0\\27\\n\\0\\4\\0\\30\\7\\0\\31\\7\\0\\32\\1&quot;..., 460, 17355571) = 460mprotect(0x7f31a419b000, 4096, PROT_READ|PROT_WRITE) = 0rt_sigaction(SIGRT_30, {sa_handler=0x7f318aa21480, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x7f31aa65c630}, {sa_handler=0x7f318a810020, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x7f31aa65c630}, 8) = 0accept(4, 看，看到了吧，调用 accept(4,) 一直在监听 fd = 4 ，等待客户端连接，我们看一下 accept 的方法： 1int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);; accept 系统调用目的就是等待一个 socket connection，这也印证了 BIO 的模型。把 server 端和 client 端全部设置成非阻塞模式，运行： 一直在循环等待 client 连接，现在打开一个 client 去连接server，同样执行nc 127.0.0.1 9999 再来发送一组数据，比如”test nio”，我们可以看到 server 端接收到了数据打印了出来： 再开启一个客户端来连接服务端，发送数据”client2 test”，服务端如下图： 最后看一下 NIO 的系统调用片段： 123socket(AF_UNIX, SOCK_STREAM|SOCK_CLOEXEC|SOCK_NONBLOCK, 0) = 3 .....accept(4, 0x7f1fe2065730, [28]) = -1 EAGAIN (Resource temporarily unavailable) 可以看到 socket 调用使用 SOCK_NONBLOCK 方式，另外，每一次调用 accept() 都会返回一个状态码，-1 表示没有连接可用。用man 2 socket来看一下描述： 综上所述，在非阻塞模式下，解决了 BIO 的两次阻塞，但是非阻塞也有弊端，我每一次都要循环遍历所有的 socket 连接，才能看到是否有消息发送，如果有大量的连接的话，显然效率是极低的。况且并不是所有的连接都是有消息的，每次仍然轮询的那些连接，也是不合理的。 那么，NIO 中，java 程序一直在轮询所有的连接，不断地在用户态和内核态切换，如果，把轮询放到内核中去做，那岂不是效率要高的多，这就引出来多路复用的模式。 多路复用（同步非阻塞）首先理解一下多路复用的概念，”多路” 实际上指的就是多个 IO，多个 socket 连接，也就是说单个线程通过记录跟踪每一个 IO 的状态，来同时管理多个 IO。IO 多路复用的实现主要有三种，按照出现的时间顺序为：select，poll，epoll。 selectselect 可以传入一个 fd 数组，内核需要开辟空间来存这部分 fd，然后去轮询，就算有数据也只是修改状态，然后全部返回给应用，并不会告诉应用那些 IO 是有数据的，所以应用还是要轮询一次，找有变化的 IO，再调用 read 取读取数据。所以这样就会有 2 次轮询和 2 次数据拷贝，另外 select 只支持最大 1024 个 fd，另外 select 是线程不安全的。 poll其实 poll 跟 select 差不多，但是可以支持任意个 fd，没有 1024 大小的限制，但是会受到系统文件描述符的限制，可用命令 ulimit -a 查看系统的限制。可以看下 POLL 方法描述 epollepoll 是最新的 IO 多路复用的实现，linux 内核 2.6 以后才出现。epoll 做了两件事情，第一件事就是，在内核中，使用红黑树来维护所有的需要检查的 fd，红黑树的时间复杂度是 O(logN)，另外一件事就是使用了事件驱动机制，在内核中维护了一张链表，把有状态的 fd 都放到那个链表里面，应用直接来取有状态的 fd 集合，效率大大的提高。epoll(7) 的方法调用又分为三个系统调用，epoll_create,epoll_ctl,epoll_wait。 应用调用 epoll_create 方法会在内核开辟一个红黑树结构，返回一个 fd 应用调用 epoll_ctl 方法传入需要监听的 fd 和针对该 fd 相应的事件，是读还是写等？那么内核会不断地轮询该 fd，看是否有状态变化 应用程序 epoll_wait 方法，内核会返回一个链表，链表里面是有状态变化的 fd，应用程序再去遍历这些 fd，调用 read() 或 write() 进行操作 链表里面的 fd 是从中断处理那边产生的，网卡中断会把 fd 放到 fd buffer 里面，然后内核再把 fd buffer 里面的 fd 添加到红黑树，接着把有状态变化的 fd 放到链表里面。 接下来，再来看一个 java 多路复用的例子，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class SocketMultiplexing { public static void main(String[] args) throws IOException { // 开启一个服务端 final ServerSocketChannel server = ServerSocketChannel.open(); server.configureBlocking(false); server.bind(new InetSocketAddress(9999)); // Selector 类是多路复用的 java 实现 final Selector selector = Selector.open(); // 相当于调用了 epoll_create /** * 如果是 epoll 模型：相当于调用了 epoll_ctl，监听 EPOLLIN 事件 * 如果是 select/poll 模型：会在 jvm 里面开辟一个数组，把 fd 放进去。 */ server.register(selector, SelectionKey.OP_ACCEPT); System.out.println(&quot;server start: &quot; + server.socket().getInetAddress() + &quot;:&quot; + server.getLocalAddress()); while (true) { final Set&lt;SelectionKey&gt; selectionKeys = selector.keys(); System.out.println(&quot;total checking fd size: &quot; + selectionKeys.size()); if (selector.select() &gt; 0 ) { // select() 方法就是拿到有 IO 状态变化的 fd 数量 final Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); // 拿到 IO 状态变化的 fd 集合 final Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while (keyIterator.hasNext()) { final SelectionKey key = keyIterator.next(); // 拿到 fd keyIterator.remove(); // 移除掉，不然一直在循环处理 // 接下来，对不同的 IO 事件进行处理，是建立连接还是读数据还是写数据？ if (key.isAcceptable()) { final ServerSocketChannel channel = (ServerSocketChannel)key.channel(); // 拿到的是 ServerSocketChannel，服务端 final SocketChannel client = channel.accept(); // accept 之后会拿到一个新的 fd client.configureBlocking(false); System.out.println(&quot;client: &quot; + client.socket().getInetAddress() + &quot;:&quot; + client.getLocalAddress()); ByteBuffer buffer = ByteBuffer.allocate(4096); //需要把上面调用 accept 产生的新的 fd 也要放到监听的列表里面去，并且监听的时间是 READ，绑定一个 buffer 到这个 fd 上。 client.register(selector, SelectionKey.OP_READ, buffer); } else if (key.isReadable()) { final SocketChannel client = (SocketChannel) key.channel(); // 拿到的是 SocketChannel 对象，客户端 // 拿到客户端传过来的数据，一个 buffer，因为上面 register 的时候，绑定了一个 buffer 在这个 fd 上。 final ByteBuffer buffer = (ByteBuffer) key.attachment(); buffer.clear(); while (true) { final int read = client.read(buffer); if (read &gt; 0) { // 有数据 buffer.flip(); // 翻转，由读变成写 while (buffer.hasRemaining()) { client.write(buffer); // 写回 client } } else if (read == 0) { // 没有数据 break; } else { client.close(); break; } } } } } } }} 上面的例子根据注释能够看懂做了什么事情，不再详述，运行该程序：strace -ff -o out java top.caolizhi.example.io.multiplexing.SocketMultiplexing 一开始服务启动会得到一个监听的 fd，所以 total checking fd size 是 1。 根据 out.pid 文件看一下当前 java 进程的 fd，ll /proc/1931/fd可以看到一个类型为 eventpoll 的 fd 5，还有两个 pipe 类型的 fd， 再用 lsof 命令执行一下： 可以看到程序打开了一个类型为 eventpoll 的 fd 5 ，还有只能 write 的管道 fd 6以及只能 read 的管道 fd 7。我们添加一个客户端来连接服务器，同样用 nc 命令，执行完后： 可以看到，当有客户端连接后，产生一个新的 socket fd，程序把这个新的 socket fd 调用 register 方法注册 READ 事件，那么此时total checking fd size 是 2。然后在客户端发送数据，”abc“,”dddd“，服务端也会回写同样的数据给客户端。如图： 接下来整体看一下这个程序的系统调用追踪： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 建一个 socket io，返回fd 4socket(AF_INET6, SOCK_STREAM, IPPROTO_IP) = 4# 绑定端口bind(4, {sa_family=AF_INET6, sin6_port=htons(9999), inet_pton(AF_INET6, &quot;::&quot;, &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0}, 28) = 0# 监听 socket 连接listen(4, 50) = 0 ...........# 创建一个 epoll 实例，返回fd 5epoll_create(256) = 5# 创建管道pipe([6, 7]) = 0fcntl(6, F_GETFL) = 0 (flags O_RDONLY)fcntl(6, F_SETFL, O_RDONLY|O_NONBLOCK) = 0fcntl(7, F_GETFL) = 0x1 (flags O_WRONLY)fcntl(7, F_SETFL, O_WRONLY|O_NONBLOCK) = 0# 针对 5 的 epoll 实例，添加一个监听 fd 6，监听的时间是 EPOLLINepoll_ctl(5, EPOLL_CTL_ADD, 6, {EPOLLIN, {u32=6, u64=140041703653382}}) = 0# 调用系统 write 方法，打印信息write(1, &quot;server start: /0:0:0:0:0:0:0:0:/&quot;..., 52) = 52 ........... write(1, &quot;total checking fd size: 1&quot;, 25) = 25# 针对 5 的 epoll 实例，添加一个监听 fd 4，监听的时间是 EPOLLINepoll_ctl(5, EPOLL_CTL_ADD, 4, {EPOLLIN, {u32=4, u64=140041703653380}}) = 0 ........... # 返回一个有 IO 状态改变的 fd 数量，因为此时发生了客户端的连接，有事件产生epoll_wait(5, [{EPOLLIN, {u32=4, u64=140041703653380}}], 1024, -1) = 1# 接受了一个客户端连接，返回fd 9accept(4, {sa_family=AF_INET6, sin6_port=htons(59298), inet_pton(AF_INET6, &quot;::ffff:192.168.170.112&quot;, &amp;sin6_addr), sin6_flowinfo=htonl(0), sin6_scope_id=0}, [28]) = 9fcntl(9, F_GETFL) = 0x2 (flags O_RDWR) ...........write(1, &quot;client: /192.168.170.112:/192.16&quot;..., 46) = 46write(1, &quot;\\n&quot;, 1) = 1write(1, &quot;total checking fd size: 2&quot;, 25) = 25write(1, &quot;\\n&quot;, 1) = 1# 把 fd 9 添加到监听列表中epoll_ctl(5, EPOLL_CTL_ADD, 9, {EPOLLIN, {u32=9, u64=140041703653385}}) = 0epoll_wait(5, [{EPOLLIN, {u32=9, u64=140041703653385}}], 1024, -1) = 1 ...........# 读取 fd 9 的 socket 数据read(9, &quot;abc\\n&quot;, 4096) = 4pread64(3, &quot;\\312\\376\\272\\276\\0\\0\\0007\\0.\\n\\0\\t\\0+\\7\\0,\\5\\377\\377\\377\\377\\377\\377\\377\\376\\5\\377\\377\\377\\377&quot;..., 1021, 17297719) = 1021# 把 fd 9 socket 读取到数据再写回到 fd 9 的通道中write(9, &quot;abc\\n&quot;, 4) = 4write(1, &quot;total checking fd size: 2&quot;, 25) = 25futex(0x7f5ea80bdb54, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7f5ea80bdb50, FUTEX_OP_SET&lt;&lt;28|0&lt;&lt;12|FUTEX_OP_CMP_GT&lt;&lt;24|0x1) = 1write(1, &quot;\\n&quot;, 1) = 1epoll_wait(5, [{EPOLLIN, {u32=9, u64=140041703653385}}], 1024, -1) = 1read(9, &quot;dddd\\n&quot;, 4096) = 5futex(0x7f5ea80bf954, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7f5ea80bf950, FUTEX_OP_SET&lt;&lt;28|0&lt;&lt;12|FUTEX_OP_CMP_GT&lt;&lt;24|0x1) = 1write(9, &quot;dddd\\n&quot;, 5) = 5write(1, &quot;total checking fd size: 2&quot;, 25) = 25write(1, &quot;\\n&quot;, 1) = 1# 没有任何 IO 状态发生变量epoll_wait(5, 另外，根据 epoll 的系统调用文档，又分为边缘触发和水平触发，这里不拓展了，有兴趣可以去看 man page 文档。 AIO（异步非阻塞）linux 内核是没有实现 AIO 的。它与同步非阻塞的区别在于，不需要一个线程去轮询 IO 的状态改变，而是一个 IO 的状态变更，系统会通知相应的线程来处理。JDK 中的 AIO 的底层实现也是基于 epoll 来实现的，并非真正的异步 IO。 参考https://tech.meituan.com/2016/11/04/nio.htmlhttps://notes.shichao.io/unp/ch6/深入理解计算机操作系统","link":"/2021-09-%E7%BD%91%E7%BB%9CIO%E6%A8%A1%E5%9E%8B/"},{"title":"JVM 系列 —— JVM 基础","text":"这是 JVM 系列的第一篇，见 JVM 系列。 写在前面最近想把之前学习 JVM 做的笔记整理一下，想写一个 JVM 的系列，主要包括以下部分： JVM 基础 类文件格式 类加载 java 运行时数据区 对象 JMM GC 基础知识 GC 常用垃圾回收器 GC 调优的问题 目的就是想复习一下知识点，然后巩固一下基础。很多东西不去用不去深入探究就会忘记。所以还是想再记录一下。 java 从编码到执行首先，一个 java 文件从编码到运行的流程是一个怎样的流程，在 java 编程里面，我们最常用的命令就是 java 和 javac，我们会先执行 javac 编译 .java 文件，通过编译器翻译成 java 字节码文件即 .class 文件，然后我们再通过 java 命令就可以让某个程序跑起来。所以这两个命令就代表了从编码到执行的两个过程，如下图： 对于 java 命令的操作，流程上是经过类加载器加载到内存(运行时数据区域)当中，然后再通过执行引擎（包括字节码解释器和 JIT（just in time）即时编译器）翻译成机器码，也就是操作系统指令集交给 CPU 去执行，这个过程中会调用到不同语言为 java提供的接口，即本地方法接口，native 接口。所以看起来 JVM 是个最低配的计算机系统。 jvm 是跨语言的平台，就是不同的操作系统对应不同的 jvm 版本，不同的操作系统的指令集和数据接口都有着差异，jvm 屏蔽了这样的差异细节，统一模拟成一个虚拟平台。java 是跨平台的语言，也就是说跟平台无关，只有 jvm 才与平台相关。 常见的 jvm 实现jvm 是一种规范，不同的厂商，根据这个规范做出了不同的实现，我们常用的就是 oracle 的 Hotspot jvm。实际上还有其他厂商的实现： Hotspot J9 (IBM) Microsoft VM Taobao VM - hotspot 的深度定制版，修改了大量源码 Azul zing - ZGC JRE 和 JDK用一张图来表示最直观和清晰：","link":"/2021-10-JVM%E7%B3%BB%E5%88%97-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"K8S的label和annotation区别","text":"概述label 和 annotation 都可以将元数据关联到 Kubernetes 的资源对象。与资源对象相关的事务与动作。label 主要用于来选择对象，可以指定满足特定条件的对象。但是 annotation 不能标识和选择对象。annotation 中的元数据可以是结构化或者非结构化的，也可以包含 label 中不允许出现的字符。 资源对象的名称 ( Name ) 、标签、注解这三个属性属于资源对象的元数据(metadata) 数据结构两者都是 key-value 键值对的形式： 123annotations: key1: value1 key2: value2 123labels: key1: value1 key2: value2 labellabel 是附着到资源对象上（例如 Pod ）的键值对。可以在创建资源对象的时候指定，也可以在资源对象创建后随时指定。labels 的值对系统本身并没有什么含义，只是对用户才有意义。 123labels: key1: value1 key2: value2 Kubernetes 最终将对 labels 最终索引和反向索引用来优化查询和 watch，在 UI 和命令行中会对它们排序。不要在 label 中使用大型、非标识的结构化数据，记录这样的数据应该用 annotation。 一般配合 label selector 使用。 annotationannotation 可以将 Kubernetes 资源对象关联到任意的非标识性元数据。使用客户端（如工具和库）可以检索到这些元数据。 123annotations: key1: value1 key2: value2 以下列出了一些可以记录在 annotation 中的对象信息： 声明配置层管理的字段。使用 annotation 关联这类字段可以用于区分以下几种配置来源：客户端或服务器设置的默认值，自动生成的字段或自动生成的 auto-scaling 和 auto-sizing 系统配置的字段。 创建信息、版本信息或镜像信息。例如时间戳、版本号、git 分支、PR 序号、镜像哈希值以及仓库地址。 记录日志、监控、分析或审计存储仓库的指针 可以用于 debug 的客户端（库或工具）信息，例如名称、版本和创建信息。 用户信息，以及工具或系统来源信息、例如来自非 Kubernetes 生态的相关对象的 URL 信息。 轻量级部署工具元数据，例如配置或检查点。 负责人的电话或联系方式，或能找到相关信息的目录条目信息，例如团队网站。 如果不使用 annotation，也可以将以上类型的信息存放在外部数据库或目录中，但这样做不利于创建用于部署、管理、内部检查的共享工具和客户端库。 参考 《Kubernetes权威指南第5版》 https://jimmysong.io/kubernetes-handbook/concepts/annotation.html https://jimmysong.io/kubernetes-handbook/concepts/label.html","link":"/2021-10-K8S%E7%9A%84label%E5%92%8Cannotation%E5%8C%BA%E5%88%AB/"},{"title":"VMware PRO 16 复制虚拟机","text":"对于在本地快速搭建一套分布式节点，无须重新从头开始创建虚拟机，可以通过 VMware WorkStation 快照的方式来快速创建一台机器。 单机 node01 ，右键，选择“快照”——&gt; “拍摄快照” 单机 node01 ，右键，选择“管理”——&gt; “克隆”，点击“下一页” “克隆源”页面，选择“现有快照（仅限关闭的虚拟机）”，选择刚才创建的“basic”，点击“下一页” “克隆类型”页面，选择“创建链接克隆”，点击“下一页” “新虚拟机名称”页面，自定义虚拟机名称和存储位置，点击“完成” 等待克隆完成，左侧“我的计算机”列表里面会出现克隆的虚拟机，这里是“node02” 网络配置，因为网络配置的静态 IP，所以需要配置 IP 地址，步骤跟创建虚拟机一样 修改静态IP123cd /etc/sysconfig/network-scriptsvi ifcfg-ens33 只需要修改 IPADDR = 192.168.170.112 即可 修改 hostname修改 /etc/hosts 和 /etc/sysconfig/network CentOS 7.8 如果两个文件已经不能生效，请用下面的命令修改hostnamectl set-hostname {your-custom-hostname} 重启网络服务service restart network执行 ping www.baidu.com 测试，网络畅通","link":"/2021-10-VMwarePro16%E5%A4%8D%E5%88%B6%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"title":"MongoDB GridFS 存储文件","text":"前言在开发中，会碰到存储图片或者视频的问题，也就是大文件存储的问题，能想到的有三种解决方式： 本地文件系统 数据库，比如 MongoDB 云存储，比如 Amazon S3 其他两种都比较好理解，现在想来看一下 MongoDB 是怎么来存储图片或者视频的。看到官网的文档（版本是 5.0）是如果文件大小 &lt; 16MB，一个文档是可以存的下的，超过 16MB 的话需要用 GridFS。 关于 GridFSGridFS 是 MongoDB 中存储超过 16M 文件的存储方式和约定，实现的思路就是分而治之。GridFS 默认的块（chunk）大小为 256kB，用两个 collection（chunks） 去存文件，一个 collection（files） 来存储切分的 chunk，另外一个 collection 来存储文件的元数据。这两个 collection 都在同一个 bucket 名为 fs 下。 什么时候用 GridFS在 MongoDB 中，虽然使用 GridFS 来存储超过 16MB 大小的文件，但是有些情况下，用 MongoDB 来存储文可能比本地文件系统来存储有效的多。官方文档给了下面三种情况： 本地文件系统有文件或者目录的限制，GridFS 没有限制 不需要拿整个文件加载到内存就可以取到文件的所需要的部分数据，GridFS 可以做到。 文件自动同步，尤其在分布式的应用上。 怎么使用 GridFS基于 spring boot 搭建的示例项目来展示一下: 配置 123456789# 配置上传单个文件大小无限制spring.servlet.multipart.max-file-size=-1# 配置上传总大小无限制spring.servlet.multipart.max-request-size=-1# MongoDB 的配置spring.data.mongodb.uri=mongodb://root:root123@127.0.0.1:27017spring.data.mongodb.database=testspring.data.mongodb.gridfs.database=uploads thymeleaf 模板页面代码 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;html xmlns:th=&quot;https://www.thymeleaf.org&quot;&gt;&lt;body&gt;&lt;h1&gt;&lt;font color=&quot;blue&quot;&gt;上传文件到 MongoDB &lt;/font&gt; &lt;/h1&gt;&lt;div th:if=&quot;${message}&quot;&gt; &lt;h2 th:text=&quot;${message}&quot;/&gt;&lt;/div&gt;&lt;div&gt; &lt;form method=&quot;POST&quot; enctype=&quot;multipart/form-data&quot; action=&quot;/gridFs/upload&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;File to upload:&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;file&quot; name=&quot;file&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;submit&quot; value=&quot;Upload&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt; &lt;form method=&quot;POST&quot; action=&quot;/gridFs/delete&quot;&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;input type=&quot;submit&quot; value=&quot;deleteAll&quot;/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/div&gt;&lt;div&gt; &lt;ul&gt; &lt;li th:each=&quot;file : ${files}&quot;&gt; &lt;a th:href=&quot;@{'http://127.0.0.1:8080/gridFs/' + ${file} + '/download'}&quot; th:text=&quot;${file}&quot;/&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Controller 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Controller@RequestMapping(&quot;/gridFs&quot;)public class GridFsController { private final GridFsService gridFsService; @Autowired public GridFsController(GridFsService gridFsService) { this.gridFsService = gridFsService; } // 主页 @GetMapping(&quot;/&quot;) public String listUploadFiles(Model model) { model.addAttribute(&quot;files&quot;, gridFsService.loadAllFiles()); return &quot;gridFsForm&quot;; } // 上传接口 @PostMapping(&quot;/upload&quot;) public String handleFileUpload(@RequestParam(&quot;file&quot;) MultipartFile file, RedirectAttributes redirectAttributes) { final long start = System.currentTimeMillis(); gridFsService.upload(file, &quot;user&quot; + new Random().nextInt(100)); final long end = System.currentTimeMillis(); final long period = end - start; final long t = period / 1000; redirectAttributes.addFlashAttribute(&quot;message&quot;, &quot;You successfully uploaded &quot; + file.getOriginalFilename() + &quot;!&quot; + &quot; spent time : &quot; + ( t &lt; 1 ? period + &quot;ms&quot; : t + &quot;s&quot;)); return &quot;redirect:/gridFs/&quot;; } // 下载接口 @GetMapping(&quot;/{filename}/download&quot;) @ResponseBody public ResponseEntity&lt;Resource&gt; serverFile(@PathVariable String filename) { Resource file = gridFsService.download(filename); return ResponseEntity.ok() .header(HttpHeaders.CONTENT_DISPOSITION, &quot;attachment; filename=\\&quot;&quot; + URLEncoder.encode(file.getFilename(), StandardCharsets.UTF_8) + &quot;\\&quot;&quot;) .body(file); } // 删除所有的文件接口 @PostMapping(&quot;/delete&quot;) public String deleteAllFiles(RedirectAttributes redirectAttributes) { gridFsService.deleteAll(); redirectAttributes.addFlashAttribute(&quot;message&quot;, &quot;You successfully deleted all files !&quot;); return &quot;redirect:/gridFs/&quot;; }} Service 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243@Componentpublic class GridFsServiceImpl implements GridFsService { @Autowired GridFsTemplate gridFsTemplate; @Override public void upload(MultipartFile file, String name) { final String fileName = file.getName(); System.out.println(fileName); final BasicDBObject basicDBObject = new BasicDBObject(); basicDBObject.put(&quot;user&quot;, name); ObjectId objectId = null; try { objectId = gridFsTemplate.store(file.getInputStream(), file.getOriginalFilename(), file.getContentType(), basicDBObject); } catch (IOException e) { e.printStackTrace(); } System.out.println(&quot;object id:&quot; + objectId.toString()); } @Override public List&lt;String&gt; loadAllFiles() { List&lt;GridFSFile&gt; gridFSFiles = new ArrayList&lt;&gt;(); gridFsTemplate.find(new Query()).into(gridFSFiles); final List&lt;String&gt; files = gridFSFiles.stream().map(GridFSFile::getFilename).collect(Collectors.toList()); return files; } @Override public Resource download(String fileName) { final GridFsResource[] resources = gridFsTemplate.getResources(fileName + &quot;*&quot;); return resources[0]; } @Override public void deleteAll() { gridFsTemplate.delete(new Query()); }} 演示","link":"/2021-10-MongoDB%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6/"},{"title":"VMware PRO 16 安装虚拟机-自定义分区","text":"通常我们都是按照经典的方式安装虚拟机，由 VMware 自动帮我们分区，没有必要，我们可以选择自定义分区的方式去安装虚拟机，更加充分的利用空间。 在安装完 VMware Workstation 以后，打开页面如下： 点击“创建新的虚拟机”，选择“自定义(高级)(C)”选项，选择“下一步” “选择虚拟机硬件兼容性”页面，默认设置，继续“下一步” “安装客户机操作系统”页面，选择“稍后安装操作系统”，点击“下一步” “选择客户机操作系统”页面，选择“Linux(L)”，版本选择“CentOS 7 64位”，需要根据已经下载好的 iso 文件版本来选择， 点击“下一步” “命名虚拟机”页面，命名虚拟机名字，会在左侧“我的计算机”列表中显示该名称。修改虚拟机存放的位置，可以默认。 如果C盘是固态硬盘且空间足够，可以放在C盘，加快速度。然后点击“下一步” “处理器配置”页面，处理器数量选择“1”就行了，默认值，然后点击“下一步” “此虚拟机的内存” 页面，内存设置成 1G就行了，点击“下一步” “网络类型”页面，默认选择“使用网络地址转换(NAT)(E)”，点击“下一步” “选择I/O控制器类型”页面，默认，点击“下一步” “选择磁盘类型”页面，默认，点击“下一步” “选择磁盘”页面，默认，点击“下一步” “指定磁盘容量”页面，设定最大磁盘大小为30GB，可以设置成更大的值，这里的值并不是一下就分配30GB空间，而是用多少分配多少，直到最大的值。选择“将虚拟磁盘拆分成多个文件”，点击“下一步” “指定磁盘文件”页面，默认，点击“下一步” “已准备好创建虚拟机”页面，点击“自定义硬件”，弹出“硬件”配置窗口 “硬件”页面，左侧选择“新CD/DVD（IDE）”选项， 右侧选择“使用ISO映像文件”，选择本地的 ISO 文件，点击“关闭” 最后点击“完成”，左侧我的计算机列表里会出现“node01”虚拟机 点击“开启此虚拟机”，进入安装页面 选择语言“English”，点击“Continue” 设置“NETWORK &amp; HOST NAME”,定义hostname，这里取“node01”，网络配置，后面再配，这里先点击“apply”，然后点击“Done” 设置“INSTALLATION DESTINATION”，选择“I wil configurepartitioning”，点击“Done”，进入到磁盘分区页面，添加一个分区，选择“/boot”，该区是引导程序的安装目录，分配“512mb”大小，点击“Addmount point” 选中 “/boot”，设置分区格式， “Device Type”选择 “StandardPartition”，“File System”选择“ext4” 添加一个分区，选择“swap”，该区是内存和磁盘的交换空间，分配“2GB”大小，点击“Add mount point”，“swap”分区的格式，默认即可 添加一个分区，选择根目录“/”，“DesiredCapacity“填“max”，即剩下的所有空间都分配给根目录，点击“Add mountpoint“。“Device Type”选择 “LVM”，“File System”选择“ext4” 选中 “/boot”，设置分区格式，“Device Type”选择 “LVM”，“FileSystem”选择“ext4” 分区设置好以后，点击左上角“Done”，弹出“SUMMARY OFCHANGES”框，点击“Accept Changes” 分区完成以后，点击“Begin Installation”，就会进入安装过程。 设置 root 的密码，等待系统安装完成。 安装完成后，点击“Reboot” 重启后，用 root 用户登录，输入密码即可，此时，CentOS 系统已经安装完毕。但是网络不通。 配置网络 [root@node01 \\~]\\# cd /etc/sysconfig/network-scripts/ 找到 ifcfg-ensXX， [root@node01 network-scripts]\\# vi ifcfg-ens33 修改属性： 属性 修改前值 修改后值ONBOOT no yesBOOTPROTO dhcp static 增加属性： 属性 值IPADDR 192.168.170.111NETMASK 255.255.255.0GATEWAY 192.168.170.2DNS1 114.114.114.114 192.168.170.xxx前三段来源于 ： VMware Workstation 菜单“编辑”–&gt; “虚拟网络编辑器(N)”选项， VMnet8 子网地址的前三段，“xxx”段自定义，从0~255任意，但是0,1,255 是保留段，不要用。 192.168.170.2中170 来源同上，其他保持一致。 修改完成后，需要重新启动网络服务，执行命令: service network restart ping 一下百度，可以看到能够联网了。 关闭防火墙 service iptables stop 设置防火墙开机不启动 如果遇到问题：Ncat: No route to host. 防火墙的问题 1:查看防火状态 systemctl status firewalld service iptables status 2:暂时关闭防火墙 systemctl stop firewalld service iptables stop 3:永久关闭防火墙 systemctl disable firewalld chkconfig iptables off 4:重启防火墙 systemctl enable firewalld service iptables restart","link":"/2021-10-VMwarePro16%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"title":"VMware PRO 16 配置共享文件夹","text":"安装 open-vm-tools（CentOS 为例）yum install open-vm-tools open-vm-tools-desktop 设置共享文件夹 查看共享文件夹 vmware-hgfsclient 挂载共享文件夹 sudo vmhgfs-fuse .host:/shared_file /mnt/hgfs其中： shared_file 就是上图中选择的文件夹名称，git。以上图为例，此处我应该将 your_shared_file 替换为 Linux /mnt/hgfs 是挂载点，安装好 open-vm-tools 会自动生成此目录文件。 比如我的虚拟机上： vmhgfs-fuse .host:/caolizhi-personal /mnt/hgfs 设置开机自动挂载 每次关机后，就需要重新挂载。可在文件 /etc/fstab 中添加如下一行：.host:/your_shared_file /mnt/hgfs fuse.vmhgfs-fuse defaults 0 0 比如我的虚拟机上： .host:/caolizhi-personal /mnt/hgfs fuse.vmhgfs-fuse defaults 0 0","link":"/2021-10-VMwarePro16%E9%85%8D%E7%BD%AE%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"title":"JVM 系列 —— class 文件格式","text":"这是 JVM 系列的第二篇，见 JVM 系列。 在前面的 jvm 基础中，了解了 jvm 的组成等一些基础知识，在 java 程序执行的流程中， .java 文件编译成 .class 文件，那么这个 class 文件到底长什么样子，这篇文章主要就是来介绍一个 class 文件的是什么样的格式。主要参考的是 《java 虚拟机规范 JavaSE 8版》这本书。为了方便看到 class 文件，可以在 IDEA 上装一个插件 jclasslib，格式化了 class 文件，当然也可以用命令 javap -v xxx.class 来查看。还可以下载 Java Byte Editor工具来查看，甚至修改字节码。 总览下面这张图是一个正确的 class 文件应该有的格式，以及里面的个项的含义： 首先提两点 class 加载后到哪里去了？方法区。我们知道 java 在类加载之后，会有一个jvm 运行时的内存区域，主要包括 jvm 栈，native 栈，PC，方法区，堆。 方法区实际上就是保存类编译之后的文本代码段，类似于操作系统进程中的 text segment 文本段，存储的是每一个类的结构信息， 里面保存了运行时常量池、类的元数据、字段、构造方法、普通方法等信息。方法区是堆的一个组成部分，只是一个逻辑概念，一般来说，不对方法区进行一个垃圾回收。 运行时常量池是个什么东东？是 class 文件中每一个类或者接口的常量池表（constant_pool table）的运行时的表示形式。类似于计算机系统中的符号表（symbol table）。 class 文件格式每一个 class 文件都对应这唯一一个类或接口的信息，但是并不是都是以磁盘文件 .class 的形式存在，也可以通过类加载器直接生成，一个有效的类或接口所满足的格式统称为“class 文件格式”。 每个 class 都是有字节流组成。这些字节流或以1个字节、2个字节、4个字节等组合而成，中间没有空格或对齐，并且多字节的数据项是以big-edian(大端在前，高位字节在地址的最低位，低位字节在地址的最高位)的顺序进行存储。用 u1，u2，u4 专用的数据类型来表示 class文件的内容，分别表明 1，2，4个字节的无符号数。 class 文件格式各个结构体的内容成为 项（items），比如：u4 magic;，如果由长度不定的项组成的结构称为表（table），用于表示 class 文件内容中的复杂的结构，并且以数组的形式存在。比如：cp_info constant_pool ClassFile 结构每一个 class 文件都对应一个 ClassFile 的结构： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 ClassFile { // 魔数，固定值 0xCAFEBABE，是不是 class 文件的检验标志 u4 magic; // 副版本号，比如 0 u2 minor_version; /* 主版本号，比如 jdk 11 的主版本号是：55 和次版本号配合使用，判断这个 class 文件是否被此虚拟机支持，比如 jdk1.8 默认 52.0，jdk11 默认 55.0 */ u2 major_version; // 常量池计数器，值是常量池表的大小+1 u2 constant_pool_count; /* 常量池表， 常量池索引 0 是无效的，所以常量池表的数组索引范围是： 1 ~ constant_pool_count-1 但是其他使用到常量池的数据结构可以使用索引 0 来表明：“不引用任何一个常量池” 包含 class文件结构机器子结构中引用的所有字符串常量、类或接口、字段名和其他常量 并且每一个项的第一个字节作为类型标记，用于确定该项的格式，这个字节称为标记字节（tag byte） */ cp_info constant_pool[constant_pool_count-1]; /*表结构*/ // 访问标志，表明类或接口的访问权限以及属性 u2 access_flags; /* 类索引，值是对常量池中的某个项的一个有效索引值 常量池在这个索引处的成员必须为 CONSTANT_Class_info 类型结构体，该结构体表示这个 class 文件所定义的类或接口 */ u2 this_class; /* 父类索引，值要么是 0，要么是常量池中的某个项的一个有效索引值，如果是 0 ，那么这个类就是 Object 类，唯一没有父类的类。 如果不是 0，那么常量池在这个索引出的成员必须为 CONSTANT_Class_info 类型结构体，表示这个 class 文件定义的类的直接父类，如果这个 class 是接口的话，那么 CONSTANT_Class_info 代表的就是 Object 的结构。 */ u2 super_class; // 接口计数器，当前类或接口的直接父接口的数量 u2 interfaces_count; /* 接口表，数组，里面每一个成员值都是常量池中的某项的有效索引值，长度为 `interfaces_count` 每个成员的结构都是 CONSTANT_Class_info 类型，数组成员的顺序和源代码里面的接口顺序一致 */ u2 interfaces[interfaces_count]; // 字段计数器，当前 class 文件的 fields 表的成员个数 u2 fields_count; // 字段表，fields表描述的是当前类的所有字段信息，不包括父类和父类继承的那些字段，其中的每一个成员的类型都是 field_info 结构数据项，表示该类或接口所声明的类字段或者实例字段（是否是 static 修饰） field_info fields[fields_count]; // 方法计数器，下面 methods 表的成员个数 u2 methods_count; /* 方法表， methods 表描述的是当前类的所有方法信息，包括实例方法、类方法、构造方法，实例初始化方法或类和接口初始化方法，不包括父类和父类继承的方法 其中的每一个成员的类型都是 method_info */ method_info methods[methods_count]; // 属性计数器，当前 class 文件属性表的成员个数 u2 attributes_count; // 属性表，每一个项的值必须是 attribute_info 结构，常见的泛型、注解都属于 attribute_info attribute_info attributes[attributes_count]; } 补充说明 access_flags （访问标志）每个标志的取值和含义如下： 标志名 值 含义 ACC_PUBLIC 0x0001 声明为 public，可以从包外访问 ACC_FINAL 0x0010 声明为 final，无法继承 ACC_SUPER 0x0020 当用到 invokespecial 指令的时候，需要对父类方法做特殊处理，invokespecial在 JDK1.0.2 发生了改变，为了避免二义性，之后编译的 class 都带该标志 ACC_INTERFACE 0x0200 该 class 文件定义的是接口而不是类 ACC_ABSTRACT 0x0400 声明为抽象类，不能实例化 ACC_SYNTHETIC 0x1000 声明为 synthetic，java 代码中并没有该修饰类型，是由编译器生成的，与 private 修饰符有关系 ACC_ANNOTATION 0x2000 标识注解类型 ACC_ENUM 0x4000 标识枚举类型 ACC_MODULE 0x8000 jdk8 没有，从 jdk9 开始，该类是一个 module，不是类也不是接口，会特殊处理 一个 class 的 access_flags 由这些标志互斥或组合而成，具体可以看 jvm 的规范。 类名称的内部表示形式class 文件结构中出现的类或者接口的名称，都是通过全限定的形式（fully qualified form）来表示， 称为二进制名称，这个名称使用 CONSTANT_Utf8_info 来表示。比如： 类或者接口的二进制名称会被 CONSTANT_NameAndType_info 结构所引用，以便构成它们的描述符。 分隔标识符的符号是斜杠 “/”。 这里注意的是全限定名称和非限定名称： 全限定名在整个 JVM 中绝对名称，比如： java.lang.Object，类似于绝对路径。 非限定名方法名，字段名，局部变量名和形式参数名都是用非限定名来保存的。比如： Object。 描述符字段描述符字段描述符的格式：FieldType 对于基本类型的字段，class 文件中的描述格式为：B C D F I J S Z 之一，比如类中的字段 int field, calss 文件描述符为：I，对于对象类型的字段，描述格式为： L ClassName;，比如类中字段 String field，class 文件描述为：Ljava/lang/String;对于数组类型的字段，描述格式为：[ Component Type，比如类中字段 String[] array，class 文件描述符为：[Ljava/lang/String;，如果是三维数组String[][][] f array，那么描述符为 [[[Ljava/lang/String;。 字段描述符解释表： FieldType 中的字符 类型 含义 B byte 有符号的字节型数 C char Unicode 字符码点， UTF-16编码 D double 双精度浮点型 F float 单精度浮点型 I int 整型数 J long 长整数 L ClassName ; reference ClassName 的实例引用 S short 有符号的短整数 Z boolean 布尔值 true 、 false [ reference 一个一维数组 方法描述符class 文件中方法的描述符格式为：（方法形参描述符）返回类型返回类型有两种，无返回值用 V 表示。举例说明： 12public String methodReturn(int i, String d, Thread t) {...}public void methodVoid(int i, String d, Thread t) {...} 上面两个方法，在 class 文件中的描述符分别为：(ILjava/lang/String;Ljava/lang/Thread;)Ljava/lang/String;(ILjava/lang/String;Ljava/lang/Thread;)V 值得一提的是，静态方法和非静态方法的描述符都是一样的，实例方法除了传递参数以外，还需要传递参数 this ，这一点方法描述无法表明，通过 jvm 虚拟机调用实例方法指令来实现的。 常量池java 虚拟机指令不依赖于类、类实例、接口或者数组的运行时的布局，而是依赖常量池表中的符号信息 class 文件中有个常量池表 cp_info， 它的里面的每个项都是如下的模板： 1234cp_info { u1 tag ; u2 info [ ] ; } tag 里面的值决定了 info[ ] 数组里面存放的信息，tag 的说明如下表： 常量类型 tag 值 CONSTANT_Class 7 CONSTANT_Fieldref 9 CONSTANT_Methodref 10 CONSTANT_InterfaceMethodref 11 CONSTANT_String 8 CONSTANT_Integer 3 CONSTANT_Float 4 CONSTANT_Long 5 CONSTANT_Double 6 CONSTANT_NameAndType 12 CONSTANT_Utf8 1 CONSTANT_MethodHandle 15 CONSTANT_MethodType 16 CONSTANT_InvokeDynamic 18 jdk 11 相对于 jdk 8 新增了一些： 常量类型 tag 值 CONSTANT_Dynamic 17 CONSTANT_Module 19 CONSTANT_Package 20 单独拿最常见的项 CONSTANT_Utf8_info 来说明一下，该项用于表示字符常量的值，它的结构如下： 12345CONSTANT_Utf8_info { u1 tag; u2 length; u1 bytes[length];} tag ： 由上面的表可知，这里的 tag 项的值为 CONSTANT_Utf8(1)length ：length 项的值指明了 bytes[] 数组的长度bytes：表示字符串值得 byte 数组 字段class 文件中的每个字段 field 都是由 field_info定义，结构如下： 1234567field_info { u2 access_flags; u2 name_index; u2 descriptor_index; u2 attributes_count; attribute_info attributes[attributes_count];} 里面的项的含义跟上面的差不多，不过多的解释。xxx_index 都是对常量池的一个有效的索引值。attributes_count 表示对当前字段的附加属性的数量，比如加了注解的字段 方法1234567method_info { u2 access_flags; u2 name_index; u2 descriptor_index; u2 attributes_count; attribute_info attributes[attributes_count];} 里面的一些含义和字段基本相同。 属性属性在 ClassFile 结构中以及字段表和方法表中都在使用，它的结构格式如下： 12345attribute_info { u2 attribute_name_index; u4 attribute_length; u1 info[attribute_length];} jdk8 有 23 种属性， jdk11 有 28种属性。这些属性主要分为三类： 对 jvm 虚拟机解读 class 文件有关键作用的属性； 对 jdk类库解读 class 文件有关键作用的属性； 使用的工具类属性； 着重来看一下，我们最常接触到的属性 Code_attribute，位于 method_info 结构的属性表中，包含某个方法、实例初始化方法、类或接口初始化方法的 java 虚拟机指令以及相关信息。 它的结构如下： 12345678910111213141516Code_attribute { u2 attribute_name_index; u4 attribute_length; u2 max_stack; u2 max_locals; u4 code_length; u1 code[code_length]; u2 exception_table_length; { u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; } exception_table[exception_table_length]; u2 attributes_count; attribute_info attributes[attributes_count];} 这里面最重要就是 code[] 数组，这里面保存的就是实现该方法的 jvm 代码的字节码内容。举例说明： 格式检查综上所述，jvm 在加载类之前会进行格式检查，主要做以下的检查： 魔数 常量池的格式和约束 常量池中的所有引用名称必须符合规范 属性的格式检查 class 不能有多余的字节 这里只是格式检查，并不对比如某个在不在类中进行检查，这种字节码检查会在加载之后。两中检查互不相干。 Java 虚拟机代码约束虚拟机规范规定了代码的两种约束：静态约束和结构化约束。这两种约束都是对 class文件中 method_info 结构里面的 Code_attribute 的约束。java 的普通方法、初始化方法（包括实例、类或接口初始化方法）的代码的虚拟机指令保存在这里。 静态约束静态约束主要是对 Code_attribute 里面的 code 数组中的 java 虚拟机指令进行约束。规定了排序和某些指令必须要有操作数。 结构化约束这里的约束主要是对 jvm 虚拟机指令之前的关系进行了规定，比如： 所有的指令都只能在虚拟机栈的栈帧的操作数栈和局部变量表中进行操作。再比如如果指令可以操作 int 类型的值，那同样也可以操作 boolean、byte、char、short 类型的值。 java 虚拟机内部都会把 boolean、byte、char、short 转成 int 类型。 调用实例方法或实例变量之前，这个实例已经初始化过的。还有很多约束，见java虚拟机规范详细说明。 class 文件校验上面所说的规范和约束都是为了保证能生成一个正确的 class 文件。但是大多数情况下，我们拿 class 文件过来直接跑应用的，并不会拿源码编译，然后再跑，所以拿到的并不是正确的 class 文件，java 虚拟机还是要自己校验，会在 链接 阶段对 class 文件进行校验来判断是否满足上面说的那些约束。 还需要额外做三项检查： 保证 final 类没有子类。 保证 final 方法没有被重写。 除了 Object 类之外的其他类，都有直接超类。 一句话只有符合规范和约束的 class 文件才能被正确解析和加载。","link":"/2021-11-JVM%E7%B3%BB%E5%88%97-class%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"title":"K8S集群安装动态存储 GlusterFS","text":"K8S 存储介绍 简介在 K8S 中，对容器所应用的存储资源抽象为存储卷 Volume。它的生命周期与 POD 相同，POD 中的容器如果要使用某个 Volume，需要通过 volumeMounts来指定某个 volume 或者 多个 volume 挂载到容器的目录或文件。那么就可以从容器中访问 volume 中的数据。 K8S支持内部资源对象类型、开源共享存储类型等，K8S管理宿主机的本地存储类型， EmptyDir 和 HostPath，前者为临时目录，后者为宿主机目录。内部资源对象最常见的就是持久化存储 PV，开源共享存储类型就有很多，比如： CephFS 开源共享存储系统 Glusterfs 开源共享存储系统 CSI（Container Storage Interface，容器存储接口）由存储提供商提供驱动程序和管理程序 FlexVolume 一种基于插件式驱动的存储 其他 EmptyDir 是在 pod 被调度到 node 时创建，在初始状态下目录中是空的，与 pod 的生命周期相同。 持久卷K8S 通过 Persistent Volume(PV) 和 Persistent Volume Claim(PVC) 两个资源对象来管理存储的资源。这样做的好处是屏蔽了对底层存储的实现细节。PV 是对存储资源的一种抽象，PV 是由管理员创建和配置的，与具体的厂商有关。PV 的生命周期与 POD 的生命周期分开的。 PVC 是对 PV 资源的一种申请。但是 PVC 无法表明哪种存储是什么样的特性，应用程序会根据自己的特点去选择相应的存储资源，包括读写的速度啊，并发性能等。 K8S 引入了一个新的资源对象 StorageClass 用来标记存储资源的特点和性能，动态选择合适的 PV 资源。管理员通过 StorageClass 来定义存储资源的 profile，然后应用程序根据自己的需求去申请相应的存储资源就可以了。 另外从 1.9 版本开始，K8S 引入了 CSI 机制，就是提供了一个借口，具体实现由各自存储厂商实现，解耦存储相关的代码，之前的存储代码是内嵌的，必须要修改代码才能提供相应的存储资源。 pod 通过 persistentVolumeClaim 使用PVC，会通过定义的 StorageClass 来动态绑定需要使用的存储类型，如果没有 PV，那么 PVC 会处在 Pending 的状态， 删除 PVC 时，只有与其绑定的 POD 删除时，才会删除，删除 PV 时，只有与其绑定的 PVC 删除了才会被删除。PVC 和 PV 是一对一的绑定关系。 POD 使用 PVC系统在 pod 所在的 namespace 中找到 pod 所配置的 PVC，然后再通过 PVC 绑定 PV，将 PV 存储挂载到 pod 所在的 node 的目录下，最后再将 node 的目录挂载到 pod 的容器内。 GlusterFS 安装 glusterfs在用于 GlusterFS 的 node 上安装 glusterfs，执行：yum install glusterfs glusterfs-fuse 然后给相应的 node 打上一个标签，为了将 GlusterFS 容器定向部署到安装了 GlusterFS 的 node 上。执行：kubectl label node node02 storagenode=glusterfskubectl label node node03 storagenode=glusterfskubectl label node node04 storagenode=glusterfs 删除标签用命令：kubectl label node &lt;node-name&gt; &lt;label-key&gt;- 创建 GlusterFS 管理服务GlusterFS 以 DaemonSet 方式进行部署，内容如下： glusterfs-daemonset.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798apiVersion: apps/v1kind: DaemonSetmetadata: name: glusterfs labels: glusters: damonset annotations: description: GlusterFS DaemonSet tags: glusterfsspec: selector: matchLabels: glusterfs-node: pod template: metadata: name: gulsterfs labels: glusterfs-node: pod spec: nodeSelector: storagenode: glusterfs hostNetwork: true containers: - image: gluster/gluster-centos:latest name: glusterfs volumeMounts: - name: glusterfs-heketi mountPath: &quot;/var/lib/heketi&quot; - name: glusterfs-run mountPath: &quot;/run&quot; - name: glusterfs-lvm mountPath: &quot;/run/lvm&quot; - name: glusterfs-etc mountPath: &quot;/etc/glusterfs&quot; - name: glusterfs-logs mountPath: &quot;/var/log/glusterfs&quot; - name: glusterfs-config mountPath: &quot;/var/lib/glusterd&quot; - name: glusterfs-dev mountPath: &quot;/dev&quot; - name: glusterfs-misc mountPath: &quot;/var/lib/misc/glusterfsd&quot; - name: glusterfs-cgroup mountPath: &quot;/sys/fs/cgroup&quot; readOnly: true - name: glusterfs-ssl mountPath: &quot;/etc/ssl&quot; readOnly: true securityContext: capabilities: {} privileged: true readinessProbe: timeoutSeconds: 3 initialDelaySeconds: 60 exec: command: - &quot;/bin/bash&quot; - &quot;-c&quot; - systemctl status glusterd.service livenessProbe: timeoutSeconds: 3 initialDelaySeconds: 60 exec: command: - &quot;/bin/bash&quot; - &quot;-c&quot; - systemctl status glusterd.service volumes: - name: glusterfs-heketi hostPath: path: &quot;/var/lib/heketi&quot; - name: glusterfs-run hostPath: path: &quot;/run&quot; - name: glusterfs-lvm hostPath: path: &quot;/run/lvm&quot; - name: glusterfs-etc hostPath: path: &quot;/etc/glusterfs&quot; - name: glusterfs-logs hostPath: path: &quot;/var/log/glusterfs&quot; - name: glusterfs-config hostPath: path: &quot;/var/lib/glusterd&quot; - name: glusterfs-dev hostPath: path: &quot;/dev&quot; - name: glusterfs-misc hostPath: path: &quot;/var/lib/misc/glusterfsd&quot; - name: glusterfs-cgroup hostPath: path: &quot;/sys/fs/cgroup&quot; - name: glusterfs-ssl hostPath: path: &quot;/etc/ssl&quot; 在 master 节点上执行，kubectl create -f glusterfs-daemonset.yaml， 然后查看是否生成资源，查看 glusterfs 的服务容器的pod： 123[root@node01 k8s]# kubectl get poNAME READY STATUS RESTARTS AGEglusterfs-wvlw2 1/1 Running 1 (15m ago) 20m 然后再 describe 一下 pod，我本地有四个节点，一个master（node01），三个 worker（node02,node03，node04），worker 上都安装了 GlusterFS 服务，那么 pod glusterfs-wvlw2 应该只在 node03 上存在，yaml 如下： 1234567891011121314[root@node01 k8s]# kubectl describe pod glusterfs-wvlw2Name: glusterfs-wvlw2Namespace: defaultPriority: 0Node: node03/192.168.170.113 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; node03 上Start Time: Wed, 03 Nov 2021 15:51:21 +0800Labels: controller-revision-hash=6ffb8b879 glusterfs-node=pod pod-template-generation=1Annotations: &lt;none&gt;Status: RunningIP: 192.168.170.113IPs: IP: 192.168.170.113 创建 Heketi 服务Heketi 提供了 RESTful API 管理 GlusterFS 卷的框架，方便对 GlusterFS 的管理。 给 Heketi 创建一个 ServiceAccount，完成 RBAC 授权kubectl create -f heketi-rbac.yaml，yaml 内容如下： heketi-rbac.yaml 12345678910111213141516171819202122232425262728293031323334353637383940---apiVersion: v1kind: ServiceAccountmetadata: name: heketi-service-account---apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: heketirules: - apiGroups: - &quot;&quot; verbs: - get - list watch resources: - endpoints - services - pods - apiGroups: - &quot;&quot; verbs: - create resources: - pods/exec---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: heketiroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: heketisubjects: - kind: ServiceAccount name: heketi-service-account namespace: default 部署 heketi 服务kubectl create -f heketi-deployment-svc.yaml，yaml 内容如下： heketi-deployment-svc.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475 # heketi-deployment-svc.yaml---apiVersion: apps/v1kind: Deploymentmetadata: name: heketi labels: glusterfs: heketi-deployment deploy-heketi: heketi-deployment annotations: description: Defines how to deploy Heketispec: replicas: 1 selector: matchLabels: name: deploy-heketi glusterfs: heketi-pod template: metadata: name: deploy-heketi labels: name: deploy-heketi glusterfs: heketi-pod spec: serviceAccountName: heketi-service-account containers: - image: heketi/heketi name: deploy-heketi env: - name: HEKETI_EXECUTOR value: kubernetes - name: HEKETI_FSTAB value: &quot;/var/lib/heketi/fstab&quot; - name: HEKETI_SNAPSHOT_LIMIT value: &quot;14&quot; - name: HEKETI_KUBE_GLUSTER_DAEMONSET value: &quot;y&quot; ports: - containerPort: 8080 volumeMounts: - mountPath: &quot;/var/lib/heketi&quot; name: db readinessProbe: timeoutSeconds: 3 initialDelaySeconds: 3 httpGet: port: 8080 path: &quot;/hello&quot; livenessProbe: timeoutSeconds: 3 initialDelaySeconds: 3 httpGet: port: 8080 path: &quot;/hello&quot; volumes: - name: db hostPath: path: &quot;/heketi-datae&quot;---kind: ServiceapiVersion: v1metadata: name: heketi labels: glusterfs: heketi-service deploy-heketi: support annotations: description: Expose Heketi Servicespec: selector: name: deploy-heketi ports: - port: 8080 targetPort: 8080 name: deploy-heketi 通过 Heketi 管理 GlusterFS 集群在使用 Heketi 之前，需要配置文件来表明 GlusterFS 集群的信息，用 topology.json 来表示，如下所示。其中 manage 表示主机名，storage 表示 IP， devices 表示未创建文件系统的裸磁盘（可以关闭虚拟机，然后设置虚拟机，增加一块磁盘，打开虚拟机之后，lsblk， 就能看到 /dev/sdb 的磁盘），这样 Heketi 自动完成 PV（Physical Volume）、VG（Volume Group）和 LV（Logical Volume）的创建。 topology.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 { &quot;clusters&quot;: [ { &quot;nodes&quot;: [ { &quot;node&quot;: { &quot;hostnames&quot;: { &quot;manage&quot;: [ &quot;node02&quot; ], &quot;storage&quot;: [ &quot;192.168.170.112&quot; ] }, &quot;zone&quot;: 1 }, &quot;devices&quot;: [ &quot;/dev/sdb&quot; ] }, { &quot;node&quot;: { &quot;hostnames&quot;: { &quot;manage&quot;: [ &quot;node03&quot; ], &quot;storage&quot;: [ &quot;192.168.170.113&quot; ] }, &quot;zone&quot;: 1 }, &quot;devices&quot;: [ &quot;/dev/sdb&quot; ] }, { &quot;node&quot;: { &quot;hostnames&quot;: { &quot;manage&quot;: [ &quot;node04&quot; ], &quot;storage&quot;: [ &quot;192.168.170.114&quot; ] }, &quot;zone&quot;: 1 }, &quot;devices&quot;: [ &quot;/dev/sdb&quot; ] } ] } ]} 进入到 Heketi 容器，使用 Heketi-cli 执行命令创建kubectl exec -it heketi-c7cbcd99f-5fr87 -- /bin/bash，创建上面的 topology.json 文件，然后执行命令： 12345678910111213 [root@heketi-c7cbcd99f-5fr87 /]# export HEKETI_CLI_SERVER=http://localhost:8080 [root@heketi-c7cbcd99f-5fr87 /]# heketi-cli -s $HEKETI_CLI_SERVER --user admin --secret 'My Secret' topology load --json=topology.json [root@heketi-c7cbcd99f-5fr87 /]# heketi-cli topology load --json=topology.json Creating cluster ... ID: a1960a285b7314517477b178f4babbccAllowing file volumes on cluster.Allowing block volumes on cluster.Creating node node02 ... ID: 9b6fa5213ef920f428a60bd199456c5a Adding device /dev/sdb ... OKCreating node node03 ... ID: 54abf4963294de9bec989f5b641fa1e2 Adding device /dev/sdb ... OKCreating node node04 ... ID: d8573f0c2506db8cca6c0cfeb86f4ac8 Adding device /dev/sdb ... OK 如果直接执行命令 heketi-cli topology load --json=topology.json 会出现一下错误：Error: Unable to get topology information: Invalid JWT token: Token missing iss claim需要加上 user 和 secret，可以从 /etc/heketi/heketi.json 文件中拿到值。也可以先加入环境变量，然后就可以直接执行：heketi-cli topology load --json=topology.json 123export HEKETI_CLI_USER=adminexport HEKETI_CLI_SERVER=http://localhost:8080export HEKETI_CLI_KEY=My\\ Secret 查看 Heketi 创建的 topology 的信息，执行命令：heketi-cli topology --user admin --secret 'My Secret' info Heteki 的 topology 信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@heketi-c7cbcd99f-5fr87 /]# heketi-cli topology --user admin --secret 'My Secret' info [root@heketi-c7cbcd99f-5fr87 /]# heketi-cli topology infoCluster Id: a1960a285b7314517477b178f4babbcc File: true Block: true Volumes: Nodes: Node Id: 54abf4963294de9bec989f5b641fa1e2 State: online Cluster Id: a1960a285b7314517477b178f4babbcc Zone: 1 Management Hostnames: node03 Storage Hostnames: 192.168.170.113 Devices: Id:28b4f9a350aff4c88ab7ffcab79764eb State:online Size (GiB):19 Used (GiB):1 Free (GiB):18 Known Paths: /dev/disk/by-path/pci-0000:00:10.0-scsi-0:0:1:0 /dev/sdb Bricks: Node Id: 9b6fa5213ef920f428a60bd199456c5a State: online Cluster Id: a1960a285b7314517477b178f4babbcc Zone: 1 Management Hostnames: node02 Storage Hostnames: 192.168.170.112 Devices: Id:54d66971acb11982b48dcbccf6d2e29c State:online Size (GiB):19 Used (GiB):0 Free (GiB):19 Known Paths: /dev/disk/by-path/pci-0000:00:10.0-scsi-0:0:1:0 /dev/sdb Bricks: Node Id: d8573f0c2506db8cca6c0cfeb86f4ac8 State: online Cluster Id: a1960a285b7314517477b178f4babbcc Zone: 1 Management Hostnames: node04 Storage Hostnames: 192.168.170.114 Devices: Id:c49d4d978b189c2347778e72b411d52d State:online Size (GiB):19 Used (GiB):0 Free (GiB):19 Known Paths: /dev/disk/by-path/pci-0000:00:10.0-scsi-0:0:1:0 /dev/sdb Bricks: 上面的信息可以看到，磁盘的大小，剩余空间，但是 GlusterFS 的 Volume 和 Brick 还没有创建。 关于 GlusterFS 中的一些术语： Brick: GlusterFS 的最小存储单元，表示授信存储吃里面的导出目录，格式：SERVER:EXPORT，比如：node02:/exports/data/ Volume: 一组 Bricks 的逻辑集合 定义 StorageClass定义个 StorageClass，来使用和配置 GlusterFS 提供的存储。内容如下： storageclass-gluster-heketi.yaml1234567891011apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: gluster-heketiprovisioner: kubernetes.io/glusterfsparameters: resturl: &quot;http://10.100.161.204:8080&quot; restauthenabled: &quot;true&quot; restuser: &quot;admin&quot; secretNamespace: &quot;default&quot; secretName: &quot;heketi-secret&quot; 在 master 上执行创建命令： 12345[root@node01 k8s]# kubectl create -f storageclass-gluster-heketi.yamlstorageclass.storage.k8s.io/gluster-heketi created[root@node01 k8s]# kubectl get scNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGEgluster-heketi kubernetes.io/glusterfs Delete Immediate false 15s 上面的 SC 中，还需要定义一个 secret 来授权访问 Heketi 的 API，不然调用 POST /Volume 会报错。heketi-secret.yaml 定义如下： 1234567apiVersion: v1kind: Secretmetadata: name: heketi-secretdata: key: TXkgU2VjcmV0type: kubernetes.io/glusterfs # 必须定义 定义 PVC通过上面的步骤，我们已经准备好了 PV，现在可以定义一个 PVC 来申请使用 PV 中的资源。定义一个 PVC： pvc-gluster-heketi.yaml1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: pvc-gluster-heketispec: storageClassName: gluster-heketi accessModes: - ReadWriteOnce resources: requests: storage: 1Gi 上面的定义中，没有定义 selector 属性，使用动态资源供应模式。创建过程的日志可以通过跟踪 Heketi pod 的日志。kubectl logs -f heketi-c7cbcd99f-xc774 创建 PVC 成功后，再看看其状态，已经是 Bound 状态： 123[root@node01 k8s]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEpvc-gluster-heketi Bound pvc-990850cc-5d60-4ef5-9315-7318645a83f8 1Gi RWO gluster-heketi 16s 查看 PV，可以看到，PVC 申请 PV 之后，heketi 创建一个 volume，然后将 volume 和 PV 绑定，并且是一对一的关系。 123[root@node01 k8s]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpvc-990850cc-5d60-4ef5-9315-7318645a83f8 1Gi RWO Delete Bound default/pvc-gluster-heketi gluster-heketi 8m2s describe 一下这个 PV，看到里面的状态、 StorageClass 以及容量等信息，还有一些 GlusterFS 的配置，heketi 也帮助我们完成了。看到 annotation 的描述，“Dynamically provisioned PV” 123456789101112131415161718192021222324252627[root@node01 k8s]# kubectl describe pv pvc-990850cc-5d60-4ef5-9315-7318645a83f8Name: pvc-990850cc-5d60-4ef5-9315-7318645a83f8Labels: &lt;none&gt;Annotations: Description: Gluster-Internal: Dynamically provisioned PVgluster.kubernetes.io/heketi-volume-id: 9b6067dbcd842dd55d998c5641c6ab7dgluster.org/type: filekubernetes.io/createdby: heketi-dynamic-provisionerpv.beta.kubernetes.io/gid: 2000pv.kubernetes.io/bound-by-controller: yespv.kubernetes.io/provisioned-by: kubernetes.io/glusterfsFinalizers: [kubernetes.io/pv-protection]StorageClass: gluster-heketiStatus: BoundClaim: default/pvc-gluster-heketiReclaim Policy: DeleteAccess Modes: RWOVolumeMode: FilesystemCapacity: 1GiNode Affinity: &lt;none&gt;Message: Source:Type: Glusterfs (a Glusterfs mount on the host that shares a pod's lifetime)EndpointsName: glusterfs-dynamic-990850cc-5d60-4ef5-9315-7318645a83f8EndpointsNamespace: defaultPath: vol_9b6067dbcd842dd55d998c5641c6ab7dReadOnly: falseEvents: &lt;none&gt; 通过以上的操作，一个真正 PVC 就生成了，挂载到 pod 里面就可以使用了。 pod 使用 PVC通过一个简单的 nginx pod 来使用 PVC，使用 persistentVolumeClaim 来挂载 PVC。另外，pod 和 PVC 要在同一个 namespace 中才能使用。 比较简单，不展开了。 参考 《Kubernetes 权威指南 第五版》 heketi glusterfs 创建 PVC 的时候排坑 错误：failed to create volume: failed to create volume: sed: can't read /var/lib/heketi/fstab: No such file or directory解决：到 glusterfs 服务的 node 上创建该文件， touch /var/lib/heketi/fstab 错误： Error executing crete volume: /usr/sbin/modprobe解决：执行命令：modprobe dm_thin_pool，然后查看：lsmod | grep thin。","link":"/2021-11-K8S%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8/"},{"title":"使用Kubeadm工具快速安装K8S集群","text":"预备工作 准备两台 CentOS 7.8 的虚拟机 安装 docker engineer 清理docker，没有安装过 docker ，没有必要执行 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装 yum-utils，提供了组件 yum-config-manager sudo yum install -y yum-utils 添加 yum 源sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 安装 docker enginesudo yum install docker-ce docker-ce-cli containerd.io 开启 docker 服务sudo systemctl start docker automatic startupsudo systemctl enable docker 关闭防火墙 12systemctl disable firewalld systemctl stop firewalld 可以配置防火墙的端口号，不用关闭防火墙，各个组件的端口号 组件名称 默认端口 API Server 8080（HTTP 非安全端口号）6443 （HTTPS 安全端口号） Controller Manager 10252 Scheduler 10251 kubelet 1025010255（只读端口号） etcd 2379（供客户端访问）2380 （供 etcd 集群内部节点之间访问） 集群 DNS 服务 53（UPD）53（TCP） 建议在主机上禁用 SELinux修改 /etc/sysconfig/selinux，将 SELINUX=enforcing 修改为 disabled，让容器可以读取主机文件系统 安装 kubeadm 配置 k8s 的 官方yum 源，修改 /etc/yum.repos.d/kubernetes.repo, 内容如下： 123456789[kubernetes] name=Kubernetes Repository name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearchenabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgexclude=kubelet kubeadm kubectl 运行 yum install 命令安装 kubeadm，kubelet 和 kubectl: yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes 启动 kubeadm 12systemctl start kubeletsystemctl enable kubelet kubeadm 需要关闭 linux 的 swap 系统交换区 swapoff -a，这个命令只是临时关闭，永久关闭，注释掉文件 /etc/fstab中 swap 那一行，然后重启，建议永久关闭。 修改 kubeadm 的默认配置查看初始化的配置，也称为控制平面（Control Plane）配置和加入节点的配置， kubeadm config print init-defaults 查看 kubeadm init 命令默认参数的内容 init default 配置 apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock imagePullPolicy: IfNotPresent name: node taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: 1.22.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} kubeadm config print join-defaults 查看 kubeadm join 命令默认参数的内容 join defaults 配置 apiVersion: kubeadm.k8s.io/v1beta3 caCertPath: /etc/kubernetes/pki/ca.crt discovery: bootstrapToken: apiServerEndpoint: kube-apiserver:6443 token: abcdef.0123456789abcdef unsafeSkipCAVerification: true timeout: 5m0s tlsBootstrapToken: abcdef.0123456789abcdef kind: JoinConfiguration nodeRegistration: criSocket: /var/run/dockershim.sock imagePullPolicy: IfNotPresent name: node01 taints: null 目前暂用默认配置 下载 Kubernetes 的相关镜像需要预先下载所需要的镜像，通过命令 kubeadm config images list 查看 kubeadm config images list 1234567k8s.gcr.io/kube-apiserver:v1.22.3k8s.gcr.io/kube-controller-manager:v1.22.3k8s.gcr.io/kube-scheduler:v1.22.3k8s.gcr.io/kube-proxy:v1.22.3k8s.gcr.io/pause:3.5k8s.gcr.io/etcd:3.5.0-0k8s.gcr.io/coredns/coredns:v1.8.4 执行命令：kubeadm config images pull，如果配置了 config 文件就加上参数，--config=/path/config.yaml 运行 kubeadm init 命令安装 Master 节点首先执行预检查命令，kubeadm init phase reflight 确保主机环境符合安装要求，然后再通过命令 kubeadm init 命令安装 K8S 的 Master 节点。 要说明的一点，K8S 默认设置 cgroup 驱动（cgroupdriver）为 systemd， 而 docker 服务的 cgroup 驱动默认值为 cgroupfs，建议修改为 systemd。修改 Docker 服务的配置文件（默认的位置：/etc/docker/daemon.json），如果没有的话，就新建一个 daemon.json，添加一下配置： 123{ &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]} 执行预检查命令显示： 123456[preflight] Running pre-flight checks [WARNING Hostname]: hostname &quot;node01&quot; could not be reached [WARNING Hostname]: hostname &quot;node01&quot;: lookup node01 on 114.114.114.114:53: no such host error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2 [ERROR Mem]: the system RAM (972 MB) is less than the minimum 1700 MB [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables contents are not set to 1 上面 error 错误中，前两个 error 原因主要是虚拟机的资源不够，加大到 2 核心 和 2G 内存，最后一个 error 意思是使用了 IPV6 的地址，并且 /proc/sys/net/bridge/bridge-nf-call-iptables 值不为1，通过 echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables 即可。 再次执行预检查命令，只有 warn ，没有 error 了，执行初始化命令。启动失败： 123456789101112131415161718192021222324252627282930313233343536[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s[kubelet-check] Initial timeout of 40s passed.[kubelet-check] It seems like the kubelet isn't running or healthy.[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get &quot;http://localhost:10248/healthz&quot;: dial tcp [::1]:10248: connect: connection refused.[kubelet-check] It seems like the kubelet isn't running or healthy.[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get &quot;http://localhost:10248/healthz&quot;: dial tcp [::1]:10248: connect: connection refused.[kubelet-check] It seems like the kubelet isn't running or healthy.[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get &quot;http://localhost:10248/healthz&quot;: dial tcp [::1]:10248: connect: connection refused.[kubelet-check] It seems like the kubelet isn't running or healthy.[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get &quot;http://localhost:10248/healthz&quot;: dial tcp [::1]:10248: connect: connection refused.[kubelet-check] It seems like the kubelet isn't running or healthy.[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get &quot;http://localhost:10248/healthz&quot;: dial tcp [::1]:10248: connect: connection refused. Unfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - 'systemctl status kubelet' - 'journalctl -xeu kubelet' Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - 'docker ps -a | grep kube | grep -v pause' Once you have found the failing container, you can inspect its logs with: - 'docker logs CONTAINERID'error execution phase wait-control-plane: couldn't initialize a Kubernetes clusterTo see the stack trace of this error execute with --v=5 or higher kubelet 没有启动起来，查看日志：tail /var/log/messages 12345678910Nov 1 15:04:51 node01 kubelet: I1101 15:04:51.235877 8809 docker_service.go:242] &quot;Hairpin mode is set&quot; hairpinMode=hairpin-vethNov 1 15:04:51 node01 kubelet: I1101 15:04:51.235947 8809 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no networks found in /etc/cni/net.d&quot;Nov 1 15:04:51 node01 kubelet: I1101 15:04:51.242254 8809 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no networks found in /etc/cni/net.d&quot;Nov 1 15:04:51 node01 kubelet: I1101 15:04:51.242306 8809 docker_service.go:257] &quot;Docker cri networking managed by the network plugin&quot; networkPluginName=&quot;cni&quot;Nov 1 15:04:51 node01 kubelet: I1101 15:04:51.242331 8809 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no networks found in /etc/cni/net.d&quot;Nov 1 15:04:51 node01 kubelet: I1101 15:04:51.249360 8809 docker_service.go:264] &quot;Docker Info&quot; dockerInfo=&amp;{ID:ZB4Z:FUQW:IXZR:H3XP:E4PL:WXGO:4ODH:A72V:BDIY:D4AJ:F6S7:M2J2 Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:7 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:false Debug:false NFd:25 OomKillDisable:true NGoroutines:34 SystemTime:2021-11-01T15:04:51.242765302+08:00 LoggingDriver:json-file CgroupDriver:cgroupfs CgroupVersion:1 NEventsListener:0 KernelVersion:3.10.0-1160.45.1.el7.x86_64 OperatingSystem:CentOS Linux 7 (Core) OSVersion:7 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc0003fa070 NCPU:2 MemTotal:2093301760 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:node01 Labels:[] ExperimentalBuild:false ServerVersion:20.10.10 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[] Shim:&lt;nil&gt;} io.containerd.runtime.v1.linux:{Path:runc Args:[] Shim:&lt;nil&gt;} runc:{Path:runc Args:[] Shim:&lt;nil&gt;}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:&lt;nil&gt; Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:5b46e404f6b9f661a205e28d59c982d3634148f8 Expected:5b46e404f6b9f661a205e28d59c982d3634148f8} RuncCommit:{ID:v1.0.2-0-g52b36a2 Expected:v1.0.2-0-g52b36a2} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: DefaultAddressPools:[] Warnings:[WARNING: bridge-nf-call-ip6tables is disabled]}Nov 1 15:04:51 node01 kubelet: E1101 15:04:51.249384 8809 server.go:294] &quot;Failed to run kubelet&quot; err=&quot;failed to run Kubelet: misconfiguration: kubelet cgroup driver: \\&quot;systemd\\&quot; is different from docker cgroup driver: \\&quot;cgroupfs\\&quot;&quot;Nov 1 15:04:51 node01 systemd: kubelet.service: main process exited, code=exited, status=1/FAILURENov 1 15:04:51 node01 systemd: Unit kubelet.service entered failed state.Nov 1 15:04:51 node01 systemd: kubelet.service failed. 发现是 K8S 和 docker 的 cgroup driver 不同。刚才配置了 docker 的 cgroup 的 daemon.json文件没有重启 docker，重启 docker 服务，让配置文件生效。 执行： systemctl daemon-reload &amp;&amp; systemctl restart docker 执行 kubeadm reset 命令回滚通过 kubeadm init 操作产生的文件，然后重新执行 kubeadm init 出现如下的日志，表示 Master 节点 Control Panel 安装成功了： 1234567891011121314151617181920212223242526272829303132[mark-control-plane] Marking the node node01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: 810man.kfqm2lvq8mfqq2k7[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.170.111:6443 --token 810man.kfqm2lvq8mfqq2k7 \\ --discovery-token-ca-cert-hash sha256:e89417229adccca09076f811a36cb50c0e19702c3d2bd0b1a4808c7f68ea1785 根据提示需要配置 CA 证书，如果是 root 用户，直接执行 export KUBECONFIG=/etc/kubernetes/admin.conf，然后就可以使用 kubectl 操作集群了。 但是这个只是临时的，关闭终端，下次登录会出现下面类似错误： 1The connection to the server localhost:8080 was refused - did you specify the right host or port? 所以需 要执行 cp -i /etc/kubernetes/admin.conf $HOME/.kube/config，这样就可以了。 目前 Master 节点已经可以工作了，但是没有 Worker 节点，并且现在的集群是没有网络的，需要配置网络。 加入新的 node 节点 准备 yum 源，步骤和 master 一样。 安装 kubeadm 和 kubelet 在 worker 节点上无需安装 kubectl yum install -y kubelet kubeadm --disableexcludes=kubernetes 启动 kubelet 的服务器，并设置为开机启动 systemctl start kubelet &amp;&amp; systemctl enable kubelet kubeadm 需要关闭 linux 的 swap 系统交换区 swapoff -a 修改新 node 节点的 docker cgroup 的配置， /etc/docker/daemon.json 123{ &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]} 使用 kubeadm join 命令加入集群，可以从上面的安装完 Master 的提示中复制 join 的命令： kubeadm join 192.168.170.111:6443 --token 810man.kfqm2lvq8mfqq2k7 --discovery-token-ca-cert-hash sha256:e89417229adccca09076f811a36cb50c0e19702c3d2bd0b1a4808c7f68ea1785 最后出现日志，This node has joined the cluster xxxxx 123456789101112131415[preflight] Running pre-flight checks [WARNING Hostname]: hostname &quot;node02&quot; could not be reached [WARNING Hostname]: hostname &quot;node02&quot;: lookup node02 on 114.114.114.114:53: no such host[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 如果执行 kubeadm join 失败，可以执行 kubeadm reset 命令恢复原状，然后再重新执行 join 命令。同理 kubeadm init 命令也是一样。 根据提示，在 Master 节点上执行命令 kubectl get nodes，获取到当前集群中的 node， 1234[root@node01 docker]# kubectl get nodesNAME STATUS ROLES AGE VERSIONnode01 NotReady control-plane,master 67m v1.22.3node02 NotReady &lt;none&gt; 5m38s v1.22.3 这时候是没有网络的，所以节点都是 NOT READY 的状态，在查看 /var/log/messages 的日志时，一直报网络的错误： 12Nov 1 16:18:50 node01 kubelet: I1101 16:18:50.622393 13344 cni.go:239] &quot;Unable to update cni config&quot; err=&quot;no networks found in /etc/cni/net.d&quot;Nov 1 16:18:52 node01 kubelet: E1101 16:18:52.110886 13344 kubelet.go:2337] &quot;Container runtime network not ready&quot; networkReady=&quot;NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized&quot; 所以接下来，我们需要配置网络 CNI 插件。 可以通过设置，让 Master 节点也作为 Node 角色。删除 Node 的 label node-role.kubernetes.io/master即可。通过命令： kubectl taint nodes --all node-role.kubernetes.io/master 安装 CNI 网络插件对于 CNI 网络插件的安装，选择 Calico CNI 插件，在 Master 节点，运行命令一键安装： kubectl apply -f 'https://docs.projectcalico.org/manifests/calico.yaml' 安装完之后，再次执行 kubectl get nodes ，node 已经 READY 状态。 验证 Kubernetes 集群是否正常工作运行查看 POD 命令，验证 K8S 集群服务的 POD 是否创建成功且正常运行 kubectl get pods --all-namespaces，输出如下： 12345678910111213[root@node01 docker]# kubectl get pods --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-75f8f6cc59-cfwt7 1/1 Running 0 6m19skube-system calico-node-2gb5b 1/1 Running 0 6m19skube-system calico-node-5786l 1/1 Running 0 6m19skube-system coredns-78fcd69978-774r8 1/1 Running 0 93mkube-system coredns-78fcd69978-dgpq4 1/1 Running 0 93mkube-system etcd-node01 1/1 Running 1 93mkube-system kube-apiserver-node01 1/1 Running 1 93mkube-system kube-controller-manager-node01 1/1 Running 1 93mkube-system kube-proxy-59xsr 1/1 Running 0 31mkube-system kube-proxy-kdrt9 1/1 Running 0 93mkube-system kube-scheduler-node01 1/1 Running 1 93m 至此， 一个正常的 K8S 集群就已经安装成功了。但是这个集群是不可靠的集群，一旦 Master 节点 down 调，那么整个集群就会崩溃，所以生产环境中还是要搭建高可用的集群。 补充说明token 是有效期的，默认是 24h，如果过了有效期，新的 node 就无法加入，就会报错，比如： 123456789101112I1103 13:57:58.187573 18232 checks.go:403] checking whether the given node name is valid and reachable using net.LookupHostI1103 13:57:58.187665 18232 checks.go:618] validating kubelet versionI1103 13:57:58.222792 18232 checks.go:132] validating if the &quot;kubelet&quot; service is enabled and activeI1103 13:57:58.228624 18232 checks.go:205] validating availability of port 10250I1103 13:57:58.228884 18232 checks.go:282] validating the existence of file /etc/kubernetes/pki/ca.crtI1103 13:57:58.228894 18232 checks.go:432] validating if the connectivity type is via proxy or directI1103 13:57:58.228917 18232 join.go:475] [preflight] Discovering cluster-infoI1103 13:57:58.228939 18232 token.go:80] [discovery] Created cluster-info discovery client, requesting info from &quot;192.168.170.111:6443&quot;I1103 13:57:58.241805 18232 token.go:223] [discovery] The cluster-info ConfigMap does not yet contain a JWS signature for token ID &quot;810man&quot;, will try againI1103 13:58:04.154621 18232 token.go:223] [discovery] The cluster-info ConfigMap does not yet contain a JWS signature for token ID &quot;810man&quot;, will try againI1103 13:58:10.576176 18232 token.go:223] [discovery] The cluster-info ConfigMap does not yet contain a JWS signature for token ID &quot;810man&quot;, will try againI1103 13:58:16.580191 18232 token.go:223] [discovery] The cluster-info ConfigMap does not yet contain a JWS signature for token ID &quot;810man&quot;, will try again 那么如何生成新的 token 呢，可以在 master 节点上，就是 control plane 的节点上，执行命令：kubeadm token create --print-join-command会输出新的 kubeadm join 的提示，也可以带上参数 --ttl=0，表示永不过期，输出如下： 1kubeadm join 192.168.170.111:6443 --token cyvp4j.05wpywxo03q178v4 --discovery-token-ca-cert-hash sha256:e89417229adccca09076f811a36cb50c0e19702c3d2bd0b1a4808c7f68ea1785 再次放到新的 node 节点执行即可。然后再在 master 节点执行 kubectl get nodes 命令查看是否有新加入的节点。","link":"/2021-11-%E4%BD%BF%E7%94%A8Kubeadm%E5%B7%A5%E5%85%B7%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85K8S%E9%9B%86%E7%BE%A4/"},{"title":"JVM系列 —— 类的生命周期之类加载","text":"这是 JVM 系列的第三篇，见 JVM 系列。 写在前面在提到 JVM 类加载的时候，经常容易把类加载机制和类加载器搞混淆，虽然两者紧密联系，但是实际上应该从不同的角度去理解，类加载机制可以看做是一个流程，类似软件产品从需求（class 文件格式）到落地（class 对象）的过程，而类加载器在类加载机制的流程中充当执行者，类似于软件产品中输出的IT人员。所这里想分开讨论一下。 首先来看类加载机制类的生命周期说法大致相同，从大的角度来说，包括：加载 –&gt; 链接 -&gt; 初始化 -&gt; 使用 -&gt; 卸载；从小的细节来说，包括：加载 –&gt; 验证 –&gt; 准备 –&gt; 解析 -&gt; 初始化 -&gt; 使用 -&gt; 卸载；画个图如下： 加载：就是通过类的二进制表示来创建类或接口的过程，大白话就是，找到 class 文件，放到内存里面（在 metaspace 区域），构建java类的原型–类模板对象，相当于一个快照，jvm 随便用，给机器看的。 链接：将类或接口并入虚拟机运行时状态的过程。链接的主要作用就是将字节码指令中的常量池的符号引用解析为指针、偏移量等内存地址的直接引用。 这里有点晕，需要看一下计算机操作系统的链接部分内容。 初始化：类或接口的初始化是执行类或接口的初始化方法 &lt;clinit&gt;，如果类中有 static字段或static{}代码块，会产生一个 &lt;clinit&gt;的方法。 与实例的初始化方法 &lt;init&gt; 不同，实例的初始化是调用构造器，发生在类或接口已经初始化之后，而 &lt;clinit&gt; 发生在类加载到虚拟机的初始化阶段。 其次来看类加载器JVM 规范支持两种类加载器： java 虚拟机提供的引导类加载器（bootstrap class loader） 用户自定义的类加载器 而针对 JVM 实现上，java 体系中有三种类加载器，JDK 8 实现的类加载的三级层次结构： Boostrap class loader主要加载 rt.jar 和 其他在 $JAVA_HOME/jre/lib 路径下面的核心类库，还有通过参数 -Xbootclasspath 指定的目录。 Extension class loader主要加载 $JAVA_HOME/jre/lib/ext 下面的类还有系统属性 java.ext.dirs 指定目录的类库。 System class loader也成为 Application class loader，主要加载应用程序的类库，即有系统环境变量 ClassPath、-cp 命令或者系统属性 java.class.path 指定的类库。 JDK 9 起，jdk 的类库管理发生了很大的变化，引入了平台模块系统（参考 Java Platform Module System (JSR 376)），把各个类库拆分组合成一个一个的模块，此时，针对类加载器的变化就是， Extension Classloader 改名成 Platform class loader，并且和 Bootstrap class loader 分别加载不同的模块，具体的模块参考下面的 JEP 文档。参考： jdk11 API 文档 JDK 改进提案: JEP 261 当然，除了上述的三个层级的类加载器，也可以自定义类加载器。下面的示例展示了 jdk8 和 jdk11 的不同类加载器： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ClassLoaderLevel { /** * JDK 8 ： String 类的 ClassLoader 是：null -------------- 示例类的 ClassLoader 是：sun.misc.Launcher$AppClassLoader@18b4aac2 示例类的 ClassLoader 的父加载器是：sun.misc.Launcher$ExtClassLoader@2f0e140b 示例类的 ClassLoader 的 ClassLoader 是：null -------------- 系统 ClassLoader 是：sun.misc.Launcher$AppClassLoader@18b4aac2 系统 ClassLoader 的父加载器是：sun.misc.Launcher$ExtClassLoader@2f0e140b 系统 ClassLoader 的 ClassLoader 是：null */ /** * JDK 11 打印： String 类的 ClassLoader 是：null -------------- 示例类的 ClassLoader 是：jdk.internal.loader.ClassLoaders$AppClassLoader@1f89ab83 示例类的 ClassLoader 的父加载器是：jdk.internal.loader.ClassLoaders$PlatformClassLoader@6108b2d7 示例类的 ClassLoader 的 ClassLoader 是：null -------------- 系统 ClassLoader 是：jdk.internal.loader.ClassLoaders$AppClassLoader@1f89ab83 系统 ClassLoader 的父加载器是：jdk.internal.loader.ClassLoaders$PlatformClassLoader@6108b2d7 系统 ClassLoader 的 ClassLoader 是：null */ public static void main(String[] args) { System.out.println(&quot;String 类的 ClassLoader 是：&quot; + String.class.getClassLoader()); System.out.println(&quot;--------------&quot;); System.out.println(&quot;示例类的 ClassLoader 是：&quot; + ClassLoaderLevel.class.getClassLoader()); System.out.println(&quot;示例类的 ClassLoader 的父加载器是：&quot; + ClassLoaderLevel.class.getClassLoader().getParent()); System.out.println(&quot;示例类的 ClassLoader 的 ClassLoader 是：&quot; + ClassLoaderLevel.class.getClassLoader().getClass().getClassLoader()); System.out.println(&quot;--------------&quot;); System.out.println(&quot;系统 ClassLoader 是：&quot; + ClassLoader.getSystemClassLoader()); System.out.println(&quot;系统 ClassLoader 的父加载器是：&quot; + ClassLoader.getSystemClassLoader().getParent()); System.out.println(&quot;系统 ClassLoader 的 ClassLoader 是：&quot; + ClassLoader.getSystemClassLoader().getClass().getClassLoader()); System.out.println(System.getProperty(&quot;sun.boot.class.path&quot;)); //jdk8 打印 rt.jar 的类，jdk11 空 System.out.println(System.getProperty(&quot;java.ext.dirs&quot;)); // jdk8 打印 ext 类， jdk11 空 System.out.println(System.getProperty(&quot;java.class.path&quot;)); // jdk8 和 jdk 11 都打印 classpath 下的 jar }} 虚拟机启动JVM 虚拟机规范在第五章说明了虚拟机启动时的步骤，大概流程可以用如下图所示： oop-klass 模型在说到类加载的时候，为了更好的弄清楚类加载的过程和原理，必然要提到 oop-klass 模型，简单的说，每一个 java class 加载到 JVM 中，JVM会产生一个与之对应的类模板对象，实际上是一个 C++ 的实例。这个类模板对象，从两个维度来说，一个是 oop（Ordinary Object Pointer） 模型，一个是 klass 模型，klass 存放的是这个类的元数据，类的信息，而 oop 则保存了实例的数据。举个例子： 12A a = new A();A b = new A(); 上面的代码最终反映到 JVM 层面，a 和 b 的 JVM klass 都是相同的，但是 oop 不同。看一下 jdk8 源码 的 oop 体系和 klass 体系： oopHotspot 里面的 oop 其实就是 GC 托管的指针，每一个 oop 都是一种 xxxOopDesc* 类型的指针。在 Hotspot 里面 oop 就指一个 真的指针。 看 JVM 源码 hotspot/src/share/vm/oops/oop.hpp ，{name}Desc 描述了 java 对象的结构， 能够从 C++ 访问得到。 hotspot/src/share/vm/oops/oopsHierarchy.hpp 定义了 oop 的层级和含义： 在 JVM 中， instanceOop 表示一个 java 的一个实例对象，这个实例对象是可以从 C++ 层面能访问到的。markOop 是一个比较特殊的类型，看起来是一个像指针，实际上是藏在指针里面的对象（数据）。不收 GC 托管。只是为了满足“面向对象”编程而设计的。路径 share/vm/oops/markOop.hpp oop 一般有对象头、对象专有属性和数据体这 3 部分组成。 klass按照 官方文档，klass 提供两种能力： 提供一个与 java 类对等的 C++ 类型描述 提供虚拟机内部的函数分发机制（没有搞过 C++，不是很理解）JVM 里面 klass 的层级结构如下： 总之一句话，每一个 java class 字节流文件，最终都会 JVM 内部产生一个 klassOop 和它对等，java类的字段、方法以及常量池都会保存到 klassOop 实例对象中。 类加载虚拟机运行的时候，一个类或接口不仅仅是有二进制名称来确定的，还有它的定义类加载共同确定的，也就是说，类名称相同，但是是不同类加载加载的，那么最后生成实例是两个不同类型的实例。 在上一篇讲过 class 文件格式，那么 JVM 是怎样去解析这个 class 文件呢？ 这里要说明的是，这个 class 文件格式并不仅仅局限于二进制文件，也有可能从网络加载，但是最终解析的都是 class 文件的二进制字节流 对于类的解析逻辑在源码 hotspot/src/share/vm/classfile/classFileParser.cpp 的 ClassFileParser::parseClassFile() 函数中，贴一下源码： 类文件解析源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136instanceKlassHandle ClassFileParser::parseClassFile(Symbol* name, ClassLoaderData* loader_data, Handle protection_domain, KlassHandle host_klass, GrowableArray&lt;Handle&gt;* cp_patches, TempNewSymbol&amp; parsed_name, bool verify, TRAPS) { // class 流 ClassFileStream* cfs = stream(); ... ... // 魔数值校验 u4 magic = cfs-&gt;get_u4_fast(); guarantee_property(magic == JAVA_CLASSFILE_MAGIC, &quot;Incompatible magic value %u in class file %s&quot;, magic, CHECK_(nullHandle)); // 版本号校验 u2 minor_version = cfs-&gt;get_u2_fast(); u2 major_version = cfs-&gt;get_u2_fast(); if (DumpSharedSpaces &amp;&amp; major_version &lt; JAVA_1_5_VERSION) { ... ... } // Check version numbers - we check this even with verifier off if (!is_supported_version(major_version, minor_version)) { ... ... } _major_version = major_version; _minor_version = minor_version; // 解析常量池 constantPoolHandle cp = parse_constant_pool(CHECK_(nullHandle)); // 访问标志 AccessFlags access_flags; ... ... if ((flags &amp; JVM_ACC_INTERFACE) &amp;&amp; _major_version &lt; JAVA_6_VERSION) { ... ... } // 类索引 _this_class_index = cfs-&gt;get_u2_fast(); ... ... // 父类索引 instanceKlassHandle super_klass = parse_super_class(super_class_index, CHECK_NULL); // 接口 u2 itfs_len = cfs-&gt;get_u2_fast(); Array&lt;Klass*&gt;* local_interfaces = parse_interfaces(itfs_len, protection_domain, _class_name, &amp;has_default_methods, CHECK_(nullHandle)); u2 java_fields_count = 0; // 字段解析 Array&lt;u2&gt;* fields = parse_fields(class_name, access_flags.is_interface(), &amp;fac, &amp;java_fields_count, CHECK_(nullHandle)); // 方法解析 Array&lt;Method*&gt;* methods = parse_methods(access_flags.is_interface(), &amp;promoted_flags, &amp;has_final_method, &amp;declares_default_methods, CHECK_(nullHandle)); // 属性解析 ClassAnnotationCollector parsed_annotations; parse_classfile_attributes(&amp;parsed_annotations, CHECK_(nullHandle)); //创建与 java 类对等的内部对象 _klass = InstanceKlass::allocate_instance_klass(loader_data, vtable_size, itable_size, info.static_field_size, total_oop_map_size2, rt, access_flags, name, super_klass(), !host_klass.is_null(), CHECK_(nullHandle)); instanceKlassHandle this_klass (THREAD, _klass); // Fill in information already parsed this_klass-&gt;set_should_verify_class(verify); jint lh = Klass::instance_layout_helper(info.instance_size, false); this_klass-&gt;set_layout_helper(lh); if (has_final_method) { this_klass-&gt;set_has_final_method(); } this_klass-&gt;copy_method_ordering(method_ordering, CHECK_NULL); // The InstanceKlass::_methods_jmethod_ids cache // is managed on the assumption that the initial cache // size is equal to the number of methods in the class. If // that changes, then InstanceKlass::idnum_can_increment() // has to be changed accordingly. this_klass-&gt;set_initial_method_idnum(methods-&gt;length()); this_klass-&gt;set_name(cp-&gt;klass_name_at(_this_class_index)); if (is_anonymous()) // I am well known to myself cp-&gt;klass_at_put(_this_class_index, this_klass()); // eagerly resolve this_klass-&gt;set_minor_version(minor_version); this_klass-&gt;set_major_version(major_version); this_klass-&gt;set_has_default_methods(has_default_methods); this_klass-&gt;set_declares_default_methods(declares_default_methods); if (!host_klass.is_null()) { assert (this_klass-&gt;is_anonymous(), &quot;should be the same&quot;); this_klass-&gt;set_host_klass(host_klass()); } if (cached_class_file != NULL) { // JVMTI: we have an InstanceKlass now, tell it about the cached bytes this_klass-&gt;set_cached_class_file(cached_class_file); } // 创建镜像类和静态字段初始化 java_lang_Class::create_mirror(this_klass, class_loader, protection_domain, CHECK_(nullHandle)); }} 从源码里面可以看到，调用klass 的子类 InstanceClass 调用方法 allocate_instance_klass() 构建了一个 instanceKlass 对象实例。InstanceKlass 是虚拟机级别的java类的对等对象，包含了在运行期间构建一个类所有必要的信息。至此，java 类的生命周期的第一个阶段 —— 加载 就结束了。下面的源码是 InstanceKlass 的结构： hotspot/src/share/vm/oops/instanceKlass.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190class InstanceKlass: public Klass { friend class VMStructs; friend class ClassFileParser; friend class CompileReplay; protected: // Constructor InstanceKlass(int vtable_len, int itable_len, int static_field_size, int nonstatic_oop_map_size, ReferenceType rt, AccessFlags access_flags, bool is_anonymous); public: static InstanceKlass* allocate_instance_klass( ClassLoaderData* loader_data, int vtable_len, int itable_len, int static_field_size, int nonstatic_oop_map_size, ReferenceType rt, AccessFlags access_flags, Symbol* name, Klass* super_klass, bool is_anonymous, TRAPS); InstanceKlass() { assert(DumpSharedSpaces || UseSharedSpaces, &quot;only for CDS&quot;); } // See &quot;The Java Virtual Machine Specification&quot; section 2.16.2-5 for a detailed description // of the class loading &amp; initialization procedure, and the use of the states. enum ClassState { allocated, // allocated (but not yet linked) loaded, // loaded and inserted in class hierarchy (but not linked yet) linked, // successfully linked/verified (but not initialized yet) being_initialized, // currently running class initializer fully_initialized, // initialized (successfull final state) initialization_error // error happened during initialization }; static int number_of_instance_classes() { return _total_instanceKlass_count; } private: static volatile int _total_instanceKlass_count; protected: // Annotations for this class Annotations* _annotations; // Array classes holding elements of this class. Klass* _array_klasses; // Constant pool for this class. ConstantPool* _constants; // The InnerClasses attribute and EnclosingMethod attribute. The // _inner_classes is an array of shorts. If the class has InnerClasses // attribute, then the _inner_classes array begins with 4-tuples of shorts // [inner_class_info_index, outer_class_info_index, // inner_name_index, inner_class_access_flags] for the InnerClasses // attribute. If the EnclosingMethod attribute exists, it occupies the // last two shorts [class_index, method_index] of the array. If only // the InnerClasses attribute exists, the _inner_classes array length is // number_of_inner_classes * 4. If the class has both InnerClasses // and EnclosingMethod attributes the _inner_classes array length is // number_of_inner_classes * 4 + enclosing_method_attribute_size. Array&lt;jushort&gt;* _inner_classes; // the source debug extension for this klass, NULL if not specified. // Specified as UTF-8 string without terminating zero byte in the classfile, // it is stored in the instanceklass as a NULL-terminated UTF-8 string char* _source_debug_extension; // Array name derived from this class which needs unreferencing // if this class is unloaded. Symbol* _array_name; // Number of heapOopSize words used by non-static fields in this klass // (including inherited fields but after header_size()). int _nonstatic_field_size; int _static_field_size; // number words used by static fields (oop and non-oop) in this klass // Constant pool index to the utf8 entry of the Generic signature, // or 0 if none. u2 _generic_signature_index; // Constant pool index to the utf8 entry for the name of source file // containing this klass, 0 if not specified. u2 _source_file_name_index; u2 _static_oop_field_count;// number of static oop fields in this klass u2 _java_fields_count; // The number of declared Java fields int _nonstatic_oop_map_size;// size in words of nonstatic oop map blocks // _is_marked_dependent can be set concurrently, thus cannot be part of the // _misc_flags. bool _is_marked_dependent; // used for marking during flushing and deoptimization bool _is_being_redefined; // used for locking redefinition bool _has_unloaded_dependent; enum { _misc_rewritten = 1 &lt;&lt; 0, // methods rewritten. _misc_has_nonstatic_fields = 1 &lt;&lt; 1, // for sizing with UseCompressedOops _misc_should_verify_class = 1 &lt;&lt; 2, // allow caching of preverification _misc_is_anonymous = 1 &lt;&lt; 3, // has embedded _host_klass field _misc_is_contended = 1 &lt;&lt; 4, // marked with contended annotation _misc_has_default_methods = 1 &lt;&lt; 5, // class/superclass/implemented interfaces has default methods _misc_declares_default_methods = 1 &lt;&lt; 6, // directly declares default methods (any access) _misc_has_been_redefined = 1 &lt;&lt; 7 // class has been redefined }; u2 _misc_flags; u2 _minor_version; // minor version number of class file u2 _major_version; // major version number of class file Thread* _init_thread; // Pointer to current thread doing initialization (to handle recursive initialization) int _vtable_len; // length of Java vtable (in words) int _itable_len; // length of Java itable (in words) OopMapCache* volatile _oop_map_cache; // OopMapCache for all methods in the klass (allocated lazily) MemberNameTable* _member_names; // Member names JNIid* _jni_ids; // First JNI identifier for static fields in this class jmethodID* _methods_jmethod_ids; // jmethodIDs corresponding to method_idnum, or NULL if none nmethodBucket* _dependencies; // list of dependent nmethods nmethod* _osr_nmethods_head; // Head of list of on-stack replacement nmethods for this class BreakpointInfo* _breakpoints; // bpt lists, managed by Method* // Linked instanceKlasses of previous versions InstanceKlass* _previous_versions; // JVMTI fields can be moved to their own structure - see 6315920 // JVMTI: cached class file, before retransformable agent modified it in CFLH JvmtiCachedClassFileData* _cached_class_file; volatile u2 _idnum_allocated_count; // JNI/JVMTI: increments with the addition of methods, old ids don't change // Class states are defined as ClassState (see above). // Place the _init_state here to utilize the unused 2-byte after // _idnum_allocated_count. u1 _init_state; // state of class u1 _reference_type; // reference type JvmtiCachedClassFieldMap* _jvmti_cached_class_field_map; // JVMTI: used during heap iteration NOT_PRODUCT(int _verify_count;) // to avoid redundant verifies // Method array. Array&lt;Method*&gt;* _methods; // Default Method Array, concrete methods inherited from interfaces Array&lt;Method*&gt;* _default_methods; // Interface (Klass*s) this class declares locally to implement. Array&lt;Klass*&gt;* _local_interfaces; // Interface (Klass*s) this class implements transitively. Array&lt;Klass*&gt;* _transitive_interfaces; // Int array containing the original order of method in the class file (for JVMTI). Array&lt;int&gt;* _method_ordering; // Int array containing the vtable_indices for default_methods // offset matches _default_methods offset Array&lt;int&gt;* _default_vtable_indices; // Instance and static variable information, starts with 6-tuples of shorts // [access, name index, sig index, initval index, low_offset, high_offset] // for all fields, followed by the generic signature data at the end of // the array. Only fields with generic signature attributes have the generic // signature data set in the array. The fields array looks like following: // // f1: [access, name index, sig index, initial value index, low_offset, high_offset] // f2: [access, name index, sig index, initial value index, low_offset, high_offset] // ... // fn: [access, name index, sig index, initial value index, low_offset, high_offset] // [generic signature index] // [generic signature index] // ... Array&lt;u2&gt;* _fields; /** 预留空间来存放 vtable(虚拟表), itable(接口表), 静态字段，引用的 map */ // embedded Java vtable follows here // embedded Java itables follows here // embedded static fields follows here // embedded nonstatic oop-map blocks follows here // embedded implementor of this interface follows here // The embedded implementor only exists if the current klass is an // iterface. The possible values of the implementor fall into following // three cases: // NULL: no implementor. // A Klass* that's not itself: one implementor. // Itself: more than one implementors. // embedded host klass follows here // The embedded host klass only exists in an anonymous class for // dynamic language support (JSR 292 enabled). The host class grants // its access privileges to this class also. The host class is either // named, or a previously loaded anonymous class. A non-anonymous class // or an anonymous class loaded through normal classloading does not // have this embedded field. // ... ...} 在上面解析 class 文件的源码中，我们看到了在调用 `allocate_instance_klass()` 创建一个 instanceKlass 之后，看到 `create_mirror()` 的函数，创建一个镜像类，接下来看看这个镜像类。 镜像类和静态字段看一下源码，位于 hotspot/src/share/vm/classfile/javaClasses.cpp。 java_lang_Class::create_mirror() 函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475void java_lang_Class::create_mirror(KlassHandle k, Handle class_loader, Handle protection_domain, TRAPS) { assert(k-&gt;java_mirror() == NULL, &quot;should only assign mirror once&quot;); // Use this moment of initialization to cache modifier_flags also, // to support Class.getModifiers(). Instance classes recalculate // the cached flags after the class file is parsed, but before the // class is put into the system dictionary. int computed_modifiers = k-&gt;compute_modifier_flags(CHECK); k-&gt;set_modifier_flags(computed_modifiers); // Class_klass has to be loaded because it is used to allocate // the mirror. if (SystemDictionary::Class_klass_loaded()) { // Allocate mirror (java.lang.Class instance) Handle mirror = InstanceMirrorKlass::cast(SystemDictionary::Class_klass())-&gt;allocate_instance(k, CHECK); // Setup indirection from mirror-&gt;klass if (!k.is_null()) { java_lang_Class::set_klass(mirror(), k()); } InstanceMirrorKlass* mk = InstanceMirrorKlass::cast(mirror-&gt;klass()); assert(oop_size(mirror()) == mk-&gt;instance_size(k), &quot;should have been set&quot;); java_lang_Class::set_static_oop_field_count(mirror(), mk-&gt;compute_static_oop_field_count(mirror())); // It might also have a component mirror. This mirror must already exist. if (k-&gt;oop_is_array()) { Handle comp_mirror; if (k-&gt;oop_is_typeArray()) { BasicType type = TypeArrayKlass::cast(k())-&gt;element_type(); comp_mirror = Universe::java_mirror(type); } else { assert(k-&gt;oop_is_objArray(), &quot;Must be&quot;); Klass* element_klass = ObjArrayKlass::cast(k())-&gt;element_klass(); assert(element_klass != NULL, &quot;Must have an element klass&quot;); comp_mirror = element_klass-&gt;java_mirror(); } assert(comp_mirror.not_null(), &quot;must have a mirror&quot;); // Two-way link between the array klass and its component mirror: ArrayKlass::cast(k())-&gt;set_component_mirror(comp_mirror()); set_array_klass(comp_mirror(), k()); } else { assert(k-&gt;oop_is_instance(), &quot;Must be&quot;); initialize_mirror_fields(k, mirror, protection_domain, THREAD); if (HAS_PENDING_EXCEPTION) { // If any of the fields throws an exception like OOM remove the klass field // from the mirror so GC doesn't follow it after the klass has been deallocated. // This mirror looks like a primitive type, which logically it is because it // it represents no class. java_lang_Class::set_klass(mirror(), NULL); return; } } // set the classLoader field in the java_lang_Class instance assert(class_loader() == k-&gt;class_loader(), &quot;should be same&quot;); set_class_loader(mirror(), class_loader()); // Setup indirection from klass-&gt;mirror last // after any exceptions can happen during allocations. if (!k.is_null()) { k-&gt;set_java_mirror(mirror()); } } else { if (fixup_mirror_list() == NULL) { GrowableArray&lt;Klass*&gt;* list = new (ResourceObj::C_HEAP, mtClass) GrowableArray&lt;Klass*&gt;(40, true); set_fixup_mirror_list(list); } fixup_mirror_list()-&gt;push(k()); }} 从代码的注释里面可以看到，mirror 镜像类也是一个 instanceKlass 的实例，`SystemDictionary::Class_klass()` 返回的就是 `java_lang_Class` 类型，然后 `allocate_instance()` 这个方法就是创建， `java.lang.Class` 这个 java 类型在 JVM 内部的对等体。再调用方法 `set_klass()`，让当前创建的 klassOop 引用刚刚实例化的 `java_lang_Class` 对象。**这么做的目的是为了被 Java 程序调用，而 instanceKlass 是 JVM 内部使用的。也就是说 JVM 暴露给 java 程序的是 mirror 实例，而不是 instanceKlass，这与前面的理论一致。** JDK 库中的反射等工具类，其实都是基于 `java_lang_Class` 这个内部镜像类实现的。 另外在 allocate_instance_klass() 中，我们并没有看到静态字段的初始化，实际上静态字段的初始化是放到了镜像类中，创建镜像类的方法中有个方法 initialize_mirror_fields()，同样位于 hotspot/src/share/vm/classfile/javaClasses.cpp，贴下源码实现： initialize_mirror_fields() 方法1234567891011121314151617void java_lang_Class::initialize_mirror_fields(KlassHandle k, Handle mirror, Handle protection_domain, TRAPS) { // Allocate a simple java object for a lock. // This needs to be a java object because during class initialization // it can be held across a java call. typeArrayOop r = oopFactory::new_typeArray(T_INT, 0, CHECK); set_init_lock(mirror(), r); // Set protection domain also set_protection_domain(mirror(), protection_domain()); // Initialize static fields InstanceKlass::cast(k())-&gt;do_local_static_fields(&amp;initialize_static_field, mirror, CHECK);} 从代码中找到方法 do_local_static_fields()，这个方法就是初始化静态字段的方法，位于 hotspot/src/share/vm/oops/instanceKlass.cpp 中，如下： do_local_static_fields() 实现1234567891011121314151617void InstanceKlass::do_local_static_fields(void f(fieldDescriptor*, Handle, TRAPS), Handle mirror, TRAPS) { instanceKlassHandle h_this(THREAD, this); do_local_static_fields_impl(h_this, f, mirror, CHECK);}void InstanceKlass::do_local_static_fields_impl(instanceKlassHandle this_k, void f(fieldDescriptor* fd, Handle mirror, TRAPS), Handle mirror, TRAPS) { for (JavaFieldStream fs(this_k()); !fs.done(); fs.next()) { if (fs.access_flags().is_static()) { fieldDescriptor&amp; fd = fs.field_descriptor(); f(&amp;fd, mirror, CHECK); } }} 在 javaClasses.cpp 中调用 instanceKlass 的 do_local_static_fields() 方法时，传入了一个函数指针，这个函数指针代表如下，位于 hotspot/src/share/vm/classfile/javaClasses.cpp： 给静态字段赋初值的函数指针源码 &initialize_static_field123456789101112131415161718192021222324252627282930313233343536373839404142434445static void initialize_static_field(fieldDescriptor* fd, Handle mirror, TRAPS) { assert(mirror.not_null() &amp;&amp; fd-&gt;is_static(), &quot;just checking&quot;); if (fd-&gt;has_initial_value()) { BasicType t = fd-&gt;field_type(); switch (t) { case T_BYTE: mirror()-&gt;byte_field_put(fd-&gt;offset(), fd-&gt;int_initial_value()); break; case T_BOOLEAN: mirror()-&gt;bool_field_put(fd-&gt;offset(), fd-&gt;int_initial_value()); break; case T_CHAR: mirror()-&gt;char_field_put(fd-&gt;offset(), fd-&gt;int_initial_value()); break; case T_SHORT: mirror()-&gt;short_field_put(fd-&gt;offset(), fd-&gt;int_initial_value()); break; case T_INT: mirror()-&gt;int_field_put(fd-&gt;offset(), fd-&gt;int_initial_value()); break; case T_FLOAT: mirror()-&gt;float_field_put(fd-&gt;offset(), fd-&gt;float_initial_value()); break; case T_DOUBLE: mirror()-&gt;double_field_put(fd-&gt;offset(), fd-&gt;double_initial_value()); break; case T_LONG: mirror()-&gt;long_field_put(fd-&gt;offset(), fd-&gt;long_initial_value()); break; case T_OBJECT: { #ifdef ASSERT TempNewSymbol sym = SymbolTable::new_symbol(&quot;Ljava/lang/String;&quot;, CHECK); assert(fd-&gt;signature() == sym, &quot;just checking&quot;); #endif oop string = fd-&gt;string_initial_value(CHECK); mirror()-&gt;obj_field_put(fd-&gt;offset(), string); } break; default: THROW_MSG(vmSymbols::java_lang_ClassFormatError(), &quot;Illegal ConstantValue attribute in class file&quot;); } }} 在上面的函数中，通过 mirror() -&gt; xxx_field_put() 的方法将不同类型的静态字段存储到镜像类中。实际上，静态字段在类加载的阶段就已经完成了初始化。这里会有疑问：为什么要放在镜像类中？ 因为前面说过镜像类是给 java 的应用程序调用，所以 JDK 类库等反射工具类都可以拿到这个类的所有字段，无论字段是不是静态的。 至此，类的生命周期中第一阶段：类加载，已经完成了。 -XX:+TraceClassLoading 通过这个参数可以追踪加载的类","link":"/2021-12-JVM%E7%B3%BB%E5%88%97-%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"title":"JVM系列-双亲委派模型","text":"这是 JVM 系列的第六篇，见 JVM 系列。 写在前面在前面的文章里面，JVM 拿到 class 文件流之后，完成了以下的工作： 校验魔数 校验版本 解析常量池 解析字段 解析方法 解析属性 创建与 java 对象对等的内部对象 instanceKlass，提供给 JVM 使用 创建镜像类，提供给Java应用使用 要想在JVM内部创建对等的 oop-klass 对象，就必须要经过类加载器的加载过程。前面提到 java 体系中，我们了解到有 3 类类加载：引导类加载器（Bootstrap ClassLoader）、扩展类加载器（Bootstrap ClassLoader）、系统类加载器（Bootstrap ClassLoader）。实际上 JVM 规范只提到了 2 种，引导类加载器和自定义类加载器。当然引导类加载器事 C++ 写的，自定义类加载器用 java 语言定义。 C++ 定义的引导类加载器C++ 的类加载器位于：hotspot/src/share/vm/classfile/classLoader.hpp，如下： C++ 引导类加载器的定义 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237class ClassLoader: AllStatic { public: enum SomeConstants { package_hash_table_size = 31 // Number of buckets }; protected: friend class LazyClassPathEntry;// Performance countersstatic PerfCounter* _perf_accumulated_time;static PerfCounter* _perf_classes_inited;static PerfCounter* _perf_class_init_time;static PerfCounter* _perf_class_init_selftime;static PerfCounter* _perf_classes_verified;static PerfCounter* _perf_class_verify_time;static PerfCounter* _perf_class_verify_selftime;static PerfCounter* _perf_classes_linked;static PerfCounter* _perf_class_link_time;static PerfCounter* _perf_class_link_selftime;static PerfCounter* _perf_class_parse_time;static PerfCounter* _perf_class_parse_selftime;static PerfCounter* _perf_sys_class_lookup_time;static PerfCounter* _perf_shared_classload_time;static PerfCounter* _perf_sys_classload_time;static PerfCounter* _perf_app_classload_time;static PerfCounter* _perf_app_classload_selftime;static PerfCounter* _perf_app_classload_count;static PerfCounter* _perf_define_appclasses;static PerfCounter* _perf_define_appclass_time;static PerfCounter* _perf_define_appclass_selftime;static PerfCounter* _perf_app_classfile_bytes_read;static PerfCounter* _perf_sys_classfile_bytes_read;static PerfCounter* _sync_systemLoaderLockContentionRate;static PerfCounter* _sync_nonSystemLoaderLockContentionRate;static PerfCounter* _sync_JVMFindLoadedClassLockFreeCounter;static PerfCounter* _sync_JVMDefineClassLockFreeCounter;static PerfCounter* _sync_JNIDefineClassLockFreeCounter;static PerfCounter* _unsafe_defineClassCallCounter;static PerfCounter* _isUnsyncloadClass;static PerfCounter* _load_instance_class_failCounter;// First entry in linked list of ClassPathEntry instancesstatic ClassPathEntry* _first_entry;// Last entry in linked list of ClassPathEntry instancesstatic ClassPathEntry* _last_entry;static int _num_entries;// Hash table used to keep track of loaded packagesstatic PackageHashtable* _package_hash_table;static const char* _shared_archive;// Info used by CDSCDS_ONLY(static SharedPathsMiscInfo * _shared_paths_misc_info;)// Hash functionstatic unsigned int hash(const char *s, int n);// Returns the package file name corresponding to the specified package// or class name, or null if not found.static PackageInfo* lookup_package(const char *pkgname);// Adds a new package entry for the specified class or package name and// corresponding directory or jar file name.static bool add_package(const char *pkgname, int classpath_index, TRAPS);// Initializationstatic void setup_bootstrap_meta_index();static void setup_meta_index(const char* meta_index_path, const char* meta_index_dir,int start_index);static void setup_bootstrap_search_path();static void setup_search_path(const char *class_path, bool canonicalize=false);static void load_zip_library();static ClassPathEntry* create_class_path_entry(const char *path, const struct stat* st,bool lazy, bool throw_exception, TRAPS);// Canonicalizes path names, so strcmp will work properly. This is mainly// to avoid confusing the zip librarystatic bool get_canonical_path(const char* orig, char* out, int len);public:static int crc32(int crc, const char* buf, int len);static bool update_class_path_entry_list(const char *path,bool check_for_duplicates,bool throw_exception=true);static void print_bootclasspath();// Timingstatic PerfCounter* perf_accumulated_time() { return _perf_accumulated_time; }static PerfCounter* perf_classes_inited() { return _perf_classes_inited; }static PerfCounter* perf_class_init_time() { return _perf_class_init_time; }static PerfCounter* perf_class_init_selftime() { return _perf_class_init_selftime; }static PerfCounter* perf_classes_verified() { return _perf_classes_verified; }static PerfCounter* perf_class_verify_time() { return _perf_class_verify_time; }static PerfCounter* perf_class_verify_selftime() { return _perf_class_verify_selftime; }static PerfCounter* perf_classes_linked() { return _perf_classes_linked; }static PerfCounter* perf_class_link_time() { return _perf_class_link_time; }static PerfCounter* perf_class_link_selftime() { return _perf_class_link_selftime; }static PerfCounter* perf_class_parse_time() { return _perf_class_parse_time; }static PerfCounter* perf_class_parse_selftime() { return _perf_class_parse_selftime; }static PerfCounter* perf_sys_class_lookup_time() { return _perf_sys_class_lookup_time; }static PerfCounter* perf_shared_classload_time() { return _perf_shared_classload_time; }static PerfCounter* perf_sys_classload_time() { return _perf_sys_classload_time; }static PerfCounter* perf_app_classload_time() { return _perf_app_classload_time; }static PerfCounter* perf_app_classload_selftime() { return _perf_app_classload_selftime; }static PerfCounter* perf_app_classload_count() { return _perf_app_classload_count; }static PerfCounter* perf_define_appclasses() { return _perf_define_appclasses; }static PerfCounter* perf_define_appclass_time() { return _perf_define_appclass_time; }static PerfCounter* perf_define_appclass_selftime() { return _perf_define_appclass_selftime; }static PerfCounter* perf_app_classfile_bytes_read() { return _perf_app_classfile_bytes_read; }static PerfCounter* perf_sys_classfile_bytes_read() { return _perf_sys_classfile_bytes_read; }// Record how often system loader lock object is contendedstatic PerfCounter* sync_systemLoaderLockContentionRate() {return _sync_systemLoaderLockContentionRate;}// Record how often non system loader lock object is contendedstatic PerfCounter* sync_nonSystemLoaderLockContentionRate() {return _sync_nonSystemLoaderLockContentionRate;}// Record how many calls to JVM_FindLoadedClass w/o holding a lockstatic PerfCounter* sync_JVMFindLoadedClassLockFreeCounter() {return _sync_JVMFindLoadedClassLockFreeCounter;}// Record how many calls to JVM_DefineClass w/o holding a lockstatic PerfCounter* sync_JVMDefineClassLockFreeCounter() {return _sync_JVMDefineClassLockFreeCounter;}// Record how many calls to jni_DefineClass w/o holding a lockstatic PerfCounter* sync_JNIDefineClassLockFreeCounter() {return _sync_JNIDefineClassLockFreeCounter;}// Record how many calls to Unsafe_DefineClassstatic PerfCounter* unsafe_defineClassCallCounter() {return _unsafe_defineClassCallCounter;}// Record how many times SystemDictionary::load_instance_class call// fails with linkageError when Unsyncloadclass flag is set.static PerfCounter* load_instance_class_failCounter() {return _load_instance_class_failCounter;}// Load individual .class filestatic instanceKlassHandle load_classfile(Symbol* h_name, TRAPS);// If the specified package has been loaded by the system, then returns// the name of the directory or ZIP file that the package was loaded from.// Returns null if the package was not loaded.// Note: The specified name can either be the name of a class or package.// If a package name is specified, then it must be &quot;/&quot;-separator and also// end with a trailing &quot;/&quot;.static oop get_system_package(const char* name, TRAPS);// Returns an array of Java strings representing all of the currently// loaded system packages.// Note: The package names returned are &quot;/&quot;-separated and end with a// trailing &quot;/&quot;.static objArrayOop get_system_packages(TRAPS);// Initializationstatic void initialize();CDS_ONLY(static void initialize_shared_path();)static void create_package_info_table();static void create_package_info_table(HashtableBucket&lt;mtClass&gt; *t, int length,int number_of_entries);static int compute_Object_vtable();static ClassPathEntry* classpath_entry(int n) {ClassPathEntry* e = ClassLoader::_first_entry;while (--n &gt;= 0) {assert(e != NULL, &quot;Not that many classpath entries.&quot;);e = e-&gt;next();}return e;}static int num_classpath_entries() {return _num_entries;}#if INCLUDE_CDS// Sharing dump and restorestatic void copy_package_info_buckets(char** top, char* end);static void copy_package_info_table(char** top, char* end);static void check_shared_classpath(const char *path);static void finalize_shared_paths_misc_info();static int get_shared_paths_misc_info_size();static void* get_shared_paths_misc_info();static bool check_shared_paths_misc_info(void* info, int size);static void exit_with_path_failure(const char* error, const char* message);#endifstatic void trace_class_path(outputStream* out, const char* msg, const char* name = NULL);// VM monitoring and management supportstatic jlong classloader_time_ms();static jlong class_method_total_size();static jlong class_init_count();static jlong class_init_time_ms();static jlong class_verify_time_ms();static jlong class_link_count();static jlong class_link_time_ms();// indicates if class path already contains a entry (exact match by name)static bool contains_entry(ClassPathEntry* entry);// adds a class path liststatic void add_to_list(ClassPathEntry* new_entry);// creates a class path zip entry (returns NULL if JAR file cannot be opened)static ClassPathZipEntry* create_class_path_zip_entry(const char *apath);// obtain package name from a fully qualified class name// *bad_class_name is set to true if there's a problem with parsing class_name, to// distinguish from a class_name with no package name, as both cases have a NULL return valuestatic const char* package_from_name(const char* const class_name, bool* bad_class_name = NULL);// Debuggingstatic void verify() PRODUCT_RETURN;// Force compilation of all methods in all classes in bootstrap class path (stress test)#ifndef PRODUCTprotected:static int _compile_the_world_class_counter;static int _compile_the_world_method_counter;public:static void compile_the_world();static void compile_the_world_in(char* name, Handle loader, TRAPS);static int compile_the_world_counter() { return _compile_the_world_class_counter; }#endif //PRODUCT}; 核心的方法： 加载类文件12// Load individual .class filestatic instanceKlassHandle load_classfile(Symbol* h_name, TRAPS); 再看看 load_classfile() 函数里面的内容： load_classfile() 函数定义 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879instanceKlassHandle ClassLoader::load_classfile(Symbol* h_name, TRAPS) { ResourceMark rm(THREAD); const char* class_name = h_name-&gt;as_C_string(); EventMark m(&quot;loading class %s&quot;, class_name); ThreadProfilerMark tpm(ThreadProfilerMark::classLoaderRegion); stringStream st; // st.print() uses too much stack space while handling a StackOverflowError // st.print(&quot;%s.class&quot;, h_name-&gt;as_utf8()); st.print_raw(h_name-&gt;as_utf8()); st.print_raw(&quot;.class&quot;); const char* file_name = st.as_string(); ClassLoaderExt::Context context(class_name, file_name, THREAD); // Lookup stream for parsing .class file ClassFileStream* stream = NULL; int classpath_index = 0; ClassPathEntry* e = NULL; instanceKlassHandle h; { PerfClassTraceTime vmtimer(perf_sys_class_lookup_time(), ((JavaThread*) THREAD)-&gt;get_thread_stat()-&gt;perf_timers_addr(), PerfClassTraceTime::CLASS_LOAD); e = _first_entry; while (e != NULL) { stream = e-&gt;open_stream(file_name, CHECK_NULL); if (!context.check(stream, classpath_index)) { return h; // NULL } if (stream != NULL) { break; } e = e-&gt;next(); ++classpath_index; } } if (stream != NULL) { // class file found, parse it ClassFileParser parser(stream); ClassLoaderData* loader_data = ClassLoaderData::the_null_class_loader_data(); Handle protection_domain; TempNewSymbol parsed_name = NULL; // Callers are expected to declare a ResourceMark to determine // the lifetime of any updated (resource) allocated under // this call to parseClassFile // We do not declare another ResourceMark here, reusing the one declared // at the start of the method instanceKlassHandle result = parser.parseClassFile(h_name, loader_data, protection_domain, parsed_name, context.should_verify(classpath_index), THREAD); if (HAS_PENDING_EXCEPTION) { ResourceMark rm; if (DumpSharedSpaces) { tty-&gt;print_cr(&quot;Preload Error: Failed to load %s&quot;, class_name); } return h; }#if INCLUDE_JFR { InstanceKlass* ik = result(); ON_KLASS_CREATION(ik, parser, THREAD); result = instanceKlassHandle(ik); }#endif h = context.record_result(classpath_index, e, result, THREAD); } else { if (DumpSharedSpaces) { tty-&gt;print_cr(&quot;Preload Warning: Cannot find %s&quot;, class_name); } } return h;} load_classfile() 函数里面最重要的函数就是：parseClassFile()： parseClassFile() 函数定义 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561instanceKlassHandle ClassFileParser::parseClassFile(Symbol* name, ClassLoaderData* loader_data, Handle protection_domain, KlassHandle host_klass, GrowableArray&lt;Handle&gt;* cp_patches, TempNewSymbol&amp; parsed_name, bool verify, TRAPS) { // When a retransformable agent is attached, JVMTI caches the // class bytes that existed before the first retransformation. // If RedefineClasses() was used before the retransformable // agent attached, then the cached class bytes may not be the // original class bytes. JvmtiCachedClassFileData *cached_class_file = NULL; Handle class_loader(THREAD, loader_data-&gt;class_loader()); bool has_default_methods = false; bool declares_default_methods = false; // JDK-8252904: // The stream (resource) attached to the instance klass may // be reallocated by this method. When JFR is included the // stream may need to survive beyond the end of the call. So, // the caller is expected to declare the ResourceMark that // determines the lifetime of resources allocated under this // call. ClassFileStream* cfs = stream(); // Timing assert(THREAD-&gt;is_Java_thread(), &quot;must be a JavaThread&quot;); JavaThread* jt = (JavaThread*) THREAD; PerfClassTraceTime ctimer(ClassLoader::perf_class_parse_time(), ClassLoader::perf_class_parse_selftime(), NULL, jt-&gt;get_thread_stat()-&gt;perf_recursion_counts_addr(), jt-&gt;get_thread_stat()-&gt;perf_timers_addr(), PerfClassTraceTime::PARSE_CLASS); init_parsed_class_attributes(loader_data); if (JvmtiExport::should_post_class_file_load_hook()) { // Get the cached class file bytes (if any) from the class that // is being redefined or retransformed. We use jvmti_thread_state() // instead of JvmtiThreadState::state_for(jt) so we don't allocate // a JvmtiThreadState any earlier than necessary. This will help // avoid the bug described by 7126851. JvmtiThreadState *state = jt-&gt;jvmti_thread_state(); if (state != NULL) { KlassHandle *h_class_being_redefined = state-&gt;get_class_being_redefined(); if (h_class_being_redefined != NULL) { instanceKlassHandle ikh_class_being_redefined = instanceKlassHandle(THREAD, (*h_class_being_redefined)()); cached_class_file = ikh_class_being_redefined-&gt;get_cached_class_file(); } } unsigned char* ptr = cfs-&gt;buffer(); unsigned char* end_ptr = cfs-&gt;buffer() + cfs-&gt;length(); JvmtiExport::post_class_file_load_hook(name, class_loader(), protection_domain, &amp;ptr, &amp;end_ptr, &amp;cached_class_file); if (ptr != cfs-&gt;buffer()) { // JVMTI agent has modified class file data. // Set new class file stream using JVMTI agent modified // class file data. cfs = new ClassFileStream(ptr, end_ptr - ptr, cfs-&gt;source()); set_stream(cfs); } } _host_klass = host_klass; _cp_patches = cp_patches; instanceKlassHandle nullHandle; // Figure out whether we can skip format checking (matching classic VM behavior) if (DumpSharedSpaces) { // verify == true means it's a 'remote' class (i.e., non-boot class) // Verification decision is based on BytecodeVerificationRemote flag // for those classes. _need_verify = (verify) ? BytecodeVerificationRemote : BytecodeVerificationLocal; } else { _need_verify = Verifier::should_verify_for(class_loader(), verify); } // Set the verify flag in stream cfs-&gt;set_verify(_need_verify); // Save the class file name for easier error message printing. _class_name = (name != NULL) ? name : vmSymbols::unknown_class_name(); cfs-&gt;guarantee_more(8, CHECK_(nullHandle)); // magic, major, minor // Magic value u4 magic = cfs-&gt;get_u4_fast(); guarantee_property(magic == JAVA_CLASSFILE_MAGIC, &quot;Incompatible magic value %u in class file %s&quot;, magic, CHECK_(nullHandle)); // Version numbers u2 minor_version = cfs-&gt;get_u2_fast(); u2 major_version = cfs-&gt;get_u2_fast(); if (DumpSharedSpaces &amp;&amp; major_version &lt; JAVA_1_5_VERSION) { ResourceMark rm; warning(&quot;Pre JDK 1.5 class not supported by CDS: %u.%u %s&quot;, major_version, minor_version, name-&gt;as_C_string()); Exceptions::fthrow( THREAD_AND_LOCATION, vmSymbols::java_lang_UnsupportedClassVersionError(), &quot;Unsupported major.minor version for dump time %u.%u&quot;, major_version, minor_version); } // Check version numbers - we check this even with verifier off if (!is_supported_version(major_version, minor_version)) { if (name == NULL) { Exceptions::fthrow( THREAD_AND_LOCATION, vmSymbols::java_lang_UnsupportedClassVersionError(), &quot;Unsupported class file version %u.%u, &quot; &quot;this version of the Java Runtime only recognizes class file versions up to %u.%u&quot;, major_version, minor_version, JAVA_MAX_SUPPORTED_VERSION, JAVA_MAX_SUPPORTED_MINOR_VERSION); } else { ResourceMark rm(THREAD); Exceptions::fthrow( THREAD_AND_LOCATION, vmSymbols::java_lang_UnsupportedClassVersionError(), &quot;%s has been compiled by a more recent version of the Java Runtime (class file version %u.%u), &quot; &quot;this version of the Java Runtime only recognizes class file versions up to %u.%u&quot;, name-&gt;as_C_string(), major_version, minor_version, JAVA_MAX_SUPPORTED_VERSION, JAVA_MAX_SUPPORTED_MINOR_VERSION); } return nullHandle; } _major_version = major_version; _minor_version = minor_version; // Check if verification needs to be relaxed for this class file // Do not restrict it to jdk1.0 or jdk1.1 to maintain backward compatibility (4982376) _relax_verify = relax_format_check_for(_loader_data); // Constant pool constantPoolHandle cp = parse_constant_pool(CHECK_(nullHandle)); int cp_size = cp-&gt;length(); cfs-&gt;guarantee_more(8, CHECK_(nullHandle)); // flags, this_class, super_class, infs_len // Access flags AccessFlags access_flags; jint flags = cfs-&gt;get_u2_fast() &amp; JVM_RECOGNIZED_CLASS_MODIFIERS; if ((flags &amp; JVM_ACC_INTERFACE) &amp;&amp; _major_version &lt; JAVA_6_VERSION) { // Set abstract bit for old class files for backward compatibility flags |= JVM_ACC_ABSTRACT; } verify_legal_class_modifiers(flags, CHECK_(nullHandle)); access_flags.set_flags(flags); // This class and superclass _this_class_index = cfs-&gt;get_u2_fast(); check_property( valid_cp_range(_this_class_index, cp_size) &amp;&amp; cp-&gt;tag_at(_this_class_index).is_unresolved_klass(), &quot;Invalid this class index %u in constant pool in class file %s&quot;, _this_class_index, CHECK_(nullHandle)); Symbol* class_name = cp-&gt;unresolved_klass_at(_this_class_index); assert(class_name != NULL, &quot;class_name can't be null&quot;); // It's important to set parsed_name *before* resolving the super class. // (it's used for cleanup by the caller if parsing fails) parsed_name = class_name; // parsed_name is returned and can be used if there's an error, so add to // its reference count. Caller will decrement the refcount. parsed_name-&gt;increment_refcount(); // Update _class_name which could be null previously to be class_name _class_name = class_name; // Don't need to check whether this class name is legal or not. // It has been checked when constant pool is parsed. // However, make sure it is not an array type. if (_need_verify) { guarantee_property(class_name-&gt;byte_at(0) != JVM_SIGNATURE_ARRAY, &quot;Bad class name in class file %s&quot;, CHECK_(nullHandle)); } Klass* preserve_this_klass; // for storing result across HandleMark // release all handles when parsing is done { HandleMark hm(THREAD); // Checks if name in class file matches requested name if (name != NULL &amp;&amp; class_name != name) { ResourceMark rm(THREAD); Exceptions::fthrow( THREAD_AND_LOCATION, vmSymbols::java_lang_NoClassDefFoundError(), &quot;%s (wrong name: %s)&quot;, name-&gt;as_C_string(), class_name-&gt;as_C_string() ); return nullHandle; } if (TraceClassLoadingPreorder) { tty-&gt;print(&quot;[Loading %s&quot;, (name != NULL) ? name-&gt;as_klass_external_name() : &quot;NoName&quot;); if (cfs-&gt;source() != NULL) tty-&gt;print(&quot; from %s&quot;, cfs-&gt;source()); tty-&gt;print_cr(&quot;]&quot;); }#if INCLUDE_CDS if (DumpLoadedClassList != NULL &amp;&amp; cfs-&gt;source() != NULL &amp;&amp; classlist_file-&gt;is_open()) { // Only dump the classes that can be stored into CDS archive if (SystemDictionaryShared::is_sharing_possible(loader_data)) { if (name != NULL) { ResourceMark rm(THREAD); classlist_file-&gt;print_cr(&quot;%s&quot;, name-&gt;as_C_string()); classlist_file-&gt;flush(); } } }#endif u2 super_class_index = cfs-&gt;get_u2_fast(); instanceKlassHandle super_klass = parse_super_class(super_class_index, CHECK_NULL); // Interfaces u2 itfs_len = cfs-&gt;get_u2_fast(); Array&lt;Klass*&gt;* local_interfaces = parse_interfaces(itfs_len, protection_domain, _class_name, &amp;has_default_methods, CHECK_(nullHandle)); u2 java_fields_count = 0; // Fields (offsets are filled in later) FieldAllocationCount fac; Array&lt;u2&gt;* fields = parse_fields(class_name, access_flags.is_interface(), &amp;fac, &amp;java_fields_count, CHECK_(nullHandle)); // Methods bool has_final_method = false; AccessFlags promoted_flags; promoted_flags.set_flags(0); Array&lt;Method*&gt;* methods = parse_methods(access_flags.is_interface(), &amp;promoted_flags, &amp;has_final_method, &amp;declares_default_methods, CHECK_(nullHandle)); if (declares_default_methods) { has_default_methods = true; } // Additional attributes ClassAnnotationCollector parsed_annotations; parse_classfile_attributes(&amp;parsed_annotations, CHECK_(nullHandle)); // Finalize the Annotations metadata object, // now that all annotation arrays have been created. create_combined_annotations(CHECK_(nullHandle)); // Make sure this is the end of class file stream guarantee_property(cfs-&gt;at_eos(), &quot;Extra bytes at the end of class file %s&quot;, CHECK_(nullHandle)); if (_class_name == vmSymbols::java_lang_Object()) { check_property(_local_interfaces == Universe::the_empty_klass_array(), &quot;java.lang.Object cannot implement an interface in class file %s&quot;, CHECK_(nullHandle)); } // We check super class after class file is parsed and format is checked if (super_class_index &gt; 0 &amp;&amp; super_klass.is_null()) { Symbol* sk = cp-&gt;klass_name_at(super_class_index); if (access_flags.is_interface()) { // Before attempting to resolve the superclass, check for class format // errors not checked yet. guarantee_property(sk == vmSymbols::java_lang_Object(), &quot;Interfaces must have java.lang.Object as superclass in class file %s&quot;, CHECK_(nullHandle)); } Klass* k = SystemDictionary::resolve_super_or_fail(class_name, sk, class_loader, protection_domain, true, CHECK_(nullHandle)); KlassHandle kh (THREAD, k); super_klass = instanceKlassHandle(THREAD, kh()); } if (super_klass.not_null()) { if (super_klass-&gt;has_default_methods()) { has_default_methods = true; } if (super_klass-&gt;is_interface()) { ResourceMark rm(THREAD); Exceptions::fthrow( THREAD_AND_LOCATION, vmSymbols::java_lang_IncompatibleClassChangeError(), &quot;class %s has interface %s as super class&quot;, class_name-&gt;as_klass_external_name(), super_klass-&gt;external_name() ); return nullHandle; } // Make sure super class is not final if (super_klass-&gt;is_final()) { THROW_MSG_(vmSymbols::java_lang_VerifyError(), &quot;Cannot inherit from final class&quot;, nullHandle); } } // save super klass for error handling. _super_klass = super_klass; // Compute the transitive list of all unique interfaces implemented by this class _transitive_interfaces = compute_transitive_interfaces(super_klass, local_interfaces, CHECK_(nullHandle)); // sort methods intArray* method_ordering = sort_methods(methods); // promote flags from parse_methods() to the klass' flags access_flags.add_promoted_flags(promoted_flags.as_int()); // Size of Java vtable (in words) int vtable_size = 0; int itable_size = 0; int num_miranda_methods = 0; GrowableArray&lt;Method*&gt; all_mirandas(20); klassVtable::compute_vtable_size_and_num_mirandas( &amp;vtable_size, &amp;num_miranda_methods, &amp;all_mirandas, super_klass(), methods, access_flags, class_loader, class_name, local_interfaces, CHECK_(nullHandle)); // Size of Java itable (in words) itable_size = access_flags.is_interface() ? 0 : klassItable::compute_itable_size(_transitive_interfaces); FieldLayoutInfo info; layout_fields(class_loader, &amp;fac, &amp;parsed_annotations, &amp;info, CHECK_NULL); int total_oop_map_size2 = InstanceKlass::nonstatic_oop_map_size(info.total_oop_map_count); // Compute reference type ReferenceType rt; if (super_klass() == NULL) { rt = REF_NONE; } else { rt = super_klass-&gt;reference_type(); } // We can now create the basic Klass* for this klass _klass = InstanceKlass::allocate_instance_klass(loader_data, vtable_size, itable_size, info.static_field_size, total_oop_map_size2, rt, access_flags, name, super_klass(), !host_klass.is_null(), CHECK_(nullHandle)); instanceKlassHandle this_klass (THREAD, _klass); assert(this_klass-&gt;static_field_size() == info.static_field_size, &quot;sanity&quot;); assert(this_klass-&gt;nonstatic_oop_map_count() == info.total_oop_map_count, &quot;sanity&quot;); // Fill in information already parsed this_klass-&gt;set_should_verify_class(verify); jint lh = Klass::instance_layout_helper(info.instance_size, false); this_klass-&gt;set_layout_helper(lh); assert(this_klass-&gt;oop_is_instance(), &quot;layout is correct&quot;); assert(this_klass-&gt;size_helper() == info.instance_size, &quot;correct size_helper&quot;); // Not yet: supers are done below to support the new subtype-checking fields //this_klass-&gt;set_super(super_klass()); this_klass-&gt;set_class_loader_data(loader_data); this_klass-&gt;set_nonstatic_field_size(info.nonstatic_field_size); this_klass-&gt;set_has_nonstatic_fields(info.has_nonstatic_fields); this_klass-&gt;set_static_oop_field_count(fac.count[STATIC_OOP]); apply_parsed_class_metadata(this_klass, java_fields_count, CHECK_NULL); if (has_final_method) { this_klass-&gt;set_has_final_method(); } this_klass-&gt;copy_method_ordering(method_ordering, CHECK_NULL); // The InstanceKlass::_methods_jmethod_ids cache // is managed on the assumption that the initial cache // size is equal to the number of methods in the class. If // that changes, then InstanceKlass::idnum_can_increment() // has to be changed accordingly. this_klass-&gt;set_initial_method_idnum(methods-&gt;length()); this_klass-&gt;set_name(cp-&gt;klass_name_at(_this_class_index)); if (is_anonymous()) // I am well known to myself cp-&gt;klass_at_put(_this_class_index, this_klass()); // eagerly resolve this_klass-&gt;set_minor_version(minor_version); this_klass-&gt;set_major_version(major_version); this_klass-&gt;set_has_default_methods(has_default_methods); this_klass-&gt;set_declares_default_methods(declares_default_methods); if (!host_klass.is_null()) { assert (this_klass-&gt;is_anonymous(), &quot;should be the same&quot;); this_klass-&gt;set_host_klass(host_klass()); } // Set up Method*::intrinsic_id as soon as we know the names of methods. // (We used to do this lazily, but now we query it in Rewriter, // which is eagerly done for every method, so we might as well do it now, // when everything is fresh in memory.) if (Method::klass_id_for_intrinsics(this_klass()) != vmSymbols::NO_SID) { for (int j = 0; j &lt; methods-&gt;length(); j++) { methods-&gt;at(j)-&gt;init_intrinsic_id(); } } if (cached_class_file != NULL) { // JVMTI: we have an InstanceKlass now, tell it about the cached bytes this_klass-&gt;set_cached_class_file(cached_class_file); } // Fill in field values obtained by parse_classfile_attributes if (parsed_annotations.has_any_annotations()) parsed_annotations.apply_to(this_klass); apply_parsed_class_attributes(this_klass); // Miranda methods if ((num_miranda_methods &gt; 0) || // if this class introduced new miranda methods or (super_klass.not_null() &amp;&amp; (super_klass-&gt;has_miranda_methods())) // super class exists and this class inherited miranda methods ) { this_klass-&gt;set_has_miranda_methods(); // then set a flag } // Fill in information needed to compute superclasses. this_klass-&gt;initialize_supers(super_klass(), CHECK_(nullHandle)); // Initialize itable offset tables klassItable::setup_itable_offset_table(this_klass); // Compute transitive closure of interfaces this class implements // Do final class setup fill_oop_maps(this_klass, info.nonstatic_oop_map_count, info.nonstatic_oop_offsets, info.nonstatic_oop_counts); // Fill in has_finalizer, has_vanilla_constructor, and layout_helper set_precomputed_flags(this_klass); // reinitialize modifiers, using the InnerClasses attribute int computed_modifiers = this_klass-&gt;compute_modifier_flags(CHECK_(nullHandle)); this_klass-&gt;set_modifier_flags(computed_modifiers); // check if this class can access its super class check_super_class_access(this_klass, CHECK_(nullHandle)); // check if this class can access its superinterfaces check_super_interface_access(this_klass, CHECK_(nullHandle)); // check if this class overrides any final method check_final_method_override(this_klass, CHECK_(nullHandle)); // check that if this class is an interface then it doesn't have static methods if (this_klass-&gt;is_interface()) { /* An interface in a JAVA 8 classfile can be static */ if (_major_version &lt; JAVA_8_VERSION) { check_illegal_static_method(this_klass, CHECK_(nullHandle)); } } // Allocate mirror and initialize static fields java_lang_Class::create_mirror(this_klass, class_loader, protection_domain, CHECK_(nullHandle)); // Generate any default methods - default methods are interface methods // that have a default implementation. This is new with Lambda project. if (has_default_methods ) { DefaultMethods::generate_default_methods( this_klass(), &amp;all_mirandas, CHECK_(nullHandle)); } ClassLoadingService::notify_class_loaded(InstanceKlass::cast(this_klass()), false /* not shared class */); if (TraceClassLoading) { ResourceMark rm; // print in a single call to reduce interleaving of output if (cfs-&gt;source() != NULL) { tty-&gt;print(&quot;[Loaded %s from %s]\\n&quot;, this_klass-&gt;external_name(), cfs-&gt;source()); } else if (class_loader.is_null()) { Klass* caller = THREAD-&gt;is_Java_thread() ? ((JavaThread*)THREAD)-&gt;security_get_caller_class(1) : NULL; // caller can be NULL, for example, during a JVMTI VM_Init hook if (caller != NULL) { tty-&gt;print(&quot;[Loaded %s by instance of %s]\\n&quot;, this_klass-&gt;external_name(), InstanceKlass::cast(caller)-&gt;external_name()); } else { tty-&gt;print(&quot;[Loaded %s]\\n&quot;, this_klass-&gt;external_name()); } } else { tty-&gt;print(&quot;[Loaded %s from %s]\\n&quot;, this_klass-&gt;external_name(), InstanceKlass::cast(class_loader-&gt;klass())-&gt;external_name()); } } if (TraceClassResolution) { ResourceMark rm; // print out the superclass. const char * from = this_klass()-&gt;external_name(); if (this_klass-&gt;java_super() != NULL) { tty-&gt;print(&quot;RESOLVE %s %s (super)\\n&quot;, from, InstanceKlass::cast(this_klass-&gt;java_super())-&gt;external_name()); } // print out each of the interface classes referred to by this class. Array&lt;Klass*&gt;* local_interfaces = this_klass-&gt;local_interfaces(); if (local_interfaces != NULL) { int length = local_interfaces-&gt;length(); for (int i = 0; i &lt; length; i++) { Klass* k = local_interfaces-&gt;at(i); InstanceKlass* to_class = InstanceKlass::cast(k); const char * to = to_class-&gt;external_name(); tty-&gt;print(&quot;RESOLVE %s %s (interface)\\n&quot;, from, to); } } } // preserve result across HandleMark preserve_this_klass = this_klass(); } JFR_ONLY(INIT_ID(preserve_this_klass);) // Create new handle outside HandleMark (might be needed for // Extended Class Redefinition) instanceKlassHandle this_klass (THREAD, preserve_this_klass); debug_only(this_klass-&gt;verify();) // Clear class if no error has occurred so destructor doesn't deallocate it _klass = NULL; return this_klass;} 而 parseClassFile() 函数就是我们类加载中，解析 class 字节流，生成 instanceKlass C++ 对等对象这部分的逻辑和流程，可参考前面的文章。 Java 语言定义的类加载器Java语言定义的类加载器就是 JDK 核心类库中的类：java.lang.ClassLoader，jdk8 中的加载器类的关系如下图： AppClassLoader 和 ExtClassLoader 都被组合在 Launcher 中。扩展类加载器和系统类加载器都最终依赖于 ClassLoader 类的 defineClass 的 native 方法，才能完成类加载。 3种类型的类加载器之间的关系： 各种类加载器之间的关系并非面向对象的特性 “继承” 的关系，引导类加载器是用 C++ 写的，java 类想去继承也没有办法。上面的 JDK 类加载器也是被组合在 Launcher 类中，都是继承的 URLClassLoader 类。 所以这里可以看出，上面的 3 种类型的类加载器之间并没有面向对象中 “继承” 关系。 双亲委派机制对于java应用来说，会用 AppClassLoader 类加载器去加载，先来看下 JDK 类加载方法调用链： 上面的调用链中，最终还是会调用类 ClassLoader 中的 native 的方法去加载。比较重要的两个方法，一个是 loadClass() 和 defineClass()，着重来看一下这两个方法，首先看 loadClass 方法，这个方法就是双亲委托加载机制的核心，方法源码： ClassLoader123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class ClassLoader { ...... // The parent class loader for delegation private final ClassLoader parent; ...... protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } ......} 我们知道，系统类加载器的父加载器是扩展类加载器，扩展类加载器的父类加载器是引导类加载器。java 应用类在系统类加载器（AppClassLoader）加载后，会进入到 ClassLoader 中的 loadClasss() 方法，在方法中： 首先判断有没有加载过该类 在AppClassLoader加载时，它的代理类加载器即 parent 是 ExtClassLoader，parent 不为空，继续嵌套调用 loaderClass 方法，这时候的 this 指向的是 ExtClassLoader，它的代理类是 C++ 引导类，所以在 java 里面是 null，就会进入方法 findBootstrapClassOrNull，这个方法调用的 native 的引导类加载的。 在上面的做操作后，如果还是没有找到该类的话，就会调用方法 findClass，这个方法在 ClassLoader 类中是留给子类实现的，在 URLClassLoader 中实现了该方法，最终还是会调用 ClassLoader 中的 defineClass 方法，而 ClassLoader 中的 defineClass 方法最后调用的是 native 系列的 defineClass* 方法，如下：native 系列的 defineClass 方法12345678public abstract class ClassLoader { private native Class&lt;?&gt; defineClass0(String name, byte[] b, int off, int len, ProtectionDomain pd); private native Class&lt;?&gt; defineClass1(String name, byte[] b, int off, int len, ProtectionDomain pd, String source); private native Class&lt;?&gt; defineClass2(String name, java.nio.ByteBuffer b, int off, int len, ProtectionDomain pd, String source);} 所以在 JDK 中的类加载器，先找App类加载器加载，然后系统类加载器找扩展类加载器加载，扩展类加载器找引导类加载器加载，如果Ext加载器加载和Bootstrap类加载器都没有找到该类的话，那么App类加载器完成该类的加载，一级一级的往上委托，如果都不行，就自己加载，这样就保证了所有的类都能保证同一个类加载器。这就是双亲委托机制。 从上面的代码可以看到，如果想要自定义一个类加载器，并且打破双亲委派机制，那么需要重写类 ClassLoader 中 findClass 方法。可以来看一个例子：首先定义一个 Hello.java 类，代码： Hello.java1234567package top.caolizhi.example.jvm.classloader;public class Hello { public void helloClassLoader() { System.out.println(&quot;hello, class loader: &quot; + this.getClass().getClassLoader()); }} 再定义一个类加载器，继承 ClassLoader 类，并且重写方法 findClass。如下： CLZClassLoader.java1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CLZClassLoader extends ClassLoader { @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { File f = new File(&quot;E:/Workspaces/Git/caolizhi/jvm/target/classes/&quot;, name.replace(&quot;.&quot;, &quot;/&quot;).concat(&quot;.class&quot;)); Class&lt;?&gt; clazz = null; try { FileInputStream fileInputStream = new FileInputStream(f); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); int b; while ((b = fileInputStream.read()) != -1) { byteArrayOutputStream.write(b); } byte[] bytes = byteArrayOutputStream.toByteArray(); byteArrayOutputStream.close(); fileInputStream.close(); clazz = defineClass(name, bytes, 0, bytes.length); } catch (IOException e) { e.printStackTrace(); } return clazz; } public static void main(String[] args) { CLZClassLoader clzClassLoader = new CLZClassLoader(); try { System.out.println(&quot;系统类加载器：&quot;); Class&lt;?&gt; clazz1 = clzClassLoader.loadClass(&quot;top.caolizhi.example.jvm.classloader.Hello&quot;); Hello hello = (Hello) clazz1.newInstance(); hello.helloClassLoader(); System.out.println(&quot;=====================================================================&quot;); System.out.println(&quot;自定义类加载器：&quot;); Class&lt;?&gt; clazz = clzClassLoader.findClass(&quot;top.caolizhi.example.jvm.classloader.Hello&quot;); Object o = clazz.getDeclaredConstructor().newInstance(); // Hello o = (Hello) clazz.getDeclaredConstructor().newInstance(); // 强转就会报错，因为不是同一个类加载器加载的，JVM 认为不是同一个类。 // o.helloClassLoader(); Method method = clazz.getDeclaredMethod(&quot;helloClassLoader&quot;); method.invoke(o,null); } catch (InstantiationException | InvocationTargetException | NoSuchMethodException | IllegalAccessException | ClassNotFoundException e) { e.printStackTrace(); } }} CLZClassLoader 类 main 方法中，用 JDK 提供的方法 loadClass 和 自定义的 findClass 方法分别加载 Hello 类， Hello 类中的 helloClassLoader() 方法打印自己的类加载器信息。输出结果已经很明确，前者是双亲委托加载，后者并非如此。 12345系统类加载器：hello, class loader: sun.misc.Launcher$AppClassLoader@18b4aac2=====================================================================自定义类加载器：hello, class loader: top.caolizhi.example.jvm.classloader.CLZClassLoader@2f0e140b 另外不管是 JDK 的类加载器还是自定义的类加载器，最后都会调用方法 defineClass 方法，这个方法结构如下： defineClass 方法123456789101112131415public abstract class ClassLoader { ...... protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ProtectionDomain protectionDomain) throws ClassFormatError { protectionDomain = preDefineClass(name, protectionDomain); String source = defineClassSourceLocation(protectionDomain); Class&lt;?&gt; c = defineClass1(name, b, off, len, protectionDomain, source); postDefineClass(c, protectionDomain); return c; } ......} 这里面有个方法 preDefineClass 值得注意，其方法内容： 1234567891011121314151617181920212223242526272829303132public abstract class ClassLoader { ...... /* Determine protection domain, and check that: - not define java.* class, - signer of this class matches signers for the rest of the classes in package. */ private ProtectionDomain preDefineClass(String name, ProtectionDomain pd) { if (!checkName(name)) throw new NoClassDefFoundError(&quot;IllegalName: &quot; + name); // Note: Checking logic in java.lang.invoke.MemberName.checkForTypeAlias // relies on the fact that spoofing is impossible if a class has a name // of the form &quot;java.*&quot; if ((name != null) &amp;&amp; name.startsWith(&quot;java.&quot;)) { throw new SecurityException (&quot;Prohibited package name: &quot; + name.substring(0, name.lastIndexOf('.'))); } if (pd == null) { pd = defaultDomain; } if (name != null) checkCerts(name, pd.getCodeSource()); return pd; } ......} 从它的方法体可以看到，如果加载的类的 name 是以 java. 前缀开头的，直接拒绝，抛出异常，而 java. 开头的类都是 JDK 的核心类，哈哈，机关在这里呢，所以无论如何，JDK 的核心类库，比如 java.lang.Object 都是有保护机制的，就算是自定义的类加载器也只能重写 findClass 方法，最底层的 defineClass 方法无可撼动。 参考 《深入理解 Java 虚拟机（第3版）》 周志明著. 《揭秘 Java 虚拟机：JVM 设计原理与实现》 封亚飞著.","link":"/2021-12-JVM%E7%B3%BB%E5%88%97-%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B/"},{"title":"JVM系列 —— 运行时数据区","text":"这是 JVM 系列的第七篇，见 JVM 系列。 基于 Hotspot 虚拟机 写在前面在前面的文章中，主要了解了一个类加载到 JVM 中的过程，在JVM 虚拟机进程启动后，类加载完成，java 应用开始工作，main 方法线程开始运行，又会启动其他的线程运行，实际上 JVM 虚拟机本身开辟了很多线程，包括守护线程， main 主线程属于非守护线程，JVM 规定，当所有非守护线程执行完成以后，JVM 虚拟机退出。所以在 JVM 运行的过程中，必然会涉及到数据交互的问题，这部分数据交互的区域就是运行时数据区。 Java 虚拟机定义了若干种程序运行期间会使用到的运行时数据区，有些随虚拟机进程启动而创建，随虚拟机退出而销毁，有些随着线程的启动而创建，随着线程的结束而销毁，和线程一一对应。 下面就从虚拟机启动和线程开始的角度来看一下 JVM 运行时数据区的组成。 JVM 组成这里再在JVM系列第一篇 的 JVM 组成的结构图上细化一下运行时数据区的部分： 随线程启动而创建的数据PC 寄存器PC 寄存器的目的就是用来记录当前执行到方法的哪一行代码了。因为方法有可能是 native 的，所以如果正在执行的是 native 的方法，PC 寄存器里的值就是 undefined，如果是不是 native 的方法，那么PC 寄存器存放的就是 JVM 正在执行的字节码指令的地址。这个区域占用的内存很小，实际上，在 x86 平台，这个 PC 寄存器就是 esi 寄存器。 PC 寄存器是跟随线程启动而创建出来的，每一个线程都有一个 PC 寄存器，对于线程间的切换，CPU 会直接拿 PC 寄存器指向的指令地址，继续执行。 唯一一个不会出现 OOM 的区域。 java 虚拟机栈java 虚拟机栈和线程是 1:1 的关系，它的作用就是存储局部变量和一些中间结果。实际上 java 栈的最重要的组成就是栈桢了，每创建一个方法就会创建一个栈桢。栈是一个先入后出的结构体，java 栈相当于是一个容器，里面存放的是一个一个的栈桢，下面来看一下栈桢是什么结构。 栈桢栈桢随着方法调用而创建，随着方法结束而销毁。 无论方法是正常完成还是发生了未被捕获的异常结束，都属于方法的结束方式。 一个方法对应一个栈桢，栈桢主要由以下部分组成： 局部变量表在编译期间，这个表的长度就已经确定了。基本单位是 slot，“槽”。在类加载时可以从方法的 Code 属性得知。实际上就是一个数组结构，索引值从 0 开始，对于实例方法，0 的位置存放的是 this 引用。对于一个 slot 占用多少字节，不同的平台也是不同的，32 位平台上，一个 slot 大小位 4 字节，64 位平台上，一个 slot 大小位 8 字节，对于 long 和 double 类型，占用 2 个 slot。 操作数栈“当前栈桢的操作数栈”，在编译期间，这个栈的深度就已经确定了。同样也是在方法中的 Code 属性中获得。long 或者 double 类型都会占用两个深度。Java虚拟机会通过字节码指令来从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中，或者通过指令从操作数栈取走数据或重新入栈。 动态链接每一个栈桢中都包含一个指向运行时常量池中该栈桢所属方法的引用，这个引用是为了支持方法调用过程中的动态链接。在 class 文件的常量池中有很多符号引用，在方法的字节码中的方法调用指令就以常量池里指向方法的符号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用的时候就会转化为直接引用，这部分称为静态解析，另外一部分会在每一次运行期间都转化为直接引用，这部分称为动态链接。所谓的直接引用就是在内存中的正确偏移量，即实际的内存地址位置。实现动态链接的关键是在 java 方法栈中持有一个指向常量池的指针，便可得到 java 方法的字节码指令，完成逻辑操作。 这里会涉及到 C++ 虚方法 的概念，后面可以再详细学习。 方法返回值当一个方法开始执行后，要么正常调用完成，可能会有返回值返回给上层的调用者，要么异常调用完成，不会提供返回值给上层调用者。正常调用完成之后，要恢复调用者的上下文数据。 总的来说，一个Java方法栈桢的结构如下： java 本地方法栈在 Hotspot 中，这个栈会在线程创建的时候创建。 我们知道 JVM 是有 C++ 和 C 混合编写的，所以在 jdk 中，会有很多调用 C++ 或者 C 写的方法，在 Java 中没有实现，这类方法称为 native 方法。而 java 本地方法栈就是调用这些 native 方法而产生的。 随 JVM 进程启动而创建的数据java 堆根据 JVM 规范，这部分的区域用来分配类实例和数组对象。所有线程共享这部分区域。在 Java 虚拟机启动的时候就会被创建，并且也是垃圾回收器管理的最重要的区域，这也是 Java 和 C++ 重要的区别之一，无需显式地销毁对象所分配的内存，JVM 自动进行内存管理。 java 堆并不是对象唯一分配的地方，也有可能分配在线程的 TLAB(Thread Local Allocation Buffer) 区域。当然，这些线程私有的 TLAB 也是从 Java 堆上划分出来的。 堆结构： 方法区（非堆）方法区在虚拟机启动的时候创建。通常也称为“非堆”。是一个逻辑上的概念，Hotspot 的实现来说，jdk 1.8 和 1.7 相比，用永久代实现的方法区替换成用空间来实现方法区。方法区主要存储的是类的结构信息，比如运行时常量池、字段、方法、构造函数和普通方法的字节码内容。方法区中除了类的元数据信息，最重要的就是运行时常量池的部分了。 运行时常量池在加载类到虚拟机后，就创建对应的运行时常量池。JVM 规范说，“运行时常量池（runtime constant pool）是 class 文件中每一个类或接口的常量池表（constant_pool table）的运行时表示形式。” class 文件格式中常量池的结构为： 12u2 constant_pool_count;cp_info constant_pool[constant_pool_count-1]; 但是，并不是常量一定只有编译期间才会产生，也就是说并不是 class 文件中常量池的内容才能进入到方法区的常量池，运行期间也可以将新的常量放入池中，比如String.intern() 方法。 以上就是 JVM 运行时的数据区域。 扩展问题本机（系统）堆 和 Java 堆 ？Java 虚拟机的本质也是由其他语言所编写的应用程序，比如 Hotspot 用 C++ 和 C 编写而成。从 Java 虚拟机本身的应用角度，对于 Java 堆，包含 Java对象实例，通常称为“堆”，是垃圾回收器所管理的区域。可以指定堆的大小，使用 mmap 或 shmat 来分配 Java 堆，在 JVM 启动的过程中，预分配 Java 堆的最大大小作为一个连续区域，即使最小堆大小设置很低也是如此，为了动态扩展。从 Java 虚拟机实现的角度来说，本机堆或系统堆（native heap）使用操作系统的底层 malloc 和 free 机制进行分配，且用于底层特定的 Java 对象，比如： AWT 和 Swing 所需的 Motif 对象 数据压缩例程缓冲区，这是 Java 类库读写压缩数据（如 .zip 或 .jar 文件）所需的内存空间。 应用程序 JNI 代码进行的 Malloc 分配 Just In Time (JIT) 编译器生成的编译代码 要映射至 Java 线程的线程 JDK 1.4 之前的称呼 native heap 转为现在的称呼 directory memory 。之所以 heap 前加 native 来修饰，是因为要让其和虚拟机规范中的 java heap 区分，而现在称呼 directory memory 是因为我们能够直接通过引用访问对象，消除了一次拷贝操作。 堆与非堆、直接内存、本地内存、方法区、永久代、元空间 傻傻分不清楚？ 本地内存和直接内存当执行 java xxx命令时，操作系统会创建一个进程来执行这个 java 可执行程序，而每个进程都有自己的虚拟地址空间，JVM 启动后，用到的 java 堆、java 栈、方法区就是从进程的虚拟地址空间上分配的。JVM 内存只是进程空间的一部分，因为进程还包括代码段、数据段等。所以从 JVM 的角度来看，JVM 内存之外，java 进程之内的内存叫做本地内存（Native Memory）或者直接内存（Direct Memory）。JVM 是由 C++ 或 C 实现的应用程序，C++ 或 C 代码操作的内存区域就是本地内存中分配的。示意图：所以直接内存并不是 JVM 运行时数据区域的一部分。 方法区、永久代、元空间方法区是 JVM 规范规定一个逻辑上的概念，具体的实现有各自的厂商决定，所以 Hotspot 在堆（系统堆）中划分出一块区域，称为”永久代“，为了方便垃圾收集器能够管理到这个区域，所以jdk1.8 以前的版本，永久代实现的方法区，并且，方法区和堆是相互隔离的，但是使用的物理内存是连续的。其他的厂商比如 JRockit、J9 都没有这个永久代的概念。JDK1.8 的时候，Hotspot 用元空间实现了方法区，而元空间使用的是本地内存（Native Memory），所以元空间的大小会跟物理系统的内存有关。 堆与非堆：堆是存放实例对象和数组对象的区域，Hotspot 采用“经典分代”的思想来划分和管理堆，新生代（young）和老年代（old），而新生代（young）又划分为 Eden 区、From Survivor区、To Survivor区，默认比例是 8:1:1。非堆主要就是指元空间（Metaspace），是方法区的实现，存放类的结构信息，在类加载的时候放到这个区域。 为什么要使用直接内存或本地内存？从上面的示意图中看到，使用直接内存不会受到 java 堆大小的限制，只是会受到本机内存的限制。在 jdk 1.4 引入了新的 NIO（New Input/Output） 类，引入了基于通道（Channel） 与 缓冲区（Buffer）的 I/O 方式，可以使用 Native 函数库直接分配堆外内存，也就是本地内存。使用直接内存一般和使用堆内内存来作比较的。也就是HeapByteBuffer 和 DirectByteBuffer 来做比较。使用 HeapByteBuffer 直接在 java 堆上创建一个 buffer，而 DirectByteBuffer 是在堆外内存，即本地内存上创建一个 buffer，在 java 堆上维护一个虚引用指向本地内存的分配的空间地址，本质上都是数组，而应用程序属于用户空间，一旦有 IO 的操作，会经过操作系统内核来做拷贝处理，比如网卡有 IO 数据流进来以后，内核会拷贝数据到进程的内存区域，也就是本地内存，对于 HeapByteBuffer 来说，栈变量访问 buffer 内的数据，还是需要拷贝本地内存的数据到 java 堆上，这样 java 应用才会读取到数据；对于 DirectByteBuffer 来说，java 堆上DirectByteBuffer 对象直接指向本地内存的地址，不需要拷贝数据就能直接访问。示意图： 所以，使用直接内存可以减少一次内存拷贝，避免 java 堆和 native 堆中来回复制数据。","link":"/2021-12-JVM%E7%B3%BB%E5%88%97-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"title":"JVM系列 —— 类的生命周期之链接和类初始化","text":"这是 JVM 系列的第四篇，见 JVM 系列。 写在前面在前一篇的文章里面，说了说 JVM 类的生命周期第一阶段 —— 加载，加载主要干了几件事情： 通过类全限定名得到类的二进制字节流； 在内存中生成代表这个类的 java.lang.Class 对象，作为方法区中这个类的各种数据入口； 静态的存储结构转化为方法的运行时数据结构；接下来是链接和初始化阶段。总得来说，链接阶段就是把符号引用解析为直接引用，也就是把指向常量池的索引，换成实际的物理内存地址的阶段，而初始化阶段就是执行类构造器方法 &lt;clinit&gt;()的过程。 链接链接这部分又分为三个阶段，校验，准备，解析。 实际上想想，在被 JVM 使用之前，还需要对 class 进行校验等操作。对于链接的三个阶段，基于类的生命周期图上再增加一些说明，如下： 校验部分的规则还有很多，java 虚拟机规范定了很多校验规则。在链接阶段，准备的过程中，实际上那些变量已经被存放到了方法区。 类初始化类初始化阶段总结起来就是一句话：调用 &lt;clinit&gt;() 的方法。 那么这里的 &lt;clinit&gt;() 是个什么东东呢？ 这个方法是编译器（javac）在编译期间自动生成的，java 类中如果有静态变量或者静态代码块，那么编译后的字节码中会包含一个 &lt;clinit&gt; 方法。这个方法只能有 JVM 在运行期间调用，即 java 类的初始化。 注意哦！！！java 类编译后的字节码中也会包含一个 &lt;init&gt; 的方法哦，这个是类的构造器方法，不要把&lt;clinit&gt; 和 &lt;init&gt; 混淆了。 举个栗子，如下图： JVM 规定几种情况下，类或接口才会初始化： 执行以下指令时：new、getstatic、putstatic 或 invokestatic； 首次调用 java.lang.invoke.MethodHandle 实例时，解析的种类是2（REF_getStatic）、4（REF_putStatic）、6（REF_invokeStatic）、8（REF_newInvokeSpecial）的方法句柄； 在调用类库中的某些反射方法，比如 Class 类或 java.lang.Reflect 包中的方法； 在对某个子类进行初始化时； 在它被选定为java虚拟机启动时的初始类时； 从源码的角度上，在使用 new 关键字第一次实例化一个 java 类的时候，调用的接口是 hotspot/src/share/vm/oops/instanceKlass.cpp 中的 call_class_initializer_impl() 方法。源码如下： 类初始化源码12345678910111213141516171819202122void InstanceKlass::call_class_initializer_impl(instanceKlassHandle this_oop, TRAPS) { if (ReplayCompiles &amp;&amp; (ReplaySuppressInitializers == 1 || ReplaySuppressInitializers &gt;= 2 &amp;&amp; this_oop-&gt;class_loader() != NULL)) { // Hide the existence of the initializer for the purpose of replaying the compile return; } methodHandle h_method(THREAD, this_oop-&gt;class_initializer()); assert(!this_oop-&gt;is_initialized(), &quot;we cannot initialize twice&quot;); if (TraceClassInitialization) { tty-&gt;print(&quot;%d Initializing &quot;, call_class_initializer_impl_counter++); this_oop-&gt;name()-&gt;print_value(); tty-&gt;print_cr(&quot;%s (&quot; INTPTR_FORMAT &quot;)&quot;, h_method() == NULL ? &quot;(no method)&quot; : &quot;&quot;, (address)this_oop()); } if (h_method() != NULL) { JavaCallArguments args; // No arguments JavaValue result(T_VOID); JavaCalls::call(&amp;result, h_method, &amp;args, CHECK); // Static call (no args) }} 其中 class_initializer() 函数就是找有没有 clinit 的方法，代码如下： class_initializer()函数12345678Method* InstanceKlass::class_initializer() { Method* clinit = find_method( vmSymbols::class_initializer_name(), vmSymbols::void_method_signature()); if (clinit != NULL &amp;&amp; clinit-&gt;has_valid_initializer_flags()) { return clinit; } return NULL;} 如果找到了，就直接通过 JavaCalls::call() 执行初始化方法。 从上面的源码可知，如果 java 类中没有静态字段或者静态代码块 static{}，编译后的字节码就不会包含 clinit 方法，上面的逻辑就不会执行。 结合上篇，类加载机制基本上就是这样的一个流程，加载 -&gt; 链接 -&gt; 初始化的逻辑，当然 JVM 是个多线程的程序，这些阶段必定是糅杂在一起的，不管怎样，上面执行的顺序是不会变得，但是并不是按照顺序执行的。比如加载和验证是交叉进行的，在加载开始之后，立即启动了文件格式的校验，只有在通过了校验以后，二进制字节流才会存入方法区。","link":"/2021-12-JVM%E7%B3%BB%E5%88%97-%E9%93%BE%E6%8E%A5%E5%92%8C%E7%B1%BB%E5%88%9D%E5%A7%8B%E5%8C%96/"},{"title":"手把手带你读class文件字节码","text":"这是 JVM 系列的第五篇，见 JVM 系列。 示例代码基于 jdk1.8 版本 准备IDEA 里面如果想看 class 的二进制文件需要下载插件 BinEd ，也有 C 端的。另外查看编译后的 class 文件人类友好插件可以选用jclasslib Bytecode Viewer ，或者用命令 javap -verbose className 来打印出 class 的文件格式。 class 文件格式前面的文章（JVM 系列 —— class 文件格式 ）讲过一个正确的 class 文件格式长什么样子，另外，再强调一点就是，这个 class 文件指的是 class 文件流，并不是单纯指磁盘上的 class 文件，也可能来自网络字节流。 ClassFile 格式： ClassFile123456789101112131415161718ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];} 最简单的一个类 Demo 代码我们就用最简单的一个类，再加上一个 int 类型的字段作为示例代码，我放在工程里面的，所以会带有包名，如下： demo code12345package top.caolizhi.example.jvm.bytecode;public class Bytecode { int s = 3;} class 文件二进制字节码装完插件后，选中类文件，然后点击菜单 View -&gt; Show Bytecode With Jclasslib 。右变就会出现友好可读的 class 文件的描述：我们也可以用命令行来操作，先编译一遍，然后进入到目录 target &gt; classes，在控制台运行命令：javap -verbose top.caolizhi.example.jvm.bytecode.Bytecode，打印如下： javap -verbose 命令输出1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253E:\\Workspaces\\Git\\caolizhi-personal\\jvm\\target\\classes&gt;javap -verbose top.caolizhi.example.jvm.bytecode.BytecodeClassfile /E:/Workspaces/Git/caolizhi-personal/jvm/target/classes/top/caolizhi/example/jvm/bytecode/Bytecode.class Last modified 2021-12-9; size 352 bytes MD5 checksum e9c0623eb64cce65bad7f5f5b3e7678c Compiled from &quot;Bytecode.java&quot;public class top.caolizhi.example.jvm.bytecode.Bytecode minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#16 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#17 // top/caolizhi/example/jvm/bytecode/Bytecode.s:I #3 = Class #18 // top/caolizhi/example/jvm/bytecode/Bytecode #4 = Class #19 // java/lang/Object #5 = Utf8 s #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Ltop/caolizhi/example/jvm/bytecode/Bytecode; #14 = Utf8 SourceFile #15 = Utf8 Bytecode.java #16 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #17 = NameAndType #5:#6 // s:I #18 = Utf8 top/caolizhi/example/jvm/bytecode/Bytecode #19 = Utf8 java/lang/Object{ int s; descriptor: I flags: public top.caolizhi.example.jvm.bytecode.Bytecode(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_3 6: putfield #2 // Field s:I 9: return LineNumberTable: line 3: 0 line 5: 4 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Ltop/caolizhi/example/jvm/bytecode/Bytecode;}SourceFile: &quot;Bytecode.java&quot; 上面这些都是工具帮你把 class 美化了的，但是 JVM 没法这么读，只能一个一个字节的读，接下来，我们从 JVM 的角度去读一下字节码。在 target &gt; classes目录，找到 Bytecode.class 的文件，右键，选中 Open As Binary，class 文件的二进制如下：接下来，开始一个一个字节的去读，看看 JVM 到底是怎么解析的？ 如果我是一个虚拟机，我怎么读 class 文件？这个 ClassFormat 文件谁规定的，当然是JVM 规范啦~。参考 Java Virtual Machine Specification 读取魔数（magic） 魔数1u4 magic; 就跟公司周三早餐铁打的紫菜饭团一样，魔数也是万年不变的 oxCAFEBABE，主要就是看着这个文件流是不是 class 文件。关于这个魔数的由来，可以去看看维基百科上 Java 始祖 James Gosling 说过的话 。也就是说，前面的 4 个字节确定是 CA，FE，BA，BE。 16 进制里面的只有 A ~ F，cafe 刚好属于 16 进制里面的，又与 java 渊源已久，另外 babe 推测想用 baby 的，毕竟 babe 比较轻浮口语化，可是 y 不在 16 进制的字母里面，所以改成了 e。 class 文件字节的确也是这样： 读取版本号（minor_version,major_version） 版本号12u2 minor_version;u2 major_version; 接下来的4个字节是关于版本号的，前面的两个字节表示副版本，后面的两个字节表示主版本，比如这里：minor_version值为 0x0000，十进制就是 0， major_version值为 0x0034，十进制就是 52，而 52 对应的是 jdk8，那么这个 class 文件的格式版本号就确定为：52.0，如果在 jdk11 的环境里面解析这个 class 文件是不被支持的。 jdk 版本对应关系： jdk1.8 jdk9 jdk10 jdk11 52 53 54 55 class 文件字节： 解析常量池（constant_pool） 很重要！很重要！很重要！ 常量池12u2 constant_pool_count;cp_info constant_pool[constant_pool_count-1]; 接下来是非常重要的一部分了，后面的解析都会依赖常量池里面的值。先看版本号后面的两个字节，值为0x0014，十进制为 20，也就是说这个类的常量池表结构constant_pool数组大小为 19，0 位置保留，数组的每一个项都是cp_info 结构 ，如下： 常量池表中项的结构 cp_info1234cp_info { u1 tag; u1 info[];} 其中 tag 是个枚举值，info 根据 tag的值来确定结构，参考 JVM 规范文档 。 常量池第 1 项：先来看看常量池表的第一个项的 tag 值 0x0A，十进制为 10，如下图：该 tag的值在表中找到对应的 info 结构为 CONSTANT_Methodref_info，表示，类中方法的符号引用，它的结构如下： tag 为 10 对应的 info 结构12345CONSTANT_Methodref_info { u1 tag; // 10 u2 class_index; // 指向声明方法的类描述符 CONSTANT_Class_info 的索引项 u2 name_and_type_index; // 指向名称以及类型描述符CONSTANT_NameAndType_info 的索引项 } 也就是说，在常量池表的第一项中，对应的就是 CONSTANT_Methodref_info 结构，已经知道 tag 是 10 了，那么 0x0A 后面的两个字节 0x0004，十进制 4，表示的是 u2 class_index，指向常量池的索引 4，我们看到常量池 4 位置的值为： 再后面的两个字节 0x0010，十进制是 16，表示的是 u2 name_and_type_index，指向常量池索引 16，看 16 位置的值为： 常量池第 2 项：按照上面的方法，接着看的 tag 值 0x09 对应 CONSTANT_Fieldref_info，结构如下： tag 为 9 对应的 info 结构12345CONSTANT_Fieldref_info { u1 tag; // 9 u2 class_index; // 指向声明字段的类或接口描述符 CONSTANT_Class_info 的索引项 u2 name_and_type_index; // 指向字段描述符CONSTANT_NameAndType_info 的索引项 } u2 class_index -&gt; 0x0003，十进制 3，指向常量池第 3 个位置：&lt;top/caolizhi/example/jvm/bytecode/Bytecode&gt;u2 name_and_type_index -&gt; 0x0011，十进制 17，指向常量池 17 的位置： 常量池第 3 项：tag -&gt; 0x07，十进制7，对应 CONSTANT_Class_info tag 为 7 对应的 info 结构1234CONSTANT_Class_info { u1 tag; // 7 u2 name_index; // 全限定名常量项的索引} u2 name_index -&gt; 0x0012，十进制 18，指向常量池 18 的位置： 常量池第 4 项：tag -&gt; 0x07，十进制7，对应 CONSTANT_Class_infou2 name_index -&gt; 0x0013，十进制 19，指向常量池 19 的位置： 常量池第 5 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_info， tag 为 1 对应的 info 结构12345CONSTANT_Utf8_info { u1 tag; // 1 u2 length; // UTF-8 缩略编码字符串占用字节数 u1 bytes[length]; // 长度为 length 的 UTF-8 编码字符串} 0x01 后面的两个字节 0x0001 表示 length，值为 1，也就是说接下来的后面 1 一个长度的字节是 UTF-8 编码字符串，即 0x73，ASCII 码表示 s，其实就是类中定义的字段 s，如图： 常量池第 6 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x0001，十进制1，长度为1bytes -&gt; 0x49，对应 ASCII 码 I，字段 s 的类型 常量池第 7 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x0006，十进制 6，长度为6bytes -&gt; 字节：3C 69 6E 69 74 3E，对应 ASCII 码的 &lt;init&gt; 常量池第 8 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x0003，十进制 3，长度为3bytes -&gt; 字节：28 29 56，对应 ASCII 码的 ()V 常量池第 9 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x0004，十进制 4，长度为4bytes -&gt; 字节：43 6F 64 65，对应 ASCII 码的 Code 常量池第 10 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x000F，十进制 15，长度为15bytes -&gt; 字节：4C 69 6E 65 4E 75 6D 62 65 72 54 61 62 6C 65，对应 ASCII 码的 LineNumberTable 常量池第 11 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x0012，十进制 18，长度为18bytes -&gt; 字节：4C 6F 63 61 6C 56 61 72 69 61 62 6C 65 54 61 62 6C 65，对应 ASCII 码的 LocalVariableTable 常量池第 12 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x0004，十进制 4，长度为 4bytes -&gt; 字节：74 68 69 73，对应 ASCII 码的 this 常量池第 13 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x002C，十进制 44，长度为 44bytes -&gt; 字节：4C 74 6F 70 2F 63 61 6F 6C 69 7A 68 69 2F 65 78 61 6D 70 6C 65 2F 6A 76 6D 2F 62 79 74 65 63 6F 64 65 2F 42 79 74 65 63 6F 64 65 3B，对应 ASCII 码的 Ltop/caolizhi/example/jvm/bytecode/Bytecode; 常量池第 14 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x000A，十进制 10，长度为 10bytes -&gt; 字节：0A 53 6F 75 72 63 65 46 69 6C 65，对应 ASCII 码的 SourceFile 常量池第 15 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x000D，十进制 13，长度为 13bytes -&gt; 字节：42 79 74 65 63 6F 64 65 2E 6A 61 76 61，对应 ASCII 码的 Bytecode.java 常量池第 16 项：tag -&gt; 0x0C，十进制 12，对应 CONSTANT_NameAndType_info tag 为 12 对应的 info 结构12345CONSTANT_NameAndType_info { u1 tag; // 12 u2 name_index; // 指向该字段或方法名称常量项的索引 u2 descriptor_index; // 指向该字段或方法描述符常量项的索引} name_index -&gt; 0x0007，十进制 7，指向常量池 7 的位置： descriptor_index -&gt; 0x0008，十进制 8，指向常量池 8 的位置： 常量池第 17 项：tag -&gt; 0x0C，十进制 12，对应 CONSTANT_NameAndType_infoname_index -&gt; 0x0005，十进制 5，指向常量池 5 的位置： descriptor_index -&gt; 0x0006，十进制 6，指向常量池 6 的位置： 常量池第 18 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_infolength -&gt; 0x002A，十进制 42，长度为 42bytes -&gt; 字节：74 6F 70 2F 63 61 6F 6C 69 7A 68 69 2F 65 78 61 6D 70 6C 65 2F 6A 76 6D 2F 62 79 74 65 63 6F 64 65 2F 42 79 74 65 63 6F 64 65，对应 ASCII 码的 top/caolizhi/example/jvm/bytecode/Bytecode 常量池第 19 项：tag -&gt; 0x01，十进制1，对应 CONSTANT_Utf8_info，length -&gt; 0x0010，十进制 16，长度为 16，bytes -&gt; 字节：6A 61 76 61 2F 6C 61 6E 67 2F 4F 62 6A 65 63 74，对应 ASCII 码的 java/lang/Object 以上就是常量池的解析。 解析类的访问权限（access_flags） access_flags1u2 access_flags; 接下来的 2 个字节表示的是 access_flags，表示访问标志位，标注类或接口的访问信息，这里值为 0x0021，查文档可知，既包括 ACC_PUBLIC(0x0001) 又包括 ACC_SUPER(0x0020)，jdk1.2以后都有ACC_SUPER。现在这个类是 public 类型的。 解析当前类名称（this_class） this_class1u2 this_class; 访问标志位后面的 2 个字节 0x0003 表示当前类的全限定名，即包名+类名，指向常量池中的索引值。对应常量池 3 的位置： 解析父类名称（super_class） super_class1u2 super_class; this_class 访问标志位后面的 2 个字节 0x0004 表示当前类的父类全限定名，指向常量池中的索引值。对应常量池 4 的位置： java.lang.Object 是所有类的父类。 解析接口（interfaces） 接口项12u2 interfaces_count;u2 interfaces[interfaces_count]; 接下来的 2 个字节 0x0000，十进制 0，没有接口，也就没有 interfaces[]表结构。 解析字段（fields） 字段项12u2 fields_count;field_info fields[fields_count]; 字段项的前两个字节表示长度，0x0001，十进制 1，只有一个字段，和源码中定义一个字段匹配。field_info 结构如下： field_info 结构1234567field_info { u2 access_flags; u2 name_index; u2 descriptor_index; u2 attributes_count; attribute_info attributes[attributes_count];} 在 fields_count 字节后面 2 个字节表示字段的访问标志，access_flags -&gt; 0x0001 表示 public，各个值对应表参考。name_index -&gt; 0x0005，指向常量池 5 的位置：sdescriptor_index -&gt; 0x0006，指向常量池 6 的位置：I，有关字段类型参考链接。 attributes_count -&gt; 0x0000，没有属性值。 至此，字段的解析完毕。 解析方法（methods） 方法解析12u2 methods_count;method_info methods[methods_count]; 方法的解析和字段解析查不多，method_info 结构如下： method_info 结构1234567method_info { u2 access_flags; u2 name_index; u2 descriptor_index; u2 attributes_count; attribute_info attributes[attributes_count];} 先看 methods_count 值为：0x0001，只有一个方法，这里奇怪了，我们没有定义方法，但是为什么会有一个方法呢？ 继续往下看：access_flags -&gt; 0x0001，表示 public，可以参考链接。 name_index -&gt; 0x0007，表示方法名称，指向常量池的第 7 个索引位置值，&lt;init&gt;： descriptor_index -&gt; 0x0008，方法描述符，指向常量池的第 8 个索引位置值，()V attributes_count -&gt; 0x0001，说明有一个属性，属性的结构： attribute_info 结构12345attribute_info { u2 attribute_name_index; u4 attribute_length; u1 info[attribute_length];} 接下来的 2 个字节 0x0009 表示 attribute_name_index，指向常量池的索引值 9。 attribute_info中的info 结构类型有很多，可以参考链接 。这里的类型为 Code。 attribute_length -&gt; 占 4 个字节，0x00_00_00_38，十进制为 56，表示属性长度为 56，也就是这个字节后面的 56 个字节表示的是 Code 这个属性。不包括前面 attribute_name_index 和 attribute_length 占用的 6 个字节。 接下来看一下 Code 属性的结构，Code 属性是一个 class 文件最重要的一个属性！ Code 属性12345678910111213141516Code_attribute { u2 attribute_name_index; u4 attribute_length; u2 max_stack; // 操作数栈深度最大值 u2 max_locals; // 局部变量表所需要存储的空间，单位是 slot， u4 code_length; // 源码编译后生成的字节码指令的长度 u1 code[code_length]; // 真正存放字节码指令的地方 u2 exception_table_length; // 异常表大小 { u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; } exception_table[exception_table_length]; u2 attributes_count; // 属性大小 attribute_info attributes[attributes_count]; // 属性表} max_stack -&gt; 0x0002，表示操作数栈最大深度是 2，这里可以思考一下为什么是 2 ？ max_locals -&gt; 0x0001，表示局部变量表的大小是 1，占用一个 slot。可以看到编译后就已经确定了一个方法的大小。 code_length -&gt; 00 00 00 0A，十进制 10，也就是说后面的 10 个字节就是这个方法的字节码指令。 code -&gt; 2A B7 00 01 2A 06 B5 00 02 B1，这 10 个字节就是一组字节码指令，在 JVM 中一个字节表示一个指令，最大只有 255 个指令集。 查看JVM的指令集表，上面的 10 个字节中的字节码指令如下： 操作码 HEX 含义 aload_0 0x2A 将局部变量表中的第 0 个 slot 中 reference 类型的本地变量推送到操作数栈顶 invokespecial 0xB7 调用类的实例构造方法、private 方法或父类方法，指令后面会带上一个 u2 类型的参数，指向常量池的索引值，表示调用哪个方法 iconst_3 0x06 将 int 类型 3 推到栈顶 putfield 0xB5 用栈顶的值为指定的实例域赋值，指令后面会带上一个 u2 类型的参数，表示给哪一个赋值，指向常量池的索引值 return 0xB1 从当前方法返回 上面的字节码执行流程如下： exception_table_length -&gt; 0x0000，异常表大小是 0： attributes_count -&gt; 0x0002，Code 属性的属性表大小是 2 个， 属性表结构都是 attribute_info，如下： attribute_info 结构12345attribute_info { u2 attribute_name_index; u4 attribute_length; u1 info[attribute_length];} Code 属性的第 1 个属性： attribute_name_index -&gt; 0x000A，十进制是 10，指向常量池的索引值LineNumberTable： LineNumberTable 属性用于记录字节码指令与源代码行号对应的关系，异常抛出时显示行号，debug 调试时用到的行号，结构： LineNumberTable 结构123456789LineNumberTable_attribute { u2 attribute_name_index; u4 attribute_length; u2 line_number_table_length; { u2 start_pc; u2 line_number; } line_number_table[line_number_table_length];} attribute_length -&gt; 00 00 00 0A，十进制 10，属性的长度为 10，即后面的 10 个字节描述这个属性。 line_number_table_length -&gt; 0x0002，行号表长度为 2， 行号表第 1 行start_pc -&gt; 0x0000，字节码行号，也即字节码指令偏移位置line_number -&gt; 0x0003，Java源码行号 行号表第 2 行start_pc -&gt; 0x0004line_number -&gt; 0x0005 Code 属性的第 2 个属性： attribute_name_index -&gt; 0x000B，十进制是 11，指向常量池的索引值LocalVariableTable： LocalVariableTable 属性用于描述栈桢中局部变量表中的变量与 Java 源码中定义的变量之间的关系，结构： LocalVariableTable 结构1234567891011LocalVariableTable_attribute { u2 attribute_name_index; u4 attribute_length; u2 local_variable_table_length; { u2 start_pc; // 字节码偏移量 u2 length; // 作用范围覆盖的长度 u2 name_index; // 指向常量池的索引值 u2 descriptor_index; // 指向常量池的索引值 u2 index; // 栈桢中局部变量表中 slot 的位置 } local_variable_table[local_variable_table_length];} attribute_length -&gt; 00 00 00 0C，十进制 12，属性的长度为 12，即后面的 12 个字节描述这个属性。 local_variable_table_length -&gt; 0x0001，局部变量表长度为 1，start_pc -&gt; 0x0000，字节码行号，即 aload_0length -&gt; 0x000A，长度为 10，和上面的结合起来就是这个变量在字节码中的作用域范围，10个字节，从字节码偏移量 0 开始 到 10 结束，如下图，可以看拿到覆盖了整个 &lt;init&gt; 方法。 name_index -&gt; 0x000C，指向常量池 12 的位置 descriptor_index -&gt; 0x000D，指向常量池 13 的位置 也就是说 this 指向的对象类型是 Bytecode。 index -&gt; 0x0000，理所当然，在局部变量表的第 0 个 slot 位置。 至此，整个方法解析已经完成了 解析属性（attributes） 属性12u2 attributes_count;attribute_info attributes[attributes_count]; 接下来的 2 个字节表示了这个类的属性大小，即 attributes_count -&gt; 0x0001 attribute_info 跟上面的方法的属性类型结构都是相同的，具体类型见链接 。 attribute_name_index -&gt; 0x000E，指向常量池索引 14 的位置 SourceFile： SourceFile 属性就是记录生成这个 Class 文件的源码文件名称。一般来说，类名和文件名是一致的，除了少数类比如内部类，抛出异常时可以显示错误所属的文件名。 SourceFile 属性结构12345SourceFile_attribute { u2 attribute_name_index; u4 attribute_length; u2 sourcefile_index; } attribute_length -&gt; 00 00 00 02，长度是 2，后面的 2 个字节描述的是该属性。 sourcefile_index -&gt; 0x000F，十进制 15，指向常量池的一个索引值 Bytecode.java 至此，该类的属性解析完了 至此，该类解析完了！！！没有多余的字节！ 啰嗦一句，解析完了我该干嘛？解析完了，我把他存起来，下次用到的时候，我再开箱即用，放哪里好呢，放到内存里面，那这个只是我能用，java 应用他们咋用，嗯，我再复制一份给它用，我的是我的，它的还是我的，哈哈~！","link":"/2021-12-%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E8%AF%BBclass%E6%96%87%E4%BB%B6%E5%AD%97%E8%8A%82%E7%A0%81/"}],"tags":[{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Spring Batch","slug":"Spring-Batch","link":"/tags/Spring-Batch/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"reactive","slug":"reactive","link":"/tags/reactive/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"},{"name":"JUC","slug":"JUC","link":"/tags/JUC/"},{"name":"CAS","slug":"CAS","link":"/tags/CAS/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"K8S","slug":"K8S","link":"/tags/K8S/"},{"name":"线程池","slug":"线程池","link":"/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"I&#x2F;O","slug":"I-O","link":"/tags/I-O/"},{"name":"虚拟机","slug":"虚拟机","link":"/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Spring","slug":"Java/Spring","link":"/categories/Java/Spring/"},{"name":"JVM","slug":"Java/JVM","link":"/categories/Java/JVM/"},{"name":"响应式编程","slug":"响应式编程","link":"/categories/%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"多线程","slug":"Java/多线程","link":"/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"内存模型","slug":"Java/内存模型","link":"/categories/Java/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"云原生","slug":"云原生","link":"/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"网络编程","slug":"网络编程","link":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"MySQL","slug":"数据库/MySQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"},{"name":"MongoDB","slug":"数据库/MongoDB","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/"},{"name":"K8S","slug":"云原生/K8S","link":"/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/K8S/"}]}